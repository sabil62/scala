2025-03-28 07:40:42 [main] INFO  test_logging$ -    ---    Welcome to cloudsim+ simulator    ---    
2025-03-28 07:40:42 [main] INFO  test_logging$ - Press 1 to start Load balancing simulator
2025-03-28 07:40:42 [main] INFO  test_logging$ - Press 2 to start Network simulator
2025-03-28 07:40:42 [main] INFO  test_logging$ - Starting operation
2025-03-28 07:40:42 [main] INFO  test_logging$ - Operation completed: Success
2025-03-28 07:41:44 [main] INFO  test_logging$ -    ---    Welcome to cloudsim+ simulator    ---    
2025-03-28 07:41:44 [main] INFO  test_logging$ - Press 1 to start Load balancing simulator
2025-03-28 07:41:44 [main] INFO  test_logging$ - Press 2 to start Network simulator
2025-03-28 07:41:44 [main] INFO  test_logging$ - Starting operation
2025-03-28 07:41:44 [main] INFO  test_logging$ - Operation completed: Success
2025-03-28 07:41:54 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 07:41:55 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 07:41:55 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 07:41:55 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 07:41:55 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql project
2025-03-28 07:41:55 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 07:41:55 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 07:41:55 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 07:41:55 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 07:41:55 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 07:41:55 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 07:41:55 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 07:41:55 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 07:41:55 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52374.
2025-03-28 07:41:55 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 07:41:55 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 07:41:56 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 07:41:56 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 07:41:56 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 07:41:56 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-1ed87a29-818b-430b-a287-6338c7c2e262
2025-03-28 07:41:56 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 07:41:56 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 07:41:56 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2479ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 07:41:56 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 07:41:56 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 07:41:56 [main] INFO  o.sparkproject.jetty.server.Server - Started @2607ms
2025-03-28 07:41:56 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 07:41:56 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 07:41:56 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 07:41:56 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52425.
2025-03-28 07:41:56 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52425
2025-03-28 07:41:56 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 07:41:56 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52425, None)
2025-03-28 07:41:56 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52425 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52425, None)
2025-03-28 07:41:56 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52425, None)
2025-03-28 07:41:56 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52425, None)
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 07:41:56 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 07:41:56 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 07:41:56 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-28 07:41:56 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 07:41:56 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 07:41:56 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 07:41:56 [dispatcher-event-loop-7] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 07:41:57 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 07:41:57 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 07:41:57 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 07:41:57 [dispatcher-event-loop-11] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 07:41:57 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 07:41:57 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 07:41:57 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-2093f225-ec7e-4a91-9c81-997c95ef8762
2025-03-28 07:56:23 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 07:56:23 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 07:56:23 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 07:56:23 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 07:56:23 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql project
2025-03-28 07:56:23 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 07:56:23 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 07:56:23 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 07:56:23 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 07:56:23 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 07:56:23 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 07:56:23 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 07:56:23 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 07:56:24 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52526.
2025-03-28 07:56:24 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 07:56:24 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 07:56:24 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 07:56:24 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 07:56:24 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 07:56:24 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-8d5cbaa3-127d-4f5b-961d-895df07ad7d5
2025-03-28 07:56:24 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 07:56:24 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 07:56:24 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @3218ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 07:56:24 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 07:56:24 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 07:56:24 [main] INFO  o.sparkproject.jetty.server.Server - Started @3374ms
2025-03-28 07:56:25 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 07:56:25 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 07:56:25 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 07:56:25 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52577.
2025-03-28 07:56:25 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52577
2025-03-28 07:56:25 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 07:56:25 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52577, None)
2025-03-28 07:56:25 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52577 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52577, None)
2025-03-28 07:56:25 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52577, None)
2025-03-28 07:56:25 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52577, None)
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 07:56:25 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 07:56:25 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 07:56:25 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7645f03e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20ead579{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 07:56:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c52552f{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 07:56:30 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 289.7342 ms
2025-03-28 07:56:30 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:43
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:43) with 1 output partitions
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:43)
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:43), which has no missing parents
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.3 KiB, free 4.5 GiB)
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 4.5 GiB)
2025-03-28 07:56:30 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:52577 (size: 6.9 KiB, free: 4.5 GiB)
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:43) (first 15 tasks are for partitions Vector(0))
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 07:56:30 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 07:56:30 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 07:56:30 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 07:56:30 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1841 bytes result sent to driver
2025-03-28 07:56:30 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 202 ms on YAU (executor driver) (1/1)
2025-03-28 07:56:30 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:43) finished in 0.482 s
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 07:56:30 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 07:56:30 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:43, took 0.528399 s
2025-03-28 07:56:30 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.2113 ms
2025-03-28 07:56:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.4999 ms
2025-03-28 07:56:31 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:45
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:45) with 1 output partitions
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:45)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:45), which has no missing parents
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 12.7 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:52577 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:45) (first 15 tasks are for partitions Vector(0))
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 07:56:31 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1777 bytes result sent to driver
2025-03-28 07:56:31 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on YAU (executor driver) (1/1)
2025-03-28 07:56:31 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:45) finished in 0.039 s
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 07:56:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:45, took 0.045126 s
2025-03-28 07:56:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.3866 ms
2025-03-28 07:56:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.1734 ms
2025-03-28 07:56:31 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at mysql_config_project.scala:59
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at mysql_config_project.scala:59) with 1 output partitions
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at mysql_config_project.scala:59)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at mysql_config_project.scala:59), which has no missing parents
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:52577 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at mysql_config_project.scala:59) (first 15 tasks are for partitions Vector(0))
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 07:56:31 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-28 07:56:31 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 34 ms on YAU (executor driver) (1/1)
2025-03-28 07:56:31 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at mysql_config_project.scala:59) finished in 0.045 s
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 07:56:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at mysql_config_project.scala:59, took 0.046663 s
2025-03-28 07:56:31 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at mysql_config_project.scala:59
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (isEmpty at mysql_config_project.scala:59) with 1 output partitions
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (isEmpty at mysql_config_project.scala:59)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at isEmpty at mysql_config_project.scala:59), which has no missing parents
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:52577 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at isEmpty at mysql_config_project.scala:59) (first 15 tasks are for partitions Vector(0))
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 07:56:31 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1502 bytes result sent to driver
2025-03-28 07:56:31 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 46 ms on YAU (executor driver) (1/1)
2025-03-28 07:56:31 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (isEmpty at mysql_config_project.scala:59) finished in 0.067 s
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 07:56:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: isEmpty at mysql_config_project.scala:59, took 0.071680 s
2025-03-28 07:56:31 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at mysql_config_project.scala:59
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (isEmpty at mysql_config_project.scala:59) with 1 output partitions
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (isEmpty at mysql_config_project.scala:59)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at isEmpty at mysql_config_project.scala:59), which has no missing parents
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:52577 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at isEmpty at mysql_config_project.scala:59) (first 15 tasks are for partitions Vector(0))
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 07:56:31 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1502 bytes result sent to driver
2025-03-28 07:56:31 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 104 ms on YAU (executor driver) (1/1)
2025-03-28 07:56:31 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (isEmpty at mysql_config_project.scala:59) finished in 0.113 s
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 07:56:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: isEmpty at mysql_config_project.scala:59, took 0.118646 s
2025-03-28 07:56:31 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at mysql_config_project.scala:63
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (isEmpty at mysql_config_project.scala:63) with 1 output partitions
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (isEmpty at mysql_config_project.scala:63)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at isEmpty at mysql_config_project.scala:63), which has no missing parents
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:52577 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at isEmpty at mysql_config_project.scala:63) (first 15 tasks are for partitions Vector(0))
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 07:56:31 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1502 bytes result sent to driver
2025-03-28 07:56:31 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 28 ms on YAU (executor driver) (1/1)
2025-03-28 07:56:31 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (isEmpty at mysql_config_project.scala:63) finished in 0.038 s
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 07:56:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: isEmpty at mysql_config_project.scala:63, took 0.044331 s
2025-03-28 07:56:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.3615 ms
2025-03-28 07:56:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.2366 ms
2025-03-28 07:56:31 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:67
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (first at mysql_config_project.scala:67) with 1 output partitions
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (first at mysql_config_project.scala:67)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:67), which has no missing parents
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 07:56:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:52577 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:67) (first 15 tasks are for partitions Vector(0))
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-28 07:56:31 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 07:56:31 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1605 bytes result sent to driver
2025-03-28 07:56:31 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 87 ms on YAU (executor driver) (1/1)
2025-03-28 07:56:31 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (first at mysql_config_project.scala:67) finished in 0.102 s
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 07:56:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-28 07:56:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: first at mysql_config_project.scala:67, took 0.101558 s
2025-03-28 07:56:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.9646 ms
2025-03-28 07:56:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.7428 ms
2025-03-28 07:56:32 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:85
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (show at mysql_config_project.scala:85) with 1 output partitions
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (show at mysql_config_project.scala:85)
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[24] at show at mysql_config_project.scala:85), which has no missing parents
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 14.1 KiB, free 4.5 GiB)
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 4.5 GiB)
2025-03-28 07:56:32 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:52577 (size: 6.7 KiB, free: 4.5 GiB)
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[24] at show at mysql_config_project.scala:85) (first 15 tasks are for partitions Vector(0))
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-28 07:56:32 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 07:56:32 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-28 07:56:32 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 07:56:32 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 3103 bytes result sent to driver
2025-03-28 07:56:32 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 50 ms on YAU (executor driver) (1/1)
2025-03-28 07:56:32 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (show at mysql_config_project.scala:85) finished in 0.068 s
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 07:56:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-28 07:56:32 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: show at mysql_config_project.scala:85, took 0.070768 s
2025-03-28 07:56:32 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 07:56:32 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 07:56:32 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 07:56:32 [dispatcher-event-loop-15] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 07:56:32 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 07:56:32 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 07:56:32 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 07:56:32 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 07:56:32 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 07:56:32 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 07:56:32 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-cff9cfcc-5362-45e2-bedc-6f0a92332889
2025-03-28 16:58:39 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 16:58:39 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 16:58:39 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 16:58:39 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 16:58:39 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 16:58:39 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 16:58:39 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 16:58:39 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 16:58:40 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54112.
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 16:58:40 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 16:58:40 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 16:58:40 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-4e63bb68-4c14-4b36-a2b2-f76d8b693ad2
2025-03-28 16:58:40 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 16:58:40 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 16:58:41 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2991ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 16:58:41 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 16:58:41 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 16:58:41 [main] INFO  o.sparkproject.jetty.server.Server - Started @3090ms
2025-03-28 16:58:41 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 16:58:41 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 16:58:41 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 16:58:41 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54163.
2025-03-28 16:58:41 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54163
2025-03-28 16:58:41 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 16:58:41 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54163, None)
2025-03-28 16:58:41 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54163 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54163, None)
2025-03-28 16:58:41 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54163, None)
2025-03-28 16:58:41 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54163, None)
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:41 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 16:58:41 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 16:58:42 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 16:58:42 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 16:58:42 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 16:58:42 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:42 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 16:58:42 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 16:58:42 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 16:58:47 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 359.2313 ms
2025-03-28 16:58:47 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:30
2025-03-28 16:58:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:30) with 1 output partitions
2025-03-28 16:58:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:30)
2025-03-28 16:58:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 16:58:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 16:58:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:30), which has no missing parents
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 16:58:48 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54163 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:30) (first 15 tasks are for partitions Vector(0))
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 16:58:48 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 16:58:48 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 16:58:48 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 16:58:48 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 16:58:48 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 230 ms on YAU (executor driver) (1/1)
2025-03-28 16:58:48 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:30) finished in 0.579 s
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 16:58:48 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:30, took 0.636697 s
2025-03-28 16:58:48 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 37.1955 ms
2025-03-28 16:58:48 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.2073 ms
2025-03-28 16:58:48 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 16:58:48 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54163 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 16:58:48 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 16:58:48 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 16:58:48 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 16:58:48 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1908 bytes result sent to driver
2025-03-28 16:58:48 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 44 ms on YAU (executor driver) (1/1)
2025-03-28 16:58:48 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.056 s
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 16:58:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 16:58:48 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.061258 s
2025-03-28 16:58:48 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 33.2565 ms
2025-03-28 16:58:48 [main] INFO  task1.mysql_config_project$ - ERROR IS filter_column  does not exist. Available: id, source_table, filter_column, is_increment, destination, start_date, end_date, hadoop_destination
2025-03-28 16:58:48 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 16:58:48 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 16:58:48 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 16:58:48 [dispatcher-event-loop-13] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 16:58:48 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 16:58:48 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 16:58:48 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 16:58:48 [dispatcher-event-loop-0] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 16:58:48 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 16:58:48 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 16:58:48 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-3275cc32-008d-4e65-8ee0-ecb20be6607d
2025-03-28 17:02:22 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 17:02:23 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:02:23 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 17:02:23 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:02:23 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 17:02:23 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 17:02:23 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 17:02:23 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 17:02:23 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 17:02:23 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 17:02:23 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 17:02:23 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 17:02:23 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 17:02:23 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54222.
2025-03-28 17:02:24 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 17:02:24 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 17:02:24 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 17:02:24 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 17:02:24 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 17:02:24 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-25644287-9c50-44c6-9afd-39fb95084c6a
2025-03-28 17:02:24 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 17:02:24 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 17:02:24 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2653ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 17:02:24 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 17:02:24 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 17:02:24 [main] INFO  o.sparkproject.jetty.server.Server - Started @2793ms
2025-03-28 17:02:24 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:02:24 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 17:02:24 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 17:02:24 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54273.
2025-03-28 17:02:24 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54273
2025-03-28 17:02:24 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 17:02:24 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54273, None)
2025-03-28 17:02:24 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54273 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54273, None)
2025-03-28 17:02:24 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54273, None)
2025-03-28 17:02:24 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54273, None)
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 17:02:24 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:25 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 17:02:25 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 17:02:25 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 17:02:25 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 17:02:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 17:02:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 17:02:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 17:02:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 17:02:29 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 271.5218 ms
2025-03-28 17:02:29 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:30
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:30) with 1 output partitions
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:30)
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:30), which has no missing parents
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 17:02:29 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54273 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:30) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:02:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 17:02:29 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:02:30 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 17:02:30 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:02:30 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 17:02:30 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 203 ms on YAU (executor driver) (1/1)
2025-03-28 17:02:30 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:30) finished in 0.495 s
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 17:02:30 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:30, took 0.537951 s
2025-03-28 17:02:30 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.599 ms
2025-03-28 17:02:30 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.2092 ms
2025-03-28 17:02:30 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 17:02:30 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54273 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 17:02:30 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:02:30 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 17:02:30 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:02:30 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1908 bytes result sent to driver
2025-03-28 17:02:30 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on YAU (executor driver) (1/1)
2025-03-28 17:02:30 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.053 s
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:02:30 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 17:02:30 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.056062 s
2025-03-28 17:02:30 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.8204 ms
2025-03-28 17:02:30 [main] INFO  task1.mysql_config_project$ - ERROR IS filter_column  does not exist. Available: id, source_table, filter_column, is_increment, destination, start_date, end_date, hadoop_destination
2025-03-28 17:02:30 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 17:02:30 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:02:30 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 17:02:30 [dispatcher-event-loop-13] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 17:02:30 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 17:02:30 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 17:02:30 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 17:02:30 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 17:02:30 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 17:02:30 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 17:02:30 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-f82db84b-8ded-4cb0-b8ab-c80896c6f435
2025-03-28 17:04:08 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 17:04:08 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:04:08 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 17:04:08 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:04:08 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 17:04:08 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 17:04:08 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 17:04:08 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 17:04:08 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 17:04:08 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 17:04:08 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 17:04:08 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 17:04:08 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 17:04:09 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54321.
2025-03-28 17:04:09 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 17:04:09 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 17:04:09 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 17:04:09 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 17:04:09 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 17:04:09 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-299603dd-1242-4af4-95b2-9b6aa0b27210
2025-03-28 17:04:09 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 17:04:09 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 17:04:09 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2654ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 17:04:09 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 17:04:09 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 17:04:09 [main] INFO  o.sparkproject.jetty.server.Server - Started @2786ms
2025-03-28 17:04:09 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:04:09 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 17:04:09 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 17:04:10 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 17:04:10 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54372.
2025-03-28 17:04:10 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54372
2025-03-28 17:04:10 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 17:04:10 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54372, None)
2025-03-28 17:04:10 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54372 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54372, None)
2025-03-28 17:04:10 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54372, None)
2025-03-28 17:04:10 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54372, None)
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 17:04:10 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 17:04:10 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 17:04:10 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 17:04:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 17:04:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 307.4267 ms
2025-03-28 17:04:15 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:30
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:30) with 1 output partitions
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:30)
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:30), which has no missing parents
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 17:04:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54372 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:30) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 17:04:15 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:04:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 17:04:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:04:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 17:04:15 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 202 ms on YAU (executor driver) (1/1)
2025-03-28 17:04:15 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:30) finished in 0.499 s
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 17:04:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:30, took 0.544636 s
2025-03-28 17:04:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 45.3668 ms
2025-03-28 17:04:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.5234 ms
2025-03-28 17:04:15 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:33
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:33) with 1 output partitions
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:33)
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:04:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:33), which has no missing parents
2025-03-28 17:04:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:04:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 17:04:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54372 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:04:16 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:04:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:33) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:04:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 17:04:16 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:04:16 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 17:04:16 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:04:16 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 17:04:16 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-28 17:04:16 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 17:04:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:33) finished in 0.044 s
2025-03-28 17:04:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:04:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 17:04:16 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:33, took 0.046967 s
2025-03-28 17:04:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.7472 ms
2025-03-28 17:04:16 [main] INFO  task1.mysql_config_project$ - ########################################
2025-03-28 17:04:16 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> transactiondate ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 17:04:16 [main] INFO  task1.mysql_config_project$ - ########################################
2025-03-28 17:04:16 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> transaction_date ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 17:04:16 [main] INFO  task1.mysql_config_project$ - ########################################
2025-03-28 17:04:16 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ---->  ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 17:04:16 [main] INFO  task1.mysql_config_project$ - ########################################
2025-03-28 17:04:16 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> timestamp ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 17:04:16 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 17:04:16 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:04:16 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 17:04:16 [dispatcher-event-loop-13] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 17:04:16 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 17:04:16 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 17:04:16 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 17:04:16 [dispatcher-event-loop-1] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 17:04:16 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 17:04:16 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 17:04:16 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-00f3ea9b-4f09-44fb-a95d-a7448f2a4aaf
2025-03-28 17:21:00 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 17:21:01 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:21:01 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 17:21:01 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:21:01 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 17:21:01 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 17:21:01 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 17:21:01 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 17:21:01 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 17:21:01 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 17:21:01 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 17:21:01 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 17:21:01 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 17:21:02 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54436.
2025-03-28 17:21:02 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 17:21:02 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 17:21:02 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 17:21:02 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 17:21:02 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 17:21:02 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-b0a08b04-a8ac-435c-b3de-7e56063c8ee5
2025-03-28 17:21:02 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 17:21:02 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 17:21:02 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2581ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 17:21:02 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 17:21:02 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 17:21:02 [main] INFO  o.sparkproject.jetty.server.Server - Started @2709ms
2025-03-28 17:21:02 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:21:02 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 17:21:02 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 17:21:02 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54487.
2025-03-28 17:21:02 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54487
2025-03-28 17:21:02 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 17:21:02 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54487, None)
2025-03-28 17:21:02 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54487 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54487, None)
2025-03-28 17:21:02 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54487, None)
2025-03-28 17:21:02 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54487, None)
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@655f69da{/jobs,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@28369db0{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@590f0c50{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/stages,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cf78c85{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5befbac1{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a565afb{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/storage,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/environment,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/executors,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 17:21:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/static,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24a2e565{/,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60c1663c{/api,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3178219a{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56476c16{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b13467c{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 17:21:03 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 17:21:03 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 17:21:03 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@daf22f0{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d299393{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 17:21:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0e9707{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 17:21:07 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 273.0047 ms
2025-03-28 17:21:07 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 17:21:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 17:21:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 17:21:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 17:21:07 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 17:21:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54487 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 17:21:08 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 17:21:08 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 203 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:08 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.483 s
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 17:21:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.529159 s
2025-03-28 17:21:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 33.0414 ms
2025-03-28 17:21:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.4525 ms
2025-03-28 17:21:08 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 17:21:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54487 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 17:21:08 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1908 bytes result sent to driver
2025-03-28 17:21:08 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:08 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.043 s
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 17:21:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.046322 s
2025-03-28 17:21:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.9302 ms
2025-03-28 17:21:08 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 17:21:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.5611 ms
2025-03-28 17:21:08 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:44
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:44) with 1 output partitions
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:44)
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:44), which has no missing parents
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 16.7 KiB, free 4.5 GiB)
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 4.5 GiB)
2025-03-28 17:21:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54487 (size: 7.1 KiB, free: 4.5 GiB)
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 17:21:08 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:08 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2103 bytes result sent to driver
2025-03-28 17:21:08 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 49 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:08 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:44) finished in 0.061 s
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 17:21:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:44, took 0.065907 s
2025-03-28 17:21:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 23.7374 ms
2025-03-28 17:21:09 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:09 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:09 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:09 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:09 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:09 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:09 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:09 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.7883 ms
2025-03-28 17:21:09 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:51
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at mysql_config_project.scala:51) with 1 output partitions
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at mysql_config_project.scala:51)
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:51), which has no missing parents
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-28 17:21:09 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54487 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:51) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 17:21:09 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-28 17:21:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-28 17:21:10 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:10 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:54487 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:21:10 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:54487 in memory (size: 7.1 KiB, free: 4.5 GiB)
2025-03-28 17:21:10 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:54487 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281721092181453058349344640_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503281721092181453058349344640_0003_m_000000
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281721092181453058349344640_0003_m_000000_3: Committed. Elapsed time: 18 ms.
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2828 bytes result sent to driver
2025-03-28 17:21:11 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 1581 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:11 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at mysql_config_project.scala:51) finished in 1.632 s
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 17:21:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at mysql_config_project.scala:51, took 1.637424 s
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job df0215a4-b65f-4da0-97dc-5124d920b103.
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job df0215a4-b65f-4da0-97dc-5124d920b103 committed. Elapsed time: 28 ms.
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job df0215a4-b65f-4da0-97dc-5124d920b103.
2025-03-28 17:21:11 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 17:21:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.5147 ms
2025-03-28 17:21:11 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:44
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (show at mysql_config_project.scala:44) with 1 output partitions
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (show at mysql_config_project.scala:44)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at show at mysql_config_project.scala:44), which has no missing parents
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 12.9 KiB, free 4.5 GiB)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 4.5 GiB)
2025-03-28 17:21:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:54487 (size: 6.1 KiB, free: 4.5 GiB)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at show at mysql_config_project.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 17:21:11 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1808 bytes result sent to driver
2025-03-28 17:21:11 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 47 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:11 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (show at mysql_config_project.scala:44) finished in 0.056 s
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 17:21:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: show at mysql_config_project.scala:44, took 0.060051 s
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:11 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:11 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:11 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:11 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:11 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:51
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (save at mysql_config_project.scala:51) with 1 output partitions
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (save at mysql_config_project.scala:51)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at save at mysql_config_project.scala:51), which has no missing parents
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-28 17:21:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:54487 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at save at mysql_config_project.scala:51) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 17:21:11 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281721117660600539047831808_0005_m_000000_5' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503281721117660600539047831808_0005_m_000000
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281721117660600539047831808_0005_m_000000_5: Committed. Elapsed time: 9 ms.
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 2699 bytes result sent to driver
2025-03-28 17:21:11 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 180 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:11 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (save at mysql_config_project.scala:51) finished in 0.209 s
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 17:21:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: save at mysql_config_project.scala:51, took 0.212216 s
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 0914fe2c-ccbe-40db-95b4-3d1cd34a2d0e.
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 0914fe2c-ccbe-40db-95b4-3d1cd34a2d0e committed. Elapsed time: 24 ms.
2025-03-28 17:21:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 0914fe2c-ccbe-40db-95b4-3d1cd34a2d0e.
2025-03-28 17:21:11 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 17:21:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.0936 ms
2025-03-28 17:21:11 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:44
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (show at mysql_config_project.scala:44) with 1 output partitions
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (show at mysql_config_project.scala:44)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[20] at show at mysql_config_project.scala:44), which has no missing parents
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 15.4 KiB, free 4.5 GiB)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 4.5 GiB)
2025-03-28 17:21:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:54487 (size: 6.9 KiB, free: 4.5 GiB)
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at show at mysql_config_project.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-28 17:21:11 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:11 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1908 bytes result sent to driver
2025-03-28 17:21:12 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 337 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:12 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (show at mysql_config_project.scala:44) finished in 0.344 s
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-28 17:21:12 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: show at mysql_config_project.scala:44, took 0.348530 s
2025-03-28 17:21:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.1577 ms
2025-03-28 17:21:12 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:12 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:12 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.9432 ms
2025-03-28 17:21:12 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:51
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (save at mysql_config_project.scala:51) with 1 output partitions
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (save at mysql_config_project.scala:51)
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[23] at save at mysql_config_project.scala:51), which has no missing parents
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 4.5 GiB)
2025-03-28 17:21:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:54487 (size: 77.3 KiB, free: 4.5 GiB)
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at save at mysql_config_project.scala:51) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-28 17:21:12 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-28 17:21:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on YAU:54487 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 17:21:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on YAU:54487 in memory (size: 6.9 KiB, free: 4.5 GiB)
2025-03-28 17:21:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on YAU:54487 in memory (size: 6.1 KiB, free: 4.5 GiB)
2025-03-28 17:21:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:54487 in memory (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 17:21:12 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281721127156607895672678190_0007_m_000000_7' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503281721127156607895672678190_0007_m_000000
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281721127156607895672678190_0007_m_000000_7: Committed. Elapsed time: 5 ms.
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2785 bytes result sent to driver
2025-03-28 17:21:13 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 887 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:13 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (save at mysql_config_project.scala:51) finished in 0.914 s
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-28 17:21:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: save at mysql_config_project.scala:51, took 0.917101 s
2025-03-28 17:21:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 12bd5c46-04b8-4e4f-a042-5fac631c44b4.
2025-03-28 17:21:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 12bd5c46-04b8-4e4f-a042-5fac631c44b4 committed. Elapsed time: 19 ms.
2025-03-28 17:21:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 12bd5c46-04b8-4e4f-a042-5fac631c44b4.
2025-03-28 17:21:13 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 17:21:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.5257 ms
2025-03-28 17:21:13 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:44
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (show at mysql_config_project.scala:44) with 1 output partitions
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (show at mysql_config_project.scala:44)
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[26] at show at mysql_config_project.scala:44), which has no missing parents
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 17:21:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:54487 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[26] at show at mysql_config_project.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-28 17:21:13 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1992 bytes result sent to driver
2025-03-28 17:21:13 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 41 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:13 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (show at mysql_config_project.scala:44) finished in 0.052 s
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-28 17:21:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: show at mysql_config_project.scala:44, took 0.056003 s
2025-03-28 17:21:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.0728 ms
2025-03-28 17:21:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 18.1248 ms
2025-03-28 17:21:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.6325 ms
2025-03-28 17:21:13 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:59
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (first at mysql_config_project.scala:59) with 1 output partitions
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (first at mysql_config_project.scala:59)
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[30] at first at mysql_config_project.scala:59), which has no missing parents
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 17:21:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:54487 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[30] at first at mysql_config_project.scala:59) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
2025-03-28 17:21:13 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:21:13 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 1648 bytes result sent to driver
2025-03-28 17:21:13 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 75 ms on YAU (executor driver) (1/1)
2025-03-28 17:21:13 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 9 (first at mysql_config_project.scala:59) finished in 0.085 s
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:21:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished
2025-03-28 17:21:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: first at mysql_config_project.scala:59, took 0.088888 s
2025-03-28 17:21:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.7263 ms
2025-03-28 17:21:13 [main] INFO  task1.mysql_config_project$ - ERROR IS Unable to parse date string: 2025-03-26 02:53:31
2025-03-28 17:21:13 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 17:21:13 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:21:13 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 17:21:13 [dispatcher-event-loop-8] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 17:21:13 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 17:21:13 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 17:21:13 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 17:21:13 [dispatcher-event-loop-12] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 17:21:13 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 17:21:13 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 17:21:13 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-0c53af22-a4b8-4111-b5a4-b5b3014277ec
2025-03-28 17:45:39 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 17:45:39 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:45:39 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 17:45:39 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:45:39 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 17:45:39 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 17:45:39 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 17:45:39 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 17:45:39 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 17:45:39 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 17:45:39 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 17:45:39 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 17:45:39 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 17:45:40 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54624.
2025-03-28 17:45:40 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 17:45:40 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 17:45:40 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 17:45:40 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 17:45:40 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 17:45:40 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-9fcdf94c-da05-4096-9138-67430a32053e
2025-03-28 17:45:40 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 17:45:40 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 17:45:40 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2500ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 17:45:40 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 17:45:40 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 17:45:40 [main] INFO  o.sparkproject.jetty.server.Server - Started @2630ms
2025-03-28 17:45:41 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:45:41 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 17:45:41 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 17:45:41 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54675.
2025-03-28 17:45:41 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54675
2025-03-28 17:45:41 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 17:45:41 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54675, None)
2025-03-28 17:45:41 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54675 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54675, None)
2025-03-28 17:45:41 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54675, None)
2025-03-28 17:45:41 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54675, None)
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 17:45:41 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 17:45:41 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 17:45:41 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 17:45:41 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 17:45:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 263.2477 ms
2025-03-28 17:45:46 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 17:45:46 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54675 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 17:45:46 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:45:46 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 17:45:46 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:45:46 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 17:45:46 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 191 ms on YAU (executor driver) (1/1)
2025-03-28 17:45:46 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.468 s
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 17:45:46 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.511974 s
2025-03-28 17:45:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 38.7278 ms
2025-03-28 17:45:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.9104 ms
2025-03-28 17:45:46 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 17:45:46 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54675 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 17:45:46 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:45:46 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 17:45:46 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:45:46 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 17:45:46 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on YAU (executor driver) (1/1)
2025-03-28 17:45:46 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.045 s
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:45:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 17:45:46 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.048248 s
2025-03-28 17:45:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.2934 ms
2025-03-28 17:45:47 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 17:45:47 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:47 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:47 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:47 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:47 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:47 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:47 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:47 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.4186 ms
2025-03-28 17:45:47 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:50
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at mysql_config_project.scala:50) with 1 output partitions
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at mysql_config_project.scala:50)
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:50), which has no missing parents
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-28 17:45:47 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54675 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:50) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:45:47 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 17:45:47 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:45:47 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:45:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-28 17:45:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-28 17:45:48 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:54675 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:45:48 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:54675 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:45:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:45:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281745475867186762982873252_0002_m_000000_2' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503281745475867186762982873252_0002_m_000000
2025-03-28 17:45:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281745475867186762982873252_0002_m_000000_2: Committed. Elapsed time: 8 ms.
2025-03-28 17:45:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2828 bytes result sent to driver
2025-03-28 17:45:48 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1073 ms on YAU (executor driver) (1/1)
2025-03-28 17:45:48 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 17:45:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at mysql_config_project.scala:50) finished in 1.130 s
2025-03-28 17:45:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:45:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 17:45:48 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at mysql_config_project.scala:50, took 1.134362 s
2025-03-28 17:45:48 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 09ab3bfe-a30e-48a8-afcb-72edd4e60603.
2025-03-28 17:45:48 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 09ab3bfe-a30e-48a8-afcb-72edd4e60603 committed. Elapsed time: 26 ms.
2025-03-28 17:45:48 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 09ab3bfe-a30e-48a8-afcb-72edd4e60603.
2025-03-28 17:45:48 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:49 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:49 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.1521 ms
2025-03-28 17:45:49 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:50
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at mysql_config_project.scala:50) with 1 output partitions
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at mysql_config_project.scala:50)
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:50), which has no missing parents
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.8 KiB, free 4.5 GiB)
2025-03-28 17:45:49 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54675 (size: 76.8 KiB, free: 4.5 GiB)
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:50) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 17:45:49 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281745493675935323299108887_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503281745493675935323299108887_0003_m_000000
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281745493675935323299108887_0003_m_000000_3: Committed. Elapsed time: 7 ms.
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2742 bytes result sent to driver
2025-03-28 17:45:49 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 199 ms on YAU (executor driver) (1/1)
2025-03-28 17:45:49 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at mysql_config_project.scala:50) finished in 0.228 s
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 17:45:49 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at mysql_config_project.scala:50, took 0.232191 s
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job e6318a2f-76a7-4bb3-879e-2e8f25979b25.
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job e6318a2f-76a7-4bb3-879e-2e8f25979b25 committed. Elapsed time: 21 ms.
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job e6318a2f-76a7-4bb3-879e-2e8f25979b25.
2025-03-28 17:45:49 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:49 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:49 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:49 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.849 ms
2025-03-28 17:45:49 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:50
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:50) with 1 output partitions
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:50)
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:50), which has no missing parents
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-28 17:45:49 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:54675 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:50) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:45:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 17:45:49 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:45:49 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-28 17:45:50 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:54675 in memory (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 17:45:50 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:54675 in memory (size: 76.8 KiB, free: 4.5 GiB)
2025-03-28 17:45:50 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:45:50 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281745495181680215378182438_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503281745495181680215378182438_0004_m_000000
2025-03-28 17:45:50 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281745495181680215378182438_0004_m_000000_4: Committed. Elapsed time: 4 ms.
2025-03-28 17:45:50 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2742 bytes result sent to driver
2025-03-28 17:45:50 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 977 ms on YAU (executor driver) (1/1)
2025-03-28 17:45:50 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:50) finished in 1.010 s
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 17:45:50 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:50, took 1.014386 s
2025-03-28 17:45:50 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 9dde2ee3-396f-4679-a573-d7a261c9a72b.
2025-03-28 17:45:50 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 9dde2ee3-396f-4679-a573-d7a261c9a72b committed. Elapsed time: 16 ms.
2025-03-28 17:45:50 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 9dde2ee3-396f-4679-a573-d7a261c9a72b.
2025-03-28 17:45:50 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 17:45:50 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 23.9347 ms
2025-03-28 17:45:50 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.2435 ms
2025-03-28 17:45:50 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:58
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (first at mysql_config_project.scala:58) with 1 output partitions
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (first at mysql_config_project.scala:58)
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[18] at first at mysql_config_project.scala:58), which has no missing parents
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 17:45:50 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:54675 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at first at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 17:45:50 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:45:50 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 17:45:50 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:45:50 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1648 bytes result sent to driver
2025-03-28 17:45:50 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 61 ms on YAU (executor driver) (1/1)
2025-03-28 17:45:50 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (first at mysql_config_project.scala:58) finished in 0.070 s
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:45:50 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 17:45:50 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: first at mysql_config_project.scala:58, took 0.073874 s
2025-03-28 17:45:50 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.0913 ms
2025-03-28 17:45:50 [main] INFO  task1.mysql_config_project$ - ERROR IS Unable to parse date string: 2025-03-26 02:53:31
2025-03-28 17:45:50 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 17:45:50 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:45:50 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 17:45:50 [dispatcher-event-loop-11] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 17:45:50 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 17:45:50 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 17:45:50 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 17:45:50 [dispatcher-event-loop-0] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 17:45:50 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 17:45:50 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 17:45:50 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-4de64ef4-121a-4224-b295-2d1549e2aded
2025-03-28 17:49:34 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 17:49:34 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:49:34 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 17:49:34 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:49:34 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 17:49:34 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 17:49:34 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 17:49:34 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 17:49:34 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 17:49:34 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 17:49:34 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 17:49:34 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 17:49:34 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 17:49:35 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54749.
2025-03-28 17:49:35 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 17:49:35 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 17:49:35 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 17:49:35 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 17:49:35 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 17:49:35 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-bee0a03e-98c6-4889-abb6-65cb385f6d2d
2025-03-28 17:49:35 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 17:49:35 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 17:49:35 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2572ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 17:49:35 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 17:49:35 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 17:49:35 [main] INFO  o.sparkproject.jetty.server.Server - Started @2681ms
2025-03-28 17:49:35 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:49:35 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 17:49:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 17:49:36 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 17:49:36 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54800.
2025-03-28 17:49:36 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54800
2025-03-28 17:49:36 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 17:49:36 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54800, None)
2025-03-28 17:49:36 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54800 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54800, None)
2025-03-28 17:49:36 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54800, None)
2025-03-28 17:49:36 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54800, None)
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 17:49:36 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 17:49:36 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 17:49:36 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 17:49:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 17:49:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 304.5183 ms
2025-03-28 17:49:41 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 17:49:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54800 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:49:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 17:49:41 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:49:41 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 17:49:42 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:49:42 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 17:49:42 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 221 ms on YAU (executor driver) (1/1)
2025-03-28 17:49:42 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.520 s
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 17:49:42 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.570679 s
2025-03-28 17:49:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 37.0132 ms
2025-03-28 17:49:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.7027 ms
2025-03-28 17:49:42 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 17:49:42 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54800 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 17:49:42 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:49:42 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 17:49:42 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:49:42 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1908 bytes result sent to driver
2025-03-28 17:49:42 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on YAU (executor driver) (1/1)
2025-03-28 17:49:42 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.053 s
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:49:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 17:49:42 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.057653 s
2025-03-28 17:49:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.0291 ms
2025-03-28 17:49:42 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 17:49:43 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:43 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:43 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:43 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:43 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:43 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:43 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:43 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.067 ms
2025-03-28 17:49:43 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at mysql_config_project.scala:49)
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 77.7 KiB, free 4.5 GiB)
2025-03-28 17:49:43 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54800 (size: 77.7 KiB, free: 4.5 GiB)
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:49:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 17:49:43 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-28 17:49:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281749431129521142377382300_0002_m_000000_2' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503281749431129521142377382300_0002_m_000000
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281749431129521142377382300_0002_m_000000_2: Committed. Elapsed time: 8 ms.
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2785 bytes result sent to driver
2025-03-28 17:49:44 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1150 ms on YAU (executor driver) (1/1)
2025-03-28 17:49:44 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at mysql_config_project.scala:49) finished in 1.220 s
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 17:49:44 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at mysql_config_project.scala:49, took 1.225560 s
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job b1592ac2-635d-4af4-b163-d3af2b5e60eb.
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job b1592ac2-635d-4af4-b163-d3af2b5e60eb committed. Elapsed time: 26 ms.
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job b1592ac2-635d-4af4-b163-d3af2b5e60eb.
2025-03-28 17:49:44 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:44 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.0493 ms
2025-03-28 17:49:44 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at mysql_config_project.scala:49)
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.8 KiB, free 4.5 GiB)
2025-03-28 17:49:44 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54800 (size: 76.8 KiB, free: 4.5 GiB)
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 17:49:44 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-28 17:49:44 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:54800 in memory (size: 77.7 KiB, free: 4.5 GiB)
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:49:44 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:54800 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:49:44 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:54800 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281749447482934067166743495_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503281749447482934067166743495_0003_m_000000
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281749447482934067166743495_0003_m_000000_3: Committed. Elapsed time: 6 ms.
2025-03-28 17:49:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2785 bytes result sent to driver
2025-03-28 17:49:44 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 224 ms on YAU (executor driver) (1/1)
2025-03-28 17:49:44 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at mysql_config_project.scala:49) finished in 0.253 s
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 17:49:44 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at mysql_config_project.scala:49, took 0.256872 s
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 0bac3abe-ca38-4a6c-85bd-b8d135e20e67.
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 0bac3abe-ca38-4a6c-85bd-b8d135e20e67 committed. Elapsed time: 21 ms.
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 0bac3abe-ca38-4a6c-85bd-b8d135e20e67.
2025-03-28 17:49:44 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:44 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:44 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.5515 ms
2025-03-28 17:49:44 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:49)
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:49:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:49:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-28 17:49:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-28 17:49:45 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:54800 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-28 17:49:45 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:49:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:49:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 17:49:45 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281749444879198353013778009_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503281749444879198353013778009_0004_m_000000
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281749444879198353013778009_0004_m_000000_4: Committed. Elapsed time: 5 ms.
2025-03-28 17:49:45 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2742 bytes result sent to driver
2025-03-28 17:49:45 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 903 ms on YAU (executor driver) (1/1)
2025-03-28 17:49:45 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 17:49:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:49) finished in 0.932 s
2025-03-28 17:49:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:49:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 17:49:45 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:49, took 0.935330 s
2025-03-28 17:49:45 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job aa72b20a-2918-4ac5-9564-a80d7a480c54.
2025-03-28 17:49:45 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job aa72b20a-2918-4ac5-9564-a80d7a480c54 committed. Elapsed time: 16 ms.
2025-03-28 17:49:45 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job aa72b20a-2918-4ac5-9564-a80d7a480c54.
2025-03-28 17:49:45 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 17:49:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.6917 ms
2025-03-28 17:49:46 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at mysql_config_project.scala:52)
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 17:49:46 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:54800 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 17:49:46 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:49:46 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 17:49:46 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:49:46 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 4233 bytes result sent to driver
2025-03-28 17:49:46 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on YAU (executor driver) (1/1)
2025-03-28 17:49:46 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at mysql_config_project.scala:52) finished in 0.040 s
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 17:49:46 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at mysql_config_project.scala:52, took 0.043878 s
2025-03-28 17:49:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.4841 ms
2025-03-28 17:49:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 36.3058 ms
2025-03-28 17:49:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.5462 ms
2025-03-28 17:49:46 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:59
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (first at mysql_config_project.scala:59) with 1 output partitions
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (first at mysql_config_project.scala:59)
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:59), which has no missing parents
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 17:49:46 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:54800 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:59) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-28 17:49:46 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:49:46 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-28 17:49:46 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:49:46 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1648 bytes result sent to driver
2025-03-28 17:49:46 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 101 ms on YAU (executor driver) (1/1)
2025-03-28 17:49:46 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (first at mysql_config_project.scala:59) finished in 0.111 s
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:49:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-28 17:49:46 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: first at mysql_config_project.scala:59, took 0.116238 s
2025-03-28 17:49:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.4351 ms
2025-03-28 17:49:46 [main] INFO  task1.mysql_config_project$ - ERROR IS Unable to parse date string: 2025-03-26 02:53:31
2025-03-28 17:49:46 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 17:49:46 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:49:46 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 17:49:46 [dispatcher-event-loop-15] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 17:49:46 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 17:49:46 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 17:49:46 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 17:49:46 [dispatcher-event-loop-4] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 17:49:46 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 17:49:46 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 17:49:46 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-f723856b-a032-49cb-892f-8ea29c3d0de8
2025-03-28 17:51:09 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 17:51:10 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:51:10 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 17:51:10 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 17:51:10 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 17:51:10 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 17:51:10 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 17:51:10 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54863.
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 17:51:10 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 17:51:10 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 17:51:10 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-fbed2556-c487-40b9-b3b4-f4b591aaa04a
2025-03-28 17:51:10 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 17:51:10 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 17:51:11 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2541ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 17:51:11 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 17:51:11 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 17:51:11 [main] INFO  o.sparkproject.jetty.server.Server - Started @2666ms
2025-03-28 17:51:11 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:51:11 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 17:51:11 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 17:51:11 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54914.
2025-03-28 17:51:11 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54914
2025-03-28 17:51:11 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 17:51:11 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54914, None)
2025-03-28 17:51:11 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54914 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54914, None)
2025-03-28 17:51:11 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54914, None)
2025-03-28 17:51:11 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54914, None)
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@655f69da{/jobs,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@28369db0{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@590f0c50{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/stages,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cf78c85{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5befbac1{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a565afb{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/storage,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/environment,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/executors,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/static,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24a2e565{/,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60c1663c{/api,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3178219a{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56476c16{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b13467c{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 17:51:11 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 17:51:11 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 17:51:11 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@daf22f0{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d299393{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 17:51:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0e9707{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 17:51:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 260.3236 ms
2025-03-28 17:51:16 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 17:51:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54914 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 17:51:16 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:51:16 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 17:51:16 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:51:16 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 17:51:16 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 192 ms on YAU (executor driver) (1/1)
2025-03-28 17:51:16 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.494 s
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:51:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 17:51:16 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.534071 s
2025-03-28 17:51:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.6801 ms
2025-03-28 17:51:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.693 ms
2025-03-28 17:51:17 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 17:51:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54914 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 17:51:17 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:51:17 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 17:51:17 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:51:17 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 17:51:17 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 38 ms on YAU (executor driver) (1/1)
2025-03-28 17:51:17 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.048 s
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 17:51:17 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.051401 s
2025-03-28 17:51:17 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 23.7397 ms
2025-03-28 17:51:17 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 17:51:17 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:17 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:17 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:17 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:17 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:17 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:17 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:17 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.3315 ms
2025-03-28 17:51:17 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at mysql_config_project.scala:49)
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-28 17:51:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54914 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:51:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 17:51:17 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:51:17 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 17:51:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:54914 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:51:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:54914 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-28 17:51:18 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281751176729687658089572497_0002_m_000000_2' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503281751176729687658089572497_0002_m_000000
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281751176729687658089572497_0002_m_000000_2: Committed. Elapsed time: 10 ms.
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2785 bytes result sent to driver
2025-03-28 17:51:19 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1051 ms on YAU (executor driver) (1/1)
2025-03-28 17:51:19 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at mysql_config_project.scala:49) finished in 1.108 s
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 17:51:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at mysql_config_project.scala:49, took 1.113076 s
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job c8f2a853-4c05-4867-8054-1425b723beaa.
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job c8f2a853-4c05-4867-8054-1425b723beaa committed. Elapsed time: 27 ms.
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job c8f2a853-4c05-4867-8054-1425b723beaa.
2025-03-28 17:51:19 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:19 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:19 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.9361 ms
2025-03-28 17:51:19 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at mysql_config_project.scala:49)
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-28 17:51:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54914 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 17:51:19 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281751192666478780332542054_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503281751192666478780332542054_0003_m_000000
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281751192666478780332542054_0003_m_000000_3: Committed. Elapsed time: 6 ms.
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2742 bytes result sent to driver
2025-03-28 17:51:19 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 194 ms on YAU (executor driver) (1/1)
2025-03-28 17:51:19 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at mysql_config_project.scala:49) finished in 0.227 s
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 17:51:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at mysql_config_project.scala:49, took 0.231230 s
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 9c9782c7-ed8e-4637-a409-1282254fc735.
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 9c9782c7-ed8e-4637-a409-1282254fc735 committed. Elapsed time: 20 ms.
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 9c9782c7-ed8e-4637-a409-1282254fc735.
2025-03-28 17:51:19 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:19 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:19 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:19 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.8767 ms
2025-03-28 17:51:19 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:49)
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-28 17:51:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:54914 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:51:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 17:51:19 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:51:19 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-28 17:51:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:54914 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 17:51:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:54914 in memory (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281751198329404856213864140_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503281751198329404856213864140_0004_m_000000
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281751198329404856213864140_0004_m_000000_4: Committed. Elapsed time: 5 ms.
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2742 bytes result sent to driver
2025-03-28 17:51:20 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 924 ms on YAU (executor driver) (1/1)
2025-03-28 17:51:20 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:49) finished in 0.961 s
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 17:51:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:49, took 0.966165 s
2025-03-28 17:51:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 7c4ec6b3-1826-417f-a3ed-2b3dc1b01768.
2025-03-28 17:51:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 7c4ec6b3-1826-417f-a3ed-2b3dc1b01768 committed. Elapsed time: 14 ms.
2025-03-28 17:51:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 7c4ec6b3-1826-417f-a3ed-2b3dc1b01768.
2025-03-28 17:51:20 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 17:51:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.5904 ms
2025-03-28 17:51:20 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at mysql_config_project.scala:52)
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 17:51:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:54914 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 17:51:20 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 4233 bytes result sent to driver
2025-03-28 17:51:20 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 35 ms on YAU (executor driver) (1/1)
2025-03-28 17:51:20 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at mysql_config_project.scala:52) finished in 0.045 s
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 17:51:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at mysql_config_project.scala:52, took 0.048178 s
2025-03-28 17:51:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.8323 ms
2025-03-28 17:51:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.04 ms
2025-03-28 17:51:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.7939 ms
2025-03-28 17:51:20 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:59
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (first at mysql_config_project.scala:59) with 1 output partitions
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (first at mysql_config_project.scala:59)
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:59), which has no missing parents
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 17:51:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:54914 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:59) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-28 17:51:20 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:51:20 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1648 bytes result sent to driver
2025-03-28 17:51:20 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 60 ms on YAU (executor driver) (1/1)
2025-03-28 17:51:20 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (first at mysql_config_project.scala:59) finished in 0.071 s
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:51:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-28 17:51:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: first at mysql_config_project.scala:59, took 0.074612 s
2025-03-28 17:51:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.5161 ms
2025-03-28 17:51:20 [main] INFO  task1.mysql_config_project$ - ERROR IS Unable to parse date string: 2025-03-26 02:53:31
2025-03-28 17:51:20 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 17:51:20 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:51:20 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 17:51:20 [dispatcher-event-loop-15] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 17:51:20 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 17:51:20 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 17:51:20 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 17:51:20 [dispatcher-event-loop-0] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 17:51:20 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 17:51:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 17:51:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-050699d4-71c0-4963-9651-950874831f87
2025-03-28 17:53:50 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 17:53:50 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:53:50 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 17:53:50 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:53:50 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 17:53:50 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 17:53:50 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 17:53:50 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 17:53:50 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 17:53:50 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 17:53:50 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 17:53:50 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 17:53:50 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 17:53:51 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54981.
2025-03-28 17:53:51 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 17:53:51 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 17:53:51 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 17:53:51 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 17:53:51 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 17:53:51 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-a9a2088c-1bcb-4ef6-b0b8-11f320caa0ea
2025-03-28 17:53:51 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 17:53:51 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 17:53:51 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2604ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 17:53:51 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 17:53:51 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 17:53:51 [main] INFO  o.sparkproject.jetty.server.Server - Started @2740ms
2025-03-28 17:53:51 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:53:51 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 17:53:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 17:53:51 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 17:53:51 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 17:53:51 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55032.
2025-03-28 17:53:51 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55032
2025-03-28 17:53:51 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 17:53:51 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55032, None)
2025-03-28 17:53:51 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55032 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55032, None)
2025-03-28 17:53:51 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55032, None)
2025-03-28 17:53:51 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55032, None)
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 17:53:52 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 17:53:52 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 17:53:52 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 17:53:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 17:53:56 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 276.1651 ms
2025-03-28 17:53:56 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 17:53:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 17:53:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 17:53:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:53:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:53:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 17:53:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 17:53:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55032 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 17:53:57 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:53:57 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 17:53:57 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:53:57 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 17:53:57 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 193 ms on YAU (executor driver) (1/1)
2025-03-28 17:53:57 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.484 s
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 17:53:57 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.528619 s
2025-03-28 17:53:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.5947 ms
2025-03-28 17:53:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.3634 ms
2025-03-28 17:53:57 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 17:53:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55032 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 17:53:57 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:53:57 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 17:53:57 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:53:57 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 17:53:57 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-28 17:53:57 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.044 s
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:53:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 17:53:57 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.048272 s
2025-03-28 17:53:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.2589 ms
2025-03-28 17:53:57 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 17:53:58 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:58 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:58 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:58 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:58 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:58 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:58 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.0525 ms
2025-03-28 17:53:58 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at mysql_config_project.scala:49)
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-28 17:53:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55032 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:53:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 17:53:58 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-28 17:53:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281753581709426225035969733_0002_m_000000_2' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503281753581709426225035969733_0002_m_000000
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281753581709426225035969733_0002_m_000000_2: Committed. Elapsed time: 8 ms.
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2785 bytes result sent to driver
2025-03-28 17:53:59 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1011 ms on YAU (executor driver) (1/1)
2025-03-28 17:53:59 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at mysql_config_project.scala:49) finished in 1.063 s
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 17:53:59 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at mysql_config_project.scala:49, took 1.067730 s
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job eac029a9-d5f9-4c4b-bade-35c1f2a80aa0.
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job eac029a9-d5f9-4c4b-bade-35c1f2a80aa0 committed. Elapsed time: 30 ms.
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job eac029a9-d5f9-4c4b-bade-35c1f2a80aa0.
2025-03-28 17:53:59 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:59 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:59 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:59 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:59 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.0533 ms
2025-03-28 17:53:59 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at mysql_config_project.scala:49)
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-28 17:53:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55032 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 17:53:59 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 17:53:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:55032 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:53:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:55032 in memory (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 17:53:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:55032 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281753593078427437877539283_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503281753593078427437877539283_0003_m_000000
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281753593078427437877539283_0003_m_000000_3: Committed. Elapsed time: 6 ms.
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2785 bytes result sent to driver
2025-03-28 17:53:59 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 218 ms on YAU (executor driver) (1/1)
2025-03-28 17:53:59 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at mysql_config_project.scala:49) finished in 0.265 s
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 17:53:59 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at mysql_config_project.scala:49, took 0.268770 s
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 21905771-12d2-455e-bb60-9fb2bd957971.
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 21905771-12d2-455e-bb60-9fb2bd957971 committed. Elapsed time: 21 ms.
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 21905771-12d2-455e-bb60-9fb2bd957971.
2025-03-28 17:53:59 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:59 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:59 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:59 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:53:59 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:53:59 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:53:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.4491 ms
2025-03-28 17:53:59 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:49)
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-28 17:53:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:55032 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:53:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 17:53:59 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:53:59 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281753596260601746210396289_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503281753596260601746210396289_0004_m_000000
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281753596260601746210396289_0004_m_000000_4: Committed. Elapsed time: 5 ms.
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2742 bytes result sent to driver
2025-03-28 17:54:00 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 894 ms on YAU (executor driver) (1/1)
2025-03-28 17:54:00 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:49) finished in 0.924 s
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 17:54:00 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:49, took 0.928650 s
2025-03-28 17:54:00 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 1da0a2dd-234f-4686-85d5-50817b92a632.
2025-03-28 17:54:00 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 1da0a2dd-234f-4686-85d5-50817b92a632 committed. Elapsed time: 14 ms.
2025-03-28 17:54:00 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 1da0a2dd-234f-4686-85d5-50817b92a632.
2025-03-28 17:54:00 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 17:54:00 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.7897 ms
2025-03-28 17:54:00 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at mysql_config_project.scala:52)
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 17:54:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:55032 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 17:54:00 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 17:54:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on YAU:55032 in memory (size: 77.2 KiB, free: 4.5 GiB)
2025-03-28 17:54:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:55032 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:54:00 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 4319 bytes result sent to driver
2025-03-28 17:54:00 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 49 ms on YAU (executor driver) (1/1)
2025-03-28 17:54:00 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at mysql_config_project.scala:52) finished in 0.059 s
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:54:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 17:54:00 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at mysql_config_project.scala:52, took 0.062149 s
2025-03-28 17:54:00 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.8853 ms
2025-03-28 17:54:01 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.981 ms
2025-03-28 17:54:01 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.1269 ms
2025-03-28 17:54:01 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (first at mysql_config_project.scala:60)
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 17:54:01 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:55032 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-28 17:54:01 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:54:01 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-28 17:54:01 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:54:01 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1648 bytes result sent to driver
2025-03-28 17:54:01 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 62 ms on YAU (executor driver) (1/1)
2025-03-28 17:54:01 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (first at mysql_config_project.scala:60) finished in 0.070 s
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:54:01 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-28 17:54:01 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: first at mysql_config_project.scala:60, took 0.074087 s
2025-03-28 17:54:01 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.3221 ms
2025-03-28 17:54:01 [main] INFO  task1.mysql_config_project$ - ERROR IS Unable to parse date string: 2025-03-26 02:53:31
2025-03-28 17:54:01 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 17:54:01 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:54:01 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 17:54:01 [dispatcher-event-loop-15] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 17:54:01 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 17:54:01 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 17:54:01 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 17:54:01 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 17:54:01 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 17:54:01 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 17:54:01 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-a1054bc1-137f-4f96-9f5e-285215783413
2025-03-28 17:58:57 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 17:58:57 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:58:57 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 17:58:57 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 17:58:57 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 17:58:57 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 17:58:57 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 17:58:57 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 17:58:57 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 17:58:57 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 17:58:57 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 17:58:57 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 17:58:57 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 17:58:58 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55106.
2025-03-28 17:58:58 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 17:58:58 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 17:58:58 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 17:58:58 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 17:58:58 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 17:58:58 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-3eb7c588-3710-43ba-9bc3-9228b09101a2
2025-03-28 17:58:58 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 17:58:58 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 17:58:58 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2609ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 17:58:58 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 17:58:58 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 17:58:58 [main] INFO  o.sparkproject.jetty.server.Server - Started @2741ms
2025-03-28 17:58:58 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:58:58 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 17:58:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 17:58:58 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 17:58:58 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 17:58:58 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55157.
2025-03-28 17:58:58 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55157
2025-03-28 17:58:58 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 17:58:58 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55157, None)
2025-03-28 17:58:58 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55157 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55157, None)
2025-03-28 17:58:58 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55157, None)
2025-03-28 17:58:58 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55157, None)
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 17:58:59 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 17:58:59 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 17:58:59 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 17:58:59 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 17:59:03 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 287.7015 ms
2025-03-28 17:59:03 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 17:59:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 17:59:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 17:59:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:59:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:59:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 17:59:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 17:59:04 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55157 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 17:59:04 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 17:59:04 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 198 ms on YAU (executor driver) (1/1)
2025-03-28 17:59:04 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.494 s
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 17:59:04 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.534970 s
2025-03-28 17:59:04 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 44.1389 ms
2025-03-28 17:59:04 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.6518 ms
2025-03-28 17:59:04 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 17:59:04 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55157 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 17:59:04 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 17:59:04 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on YAU (executor driver) (1/1)
2025-03-28 17:59:04 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.047 s
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 17:59:04 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.051593 s
2025-03-28 17:59:04 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.4127 ms
2025-03-28 17:59:04 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 17:59:04 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 17:59:04 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 17:59:04 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 17:59:04 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.6812 ms
2025-03-28 17:59:04 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:52)
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 17:59:04 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55157 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 17:59:04 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:59:04 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 4233 bytes result sent to driver
2025-03-28 17:59:04 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 53 ms on YAU (executor driver) (1/1)
2025-03-28 17:59:04 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:52) finished in 0.067 s
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:59:04 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 17:59:04 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:52, took 0.072566 s
2025-03-28 17:59:04 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.8213 ms
2025-03-28 17:59:04 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.631 ms
2025-03-28 17:59:04 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.7679 ms
2025-03-28 17:59:05 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (first at mysql_config_project.scala:60)
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 17:59:05 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55157 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 17:59:05 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 17:59:05 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 17:59:05 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 17:59:05 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1648 bytes result sent to driver
2025-03-28 17:59:05 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 88 ms on YAU (executor driver) (1/1)
2025-03-28 17:59:05 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (first at mysql_config_project.scala:60) finished in 0.101 s
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 17:59:05 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 17:59:05 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: first at mysql_config_project.scala:60, took 0.103989 s
2025-03-28 17:59:05 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.3192 ms
2025-03-28 17:59:05 [main] INFO  task1.mysql_config_project$ - ERROR IS Unable to parse date string: 2025-03-26 02:53:31
2025-03-28 17:59:05 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 17:59:05 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 17:59:05 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 17:59:05 [dispatcher-event-loop-4] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 17:59:05 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 17:59:05 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 17:59:05 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 17:59:05 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 17:59:05 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 17:59:05 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 17:59:05 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-ce8cc0ef-f6bd-4074-ada7-a7cf3c1027cc
2025-03-28 18:00:33 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:00:34 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:00:34 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:00:34 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:00:34 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:00:34 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:00:34 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:00:34 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55222.
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:00:34 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:00:34 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:00:34 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:00:34 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-503af462-8255-4899-931f-17f3a29da235
2025-03-28 18:00:35 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:00:35 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:00:35 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2514ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:00:35 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:00:35 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:00:35 [main] INFO  o.sparkproject.jetty.server.Server - Started @2633ms
2025-03-28 18:00:35 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:00:35 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:00:35 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:00:35 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55273.
2025-03-28 18:00:35 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55273
2025-03-28 18:00:35 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:00:35 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55273, None)
2025-03-28 18:00:35 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55273 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55273, None)
2025-03-28 18:00:35 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55273, None)
2025-03-28 18:00:35 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55273, None)
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:35 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:00:35 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:00:36 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:00:36 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:00:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:00:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:00:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:00:36 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:00:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 264.2038 ms
2025-03-28 18:00:40 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:00:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55273 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:00:40 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:00:40 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:00:40 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:00:40 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:00:40 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 198 ms on YAU (executor driver) (1/1)
2025-03-28 18:00:40 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.484 s
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:00:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:00:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.528008 s
2025-03-28 18:00:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.6112 ms
2025-03-28 18:00:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.9379 ms
2025-03-28 18:00:41 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:00:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55273 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:00:41 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 18:00:41 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on YAU (executor driver) (1/1)
2025-03-28 18:00:41 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.040 s
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:00:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.043454 s
2025-03-28 18:00:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.7885 ms
2025-03-28 18:00:41 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:00:41 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:00:41 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:00:41 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:00:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.0772 ms
2025-03-28 18:00:41 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:52)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:00:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55273 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:00:41 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 4233 bytes result sent to driver
2025-03-28 18:00:41 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 55 ms on YAU (executor driver) (1/1)
2025-03-28 18:00:41 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:52) finished in 0.068 s
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:00:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:52, took 0.072187 s
2025-03-28 18:00:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.7523 ms
2025-03-28 18:00:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.0414 ms
2025-03-28 18:00:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.666 ms
2025-03-28 18:00:41 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (first at mysql_config_project.scala:60)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:00:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55273 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:00:41 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:00:41 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1648 bytes result sent to driver
2025-03-28 18:00:41 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 101 ms on YAU (executor driver) (1/1)
2025-03-28 18:00:41 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (first at mysql_config_project.scala:60) finished in 0.122 s
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:00:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:00:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: first at mysql_config_project.scala:60, took 0.124825 s
2025-03-28 18:00:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.3641 ms
2025-03-28 18:00:41 [main] INFO  task1.mysql_config_project$ - ERROR IS Unable to parse date string: 2025-03-26 02:53:31
2025-03-28 18:00:41 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:00:41 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:00:41 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:00:41 [dispatcher-event-loop-2] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:00:41 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:00:41 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:00:41 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:00:41 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:00:41 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:00:41 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:00:41 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-614926e6-1ece-40e9-80d8-160dcf1cb576
2025-03-28 18:01:41 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:01:42 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:01:42 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:01:42 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:01:42 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:01:42 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:01:42 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:01:42 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:01:42 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:01:42 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:01:42 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:01:42 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:01:42 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:01:42 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55335.
2025-03-28 18:01:42 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:01:42 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:01:43 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:01:43 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:01:43 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:01:43 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-6feac645-f253-49de-b65d-9e2f781a6348
2025-03-28 18:01:43 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:01:43 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:01:43 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2571ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:01:43 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:01:43 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:01:43 [main] INFO  o.sparkproject.jetty.server.Server - Started @2698ms
2025-03-28 18:01:43 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@bb5c95e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:01:43 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cea0110{/,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:01:43 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:01:43 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55386.
2025-03-28 18:01:43 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55386
2025-03-28 18:01:43 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:01:43 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55386, None)
2025-03-28 18:01:43 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55386 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55386, None)
2025-03-28 18:01:43 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55386, None)
2025-03-28 18:01:43 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55386, None)
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7cea0110{/,null,STOPPED,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:43 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:01:43 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:01:44 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:01:44 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:01:44 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:01:44 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:44 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:01:44 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:01:44 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:01:48 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 331.3321 ms
2025-03-28 18:01:48 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:01:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:01:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:01:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:01:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:01:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:01:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:01:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:01:49 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55386 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:01:49 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:01:49 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 216 ms on YAU (executor driver) (1/1)
2025-03-28 18:01:49 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.523 s
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:01:49 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.581985 s
2025-03-28 18:01:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.2187 ms
2025-03-28 18:01:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.0621 ms
2025-03-28 18:01:49 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:01:49 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55386 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:01:49 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 18:01:49 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on YAU (executor driver) (1/1)
2025-03-28 18:01:49 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.047 s
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:01:49 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.049766 s
2025-03-28 18:01:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.5863 ms
2025-03-28 18:01:49 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:01:49 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:01:49 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:01:49 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:01:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.817 ms
2025-03-28 18:01:49 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:52)
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:01:49 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55386 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:01:49 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:01:49 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 4233 bytes result sent to driver
2025-03-28 18:01:49 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 58 ms on YAU (executor driver) (1/1)
2025-03-28 18:01:49 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:52) finished in 0.069 s
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:01:49 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:01:49 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:52, took 0.074074 s
2025-03-28 18:01:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.2672 ms
2025-03-28 18:01:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.4177 ms
2025-03-28 18:01:49 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.2691 ms
2025-03-28 18:01:50 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (first at mysql_config_project.scala:60)
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:01:50 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55386 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:01:50 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:01:50 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:01:50 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:01:50 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1648 bytes result sent to driver
2025-03-28 18:01:50 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 128 ms on YAU (executor driver) (1/1)
2025-03-28 18:01:50 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (first at mysql_config_project.scala:60) finished in 0.149 s
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:01:50 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:01:50 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: first at mysql_config_project.scala:60, took 0.153322 s
2025-03-28 18:01:50 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.7473 ms
2025-03-28 18:01:50 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-28 18:01:50 [main] INFO  functions.update_parquet$ - ########### UPDATE PARQUET FUNCTION #############
2025-03-28 18:01:50 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 21 ms to list leaf files for 1 paths.
2025-03-28 18:01:51 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (load at update_parquet.scala:18) with 1 output partitions
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (load at update_parquet.scala:18)
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:18), which has no missing parents
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 4.5 GiB)
2025-03-28 18:01:51 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:55386 (size: 36.9 KiB, free: 4.5 GiB)
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 18:01:51 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8877 bytes) 
2025-03-28 18:01:51 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 18:01:51 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 959 bytes result sent to driver
2025-03-28 18:01:51 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 67 ms on YAU (executor driver) (1/1)
2025-03-28 18:01:51 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (load at update_parquet.scala:18) finished in 0.092 s
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:01:51 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 18:01:51 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: load at update_parquet.scala:18, took 0.096309 s
2025-03-28 18:01:51 [main] INFO  task1.mysql_config_project$ - ERROR IS [UNABLE_TO_INFER_SCHEMA] Unable to infer schema for Parquet. It must be specified manually.
2025-03-28 18:01:51 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:01:51 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@bb5c95e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:01:51 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:01:51 [dispatcher-event-loop-1] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:01:51 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:01:51 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:01:51 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:01:51 [dispatcher-event-loop-10] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:01:51 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:01:51 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:01:51 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-e7858d90-4f9d-44e4-9483-36defa69a7bb
2025-03-28 18:19:25 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:19:25 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:19:25 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:19:25 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:19:25 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:19:25 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:19:25 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:19:25 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:19:25 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:19:25 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:19:25 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:19:25 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:19:25 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:19:26 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55529.
2025-03-28 18:19:26 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:19:26 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:19:26 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:19:26 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:19:26 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:19:26 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-b081d0a9-1ef0-47c9-9280-4d0c06675189
2025-03-28 18:19:26 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:19:26 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:19:26 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2499ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:19:26 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:19:26 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:19:26 [main] INFO  o.sparkproject.jetty.server.Server - Started @2634ms
2025-03-28 18:19:26 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:19:26 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:19:27 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:19:27 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55580.
2025-03-28 18:19:27 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55580
2025-03-28 18:19:27 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:19:27 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55580, None)
2025-03-28 18:19:27 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55580 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55580, None)
2025-03-28 18:19:27 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55580, None)
2025-03-28 18:19:27 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55580, None)
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@655f69da{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@28369db0{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@590f0c50{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cf78c85{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5befbac1{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a565afb{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/static,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24a2e565{/,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60c1663c{/api,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3178219a{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56476c16{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b13467c{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:19:27 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:19:27 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:19:27 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@daf22f0{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d299393{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:19:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0e9707{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:19:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 281.336 ms
2025-03-28 18:19:32 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:19:32 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55580 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:19:32 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:19:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:19:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:19:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:19:32 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 194 ms on YAU (executor driver) (1/1)
2025-03-28 18:19:32 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.458 s
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:19:32 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.494719 s
2025-03-28 18:19:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.9939 ms
2025-03-28 18:19:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.9409 ms
2025-03-28 18:19:32 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:19:32 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55580 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:19:32 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:19:32 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:19:32 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:19:32 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 18:19:32 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-28 18:19:32 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.045 s
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:19:32 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.048484 s
2025-03-28 18:19:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.6809 ms
2025-03-28 18:19:32 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:19:32 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:19:32 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:19:32 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:19:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.0922 ms
2025-03-28 18:19:32 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:52)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:19:32 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55580 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:19:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:19:32 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:19:32 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:19:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:19:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 4233 bytes result sent to driver
2025-03-28 18:19:33 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 58 ms on YAU (executor driver) (1/1)
2025-03-28 18:19:33 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:52) finished in 0.069 s
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:19:33 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:52, took 0.074077 s
2025-03-28 18:19:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.0764 ms
2025-03-28 18:19:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.4244 ms
2025-03-28 18:19:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.2597 ms
2025-03-28 18:19:33 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (first at mysql_config_project.scala:60)
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:19:33 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55580 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:19:33 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:19:33 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:19:33 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:19:33 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1648 bytes result sent to driver
2025-03-28 18:19:33 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 97 ms on YAU (executor driver) (1/1)
2025-03-28 18:19:33 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (first at mysql_config_project.scala:60) finished in 0.108 s
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:19:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:19:33 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: first at mysql_config_project.scala:60, took 0.114447 s
2025-03-28 18:19:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.116 ms
2025-03-28 18:19:33 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-28 18:19:33 [main] INFO  functions.update_parquet$ - ########### UPDATE PARQUET FUNCTION #############
2025-03-28 18:19:33 [main] INFO  task1.mysql_config_project$ - ERROR IS >>>>>>>>>>>>>>>>>>>>> Wrong FS: hdfs://localhost:9000/user/sabil/transaction, expected: file:/// <<<<<<<<<<<<<<<<<
2025-03-28 18:19:33 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:19:33 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:19:33 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:19:33 [dispatcher-event-loop-2] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:19:33 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:19:33 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:19:33 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:19:33 [dispatcher-event-loop-8] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:19:33 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:19:33 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:19:33 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-da6f9cf6-1878-46bd-8ae3-86c305e86371
2025-03-28 18:21:49 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:21:50 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:21:50 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:21:50 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:21:50 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:21:50 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:21:50 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:21:50 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:21:50 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:21:50 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:21:50 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:21:50 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:21:50 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:21:51 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55636.
2025-03-28 18:21:51 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:21:51 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:21:51 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:21:51 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:21:51 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:21:51 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-e3968393-b37e-474d-be62-81eb731c89d7
2025-03-28 18:21:51 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:21:51 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:21:51 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2579ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:21:51 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:21:51 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:21:51 [main] INFO  o.sparkproject.jetty.server.Server - Started @2708ms
2025-03-28 18:21:51 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:21:51 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:21:51 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:21:51 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55687.
2025-03-28 18:21:51 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55687
2025-03-28 18:21:51 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:21:51 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55687, None)
2025-03-28 18:21:51 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55687 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55687, None)
2025-03-28 18:21:51 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55687, None)
2025-03-28 18:21:51 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55687, None)
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:21:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:52 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:21:52 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:21:52 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:21:52 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:21:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:21:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:21:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:21:52 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:21:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 461.8678 ms
2025-03-28 18:21:57 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:21:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55687 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:21:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:21:57 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:21:57 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:21:58 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:21:58 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:21:58 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 269 ms on YAU (executor driver) (1/1)
2025-03-28 18:21:58 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.701 s
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:21:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.765005 s
2025-03-28 18:21:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 43.597 ms
2025-03-28 18:21:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.7968 ms
2025-03-28 18:21:58 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:21:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55687 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:21:58 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:21:58 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:21:58 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:21:58 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1951 bytes result sent to driver
2025-03-28 18:21:58 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 55 ms on YAU (executor driver) (1/1)
2025-03-28 18:21:58 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.072 s
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:21:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.077427 s
2025-03-28 18:21:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 39.0157 ms
2025-03-28 18:21:58 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:21:58 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:21:58 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:21:58 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:21:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.331 ms
2025-03-28 18:21:58 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:52)
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:21:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55687 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:21:58 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:21:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:21:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:21:58 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 4276 bytes result sent to driver
2025-03-28 18:21:58 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 84 ms on YAU (executor driver) (1/1)
2025-03-28 18:21:58 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:52) finished in 0.103 s
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:21:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:21:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:52, took 0.109465 s
2025-03-28 18:21:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.1277 ms
2025-03-28 18:21:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 34.2903 ms
2025-03-28 18:21:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.9002 ms
2025-03-28 18:21:59 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (first at mysql_config_project.scala:60)
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:21:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55687 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:21:59 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:21:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:21:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:21:59 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1648 bytes result sent to driver
2025-03-28 18:21:59 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 137 ms on YAU (executor driver) (1/1)
2025-03-28 18:21:59 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (first at mysql_config_project.scala:60) finished in 0.160 s
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:21:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:21:59 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: first at mysql_config_project.scala:60, took 0.167555 s
2025-03-28 18:21:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.9771 ms
2025-03-28 18:21:59 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-28 18:21:59 [main] INFO  functions.update_parquet$ - ########### UPDATE PARQUET FUNCTION #############
2025-03-28 18:22:00 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 24 ms to list leaf files for 1 paths.
2025-03-28 18:22:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:55687 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:22:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:55687 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:22:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:55687 in memory (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:22:00 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:37
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (load at update_parquet.scala:37) with 1 output partitions
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (load at update_parquet.scala:37)
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:37), which has no missing parents
2025-03-28 18:22:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:55687 in memory (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 103.1 KiB, free 4.5 GiB)
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 4.5 GiB)
2025-03-28 18:22:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:55687 (size: 37.0 KiB, free: 4.5 GiB)
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:37) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 18:22:00 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8877 bytes) 
2025-03-28 18:22:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 18:22:00 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 959 bytes result sent to driver
2025-03-28 18:22:00 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 39 ms on YAU (executor driver) (1/1)
2025-03-28 18:22:00 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (load at update_parquet.scala:37) finished in 0.058 s
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:22:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 18:22:00 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: load at update_parquet.scala:37, took 0.061988 s
2025-03-28 18:22:00 [main] INFO  task1.mysql_config_project$ - ERROR IS >>>>>>>>>>>>>>>>>>>>> [UNABLE_TO_INFER_SCHEMA] Unable to infer schema for Parquet. It must be specified manually. <<<<<<<<<<<<<<<<<
2025-03-28 18:22:00 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:22:00 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:22:00 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:22:00 [dispatcher-event-loop-6] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:22:00 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:22:00 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:22:00 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:22:00 [dispatcher-event-loop-13] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:22:00 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:22:00 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:22:00 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-b0a373bd-0bd5-471a-8d1b-e0b941e55a2a
2025-03-28 18:24:19 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:24:19 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:24:19 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:24:19 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:24:19 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:24:19 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:24:19 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:24:19 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:24:19 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:24:19 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:24:19 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:24:19 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:24:19 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:24:20 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55749.
2025-03-28 18:24:20 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:24:20 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:24:20 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:24:20 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:24:20 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:24:20 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-36bcdc35-08cb-4d75-81de-9532b55702fd
2025-03-28 18:24:20 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:24:20 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:24:20 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2529ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:24:20 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:24:20 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:24:20 [main] INFO  o.sparkproject.jetty.server.Server - Started @2674ms
2025-03-28 18:24:21 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:24:21 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:24:21 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:24:21 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55800.
2025-03-28 18:24:21 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55800
2025-03-28 18:24:21 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:24:21 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55800, None)
2025-03-28 18:24:21 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55800 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55800, None)
2025-03-28 18:24:21 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55800, None)
2025-03-28 18:24:21 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55800, None)
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:24:21 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:24:21 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:24:21 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:24:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:24:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 462.5169 ms
2025-03-28 18:24:26 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:24:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:24:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:24:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:24:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:24:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:24:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55800 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:24:27 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:24:27 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:24:27 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:24:27 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:24:27 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 252 ms on YAU (executor driver) (1/1)
2025-03-28 18:24:27 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.647 s
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:24:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.709858 s
2025-03-28 18:24:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 33.8236 ms
2025-03-28 18:24:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 18.5668 ms
2025-03-28 18:24:27 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:24:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55800 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:24:27 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:24:27 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:24:27 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:24:27 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1951 bytes result sent to driver
2025-03-28 18:24:27 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on YAU (executor driver) (1/1)
2025-03-28 18:24:27 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.052 s
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:24:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.055443 s
2025-03-28 18:24:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.8568 ms
2025-03-28 18:24:27 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:24:27 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:24:27 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:24:27 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:24:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.4531 ms
2025-03-28 18:24:27 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:52)
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:24:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55800 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:24:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:24:27 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:24:27 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:24:28 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:24:28 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 4233 bytes result sent to driver
2025-03-28 18:24:28 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 56 ms on YAU (executor driver) (1/1)
2025-03-28 18:24:28 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:52) finished in 0.071 s
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:24:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:52, took 0.074918 s
2025-03-28 18:24:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.337 ms
2025-03-28 18:24:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.0474 ms
2025-03-28 18:24:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.5735 ms
2025-03-28 18:24:28 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (first at mysql_config_project.scala:60)
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:24:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55800 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:24:28 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:24:28 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:24:28 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:24:28 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1648 bytes result sent to driver
2025-03-28 18:24:28 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 93 ms on YAU (executor driver) (1/1)
2025-03-28 18:24:28 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (first at mysql_config_project.scala:60) finished in 0.110 s
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:24:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:24:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: first at mysql_config_project.scala:60, took 0.115052 s
2025-03-28 18:24:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.02 ms
2025-03-28 18:24:28 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-28 18:24:28 [main] INFO  functions.update_parquet$ - ########### UPDATE PARQUET FUNCTION #############
2025-03-28 18:24:28 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 34 ms to list leaf files for 1 paths.
2025-03-28 18:24:29 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:40
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (load at update_parquet.scala:40) with 1 output partitions
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (load at update_parquet.scala:40)
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:40), which has no missing parents
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 103.1 KiB, free 4.5 GiB)
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 4.5 GiB)
2025-03-28 18:24:29 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:55800 (size: 37.0 KiB, free: 4.5 GiB)
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:40) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 18:24:29 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8877 bytes) 
2025-03-28 18:24:29 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 18:24:29 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 959 bytes result sent to driver
2025-03-28 18:24:29 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 40 ms on YAU (executor driver) (1/1)
2025-03-28 18:24:29 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (load at update_parquet.scala:40) finished in 0.056 s
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:24:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 18:24:29 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: load at update_parquet.scala:40, took 0.060908 s
2025-03-28 18:24:29 [main] INFO  task1.mysql_config_project$ - ERROR IS >>>>>>>>>>>>>>>>>>>>> [UNABLE_TO_INFER_SCHEMA] Unable to infer schema for Parquet. It must be specified manually. <<<<<<<<<<<<<<<<<
2025-03-28 18:24:29 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:24:29 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:24:29 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:24:29 [dispatcher-event-loop-6] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:24:29 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:24:29 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:24:29 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:24:29 [dispatcher-event-loop-10] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:24:29 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:24:29 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:24:29 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-dcf25fec-5a12-47ef-96e5-11e7b14ca213
2025-03-28 18:25:32 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:25:32 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:25:32 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:25:32 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:25:32 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:25:32 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:25:32 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:25:32 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:25:32 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:25:32 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:25:32 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:25:32 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:25:32 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:25:33 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55868.
2025-03-28 18:25:33 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:25:33 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:25:33 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:25:33 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:25:33 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:25:33 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-db06e56f-fbe0-4138-a889-ad5a9c1702ad
2025-03-28 18:25:33 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:25:33 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:25:33 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2668ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:25:33 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:25:33 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:25:33 [main] INFO  o.sparkproject.jetty.server.Server - Started @2808ms
2025-03-28 18:25:33 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:25:33 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:25:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 18:25:33 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:25:33 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:25:33 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55919.
2025-03-28 18:25:33 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55919
2025-03-28 18:25:33 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:25:33 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55919, None)
2025-03-28 18:25:33 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55919 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55919, None)
2025-03-28 18:25:34 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55919, None)
2025-03-28 18:25:34 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55919, None)
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:25:34 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:25:34 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:25:34 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:25:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:25:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 287.954 ms
2025-03-28 18:25:39 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:25:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55919 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:25:39 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:25:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:25:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:25:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:25:39 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 225 ms on YAU (executor driver) (1/1)
2025-03-28 18:25:39 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.530 s
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:25:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.574663 s
2025-03-28 18:25:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 34.8416 ms
2025-03-28 18:25:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.2922 ms
2025-03-28 18:25:39 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:25:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55919 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:25:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:25:39 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:25:39 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:25:40 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:25:40 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 18:25:40 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on YAU (executor driver) (1/1)
2025-03-28 18:25:40 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.045 s
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:25:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.047788 s
2025-03-28 18:25:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.687 ms
2025-03-28 18:25:40 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:25:40 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:25:40 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:25:40 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:25:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.9056 ms
2025-03-28 18:25:40 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:52)
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:25:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55919 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:25:40 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:25:40 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:25:40 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:25:40 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 4276 bytes result sent to driver
2025-03-28 18:25:40 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on YAU (executor driver) (1/1)
2025-03-28 18:25:40 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:52) finished in 0.074 s
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:25:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:52, took 0.078821 s
2025-03-28 18:25:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.1586 ms
2025-03-28 18:25:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.9048 ms
2025-03-28 18:25:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.6583 ms
2025-03-28 18:25:40 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (first at mysql_config_project.scala:60)
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:25:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55919 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:25:40 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:25:40 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:25:40 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:25:40 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1648 bytes result sent to driver
2025-03-28 18:25:40 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 103 ms on YAU (executor driver) (1/1)
2025-03-28 18:25:40 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (first at mysql_config_project.scala:60) finished in 0.112 s
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:25:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:25:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: first at mysql_config_project.scala:60, took 0.115711 s
2025-03-28 18:25:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.16 ms
2025-03-28 18:25:40 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-28 18:25:40 [main] INFO  functions.update_parquet$ - ########### UPDATE PARQUET FUNCTION #############
2025-03-28 18:25:41 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 24 ms to list leaf files for 1 paths.
2025-03-28 18:25:41 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:42
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (load at update_parquet.scala:42) with 1 output partitions
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (load at update_parquet.scala:42)
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:42), which has no missing parents
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 103.1 KiB, free 4.5 GiB)
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 4.5 GiB)
2025-03-28 18:25:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:55919 (size: 37.0 KiB, free: 4.5 GiB)
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:42) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 18:25:41 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8877 bytes) 
2025-03-28 18:25:41 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 18:25:41 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 916 bytes result sent to driver
2025-03-28 18:25:41 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 46 ms on YAU (executor driver) (1/1)
2025-03-28 18:25:41 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (load at update_parquet.scala:42) finished in 0.064 s
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:25:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 18:25:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: load at update_parquet.scala:42, took 0.071836 s
2025-03-28 18:25:41 [main] INFO  task1.mysql_config_project$ - ERROR IS >>>>>>>>>>>>>>>>>>>>> [UNABLE_TO_INFER_SCHEMA] Unable to infer schema for Parquet. It must be specified manually. <<<<<<<<<<<<<<<<<
2025-03-28 18:25:41 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:25:41 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:25:41 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:25:41 [dispatcher-event-loop-6] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:25:41 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:25:41 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:25:41 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:25:41 [dispatcher-event-loop-10] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:25:41 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:25:41 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:25:41 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-883156e5-c520-4222-9f12-96806bbea9d8
2025-03-28 18:29:38 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:29:38 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:29:38 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:29:38 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:29:38 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:29:38 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:29:38 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:29:38 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:29:38 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:29:38 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:29:38 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:29:38 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:29:38 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:29:39 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55987.
2025-03-28 18:29:39 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:29:39 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:29:39 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:29:39 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:29:39 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:29:39 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-b8bbe1db-9b1c-4143-b03c-3d263df06351
2025-03-28 18:29:39 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:29:39 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:29:39 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2707ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:29:39 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:29:39 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:29:39 [main] INFO  o.sparkproject.jetty.server.Server - Started @2843ms
2025-03-28 18:29:39 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:29:39 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:29:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:29:40 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:29:40 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56038.
2025-03-28 18:29:40 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:56038
2025-03-28 18:29:40 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:29:40 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 56038, None)
2025-03-28 18:29:40 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:56038 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 56038, None)
2025-03-28 18:29:40 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 56038, None)
2025-03-28 18:29:40 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 56038, None)
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:29:40 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:29:40 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:29:40 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:29:40 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:29:45 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 293.5508 ms
2025-03-28 18:29:45 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:29:45 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:56038 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:29:45 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:29:45 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:29:45 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:29:45 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:29:45 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 221 ms on YAU (executor driver) (1/1)
2025-03-28 18:29:45 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.540 s
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:29:45 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.596065 s
2025-03-28 18:29:45 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.5884 ms
2025-03-28 18:29:45 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.5498 ms
2025-03-28 18:29:45 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:29:45 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:56038 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:29:45 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:29:45 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:29:45 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:29:45 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 18:29:45 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-28 18:29:45 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.044 s
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:29:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:29:45 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.046805 s
2025-03-28 18:29:45 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.9474 ms
2025-03-28 18:29:45 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:29:45 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:29:45 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:29:45 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:29:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.9992 ms
2025-03-28 18:29:46 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:52)
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:29:46 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:56038 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:29:46 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:29:46 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:29:46 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:29:46 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 4233 bytes result sent to driver
2025-03-28 18:29:46 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 62 ms on YAU (executor driver) (1/1)
2025-03-28 18:29:46 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:52) finished in 0.073 s
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:29:46 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:52, took 0.078745 s
2025-03-28 18:29:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.0346 ms
2025-03-28 18:29:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.3287 ms
2025-03-28 18:29:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.7032 ms
2025-03-28 18:29:46 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (first at mysql_config_project.scala:60)
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:29:46 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:56038 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:29:46 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:29:46 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:29:46 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:29:46 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1648 bytes result sent to driver
2025-03-28 18:29:46 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 97 ms on YAU (executor driver) (1/1)
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (first at mysql_config_project.scala:60) finished in 0.114 s
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:29:46 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:29:46 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:29:46 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: first at mysql_config_project.scala:60, took 0.118972 s
2025-03-28 18:29:46 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.991 ms
2025-03-28 18:29:46 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-28 18:29:47 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:56038 in memory (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:29:47 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:56038 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:29:47 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:56038 in memory (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:29:47 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:56038 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:29:47 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 28 ms to list leaf files for 1 paths.
2025-03-28 18:29:47 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (load at update_parquet.scala:18) with 1 output partitions
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (load at update_parquet.scala:18)
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:18), which has no missing parents
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 4.5 GiB)
2025-03-28 18:29:47 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:56038 (size: 37.0 KiB, free: 4.5 GiB)
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 18:29:47 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8877 bytes) 
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 916 bytes result sent to driver
2025-03-28 18:29:47 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 37 ms on YAU (executor driver) (1/1)
2025-03-28 18:29:47 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (load at update_parquet.scala:18) finished in 0.053 s
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 18:29:47 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: load at update_parquet.scala:18, took 0.057240 s
2025-03-28 18:29:47 [main] INFO  functions.update_parquet$ - No valid Parquet file found
2025-03-28 18:29:47 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:29:47 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:29:47 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:29:47 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:29:47 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:29:47 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:29:47 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:29:47 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.5912 ms
2025-03-28 18:29:47 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:55
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (save at update_parquet.scala:55) with 1 output partitions
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (save at update_parquet.scala:55)
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at save at update_parquet.scala:55), which has no missing parents
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 214.0 KiB, free 4.5 GiB)
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 77.0 KiB, free 4.5 GiB)
2025-03-28 18:29:47 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:56038 (size: 77.0 KiB, free: 4.5 GiB)
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at save at update_parquet.scala:55) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:29:47 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 18:29:47 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-03-28 18:29:47 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-28 18:29:48 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:29:48 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281829478074630471324864846_0005_m_000000_5' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202503281829478074630471324864846_0005_m_000000
2025-03-28 18:29:48 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281829478074630471324864846_0005_m_000000_5: Committed. Elapsed time: 10 ms.
2025-03-28 18:29:48 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 2785 bytes result sent to driver
2025-03-28 18:29:48 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 1037 ms on YAU (executor driver) (1/1)
2025-03-28 18:29:48 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 18:29:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (save at update_parquet.scala:55) finished in 1.075 s
2025-03-28 18:29:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:29:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 18:29:48 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: save at update_parquet.scala:55, took 1.079860 s
2025-03-28 18:29:48 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job f234213e-c7c6-4413-b261-a19180a093d5.
2025-03-28 18:29:48 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job f234213e-c7c6-4413-b261-a19180a093d5 committed. Elapsed time: 25 ms.
2025-03-28 18:29:48 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job f234213e-c7c6-4413-b261-a19180a093d5.
2025-03-28 18:29:48 [main] INFO  functions.update_parquet$ - Initial load completed
2025-03-28 18:29:48 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:29:48 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:29:48 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:29:48 [dispatcher-event-loop-10] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:29:48 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:29:48 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:29:48 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:29:48 [dispatcher-event-loop-14] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:29:48 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:29:48 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:29:48 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-f272b7db-625a-4a14-9c58-b24a42cd17f7
2025-03-28 18:30:24 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:30:24 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:30:24 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:30:24 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:30:24 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:30:24 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:30:24 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:30:24 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:30:25 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 56102.
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:30:25 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:30:25 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:30:25 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-e48a1bdc-783f-4756-a26c-a2f308f4e363
2025-03-28 18:30:25 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:30:25 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:30:25 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2545ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:30:26 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:30:26 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:30:26 [main] INFO  o.sparkproject.jetty.server.Server - Started @2685ms
2025-03-28 18:30:26 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:30:26 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:30:26 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:30:26 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56153.
2025-03-28 18:30:26 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:56153
2025-03-28 18:30:26 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:30:26 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 56153, None)
2025-03-28 18:30:26 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:56153 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 56153, None)
2025-03-28 18:30:26 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 56153, None)
2025-03-28 18:30:26 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 56153, None)
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:30:26 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:30:26 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:30:26 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:30:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:30:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:30:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 312.1943 ms
2025-03-28 18:30:31 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:30:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:56153 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:30:32 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:30:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:30:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:30:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:30:32 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 214 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:32 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.527 s
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:30:32 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.573831 s
2025-03-28 18:30:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 47.3047 ms
2025-03-28 18:30:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 18.0111 ms
2025-03-28 18:30:32 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:30:32 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:56153 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:30:32 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:30:32 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:30:32 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:30:32 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1865 bytes result sent to driver
2025-03-28 18:30:32 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 48 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:32 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.062 s
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:30:32 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.065663 s
2025-03-28 18:30:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.8087 ms
2025-03-28 18:30:32 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:30:33 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:33 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:33 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:33 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:33 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:33 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:33 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 51.7733 ms
2025-03-28 18:30:33 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at mysql_config_project.scala:49)
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-28 18:30:33 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:56153 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:30:33 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-28 18:30:33 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:56153 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:30:33 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:56153 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:30:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281830334682880781617097968_0002_m_000000_2' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503281830334682880781617097968_0002_m_000000
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281830334682880781617097968_0002_m_000000_2: Committed. Elapsed time: 9 ms.
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2828 bytes result sent to driver
2025-03-28 18:30:34 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1193 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:34 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at mysql_config_project.scala:49) finished in 1.256 s
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:30:34 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at mysql_config_project.scala:49, took 1.262254 s
2025-03-28 18:30:34 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 8e65d76c-b1b8-4b73-82df-9d76beee6c8e.
2025-03-28 18:30:34 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 8e65d76c-b1b8-4b73-82df-9d76beee6c8e committed. Elapsed time: 27 ms.
2025-03-28 18:30:34 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 8e65d76c-b1b8-4b73-82df-9d76beee6c8e.
2025-03-28 18:30:34 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:30:34 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:34 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:34 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:34 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:34 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:34 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:34 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:34 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.9571 ms
2025-03-28 18:30:34 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at mysql_config_project.scala:49)
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-28 18:30:34 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:56153 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:30:34 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:30:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281830344312265900075541962_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503281830344312265900075541962_0003_m_000000
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281830344312265900075541962_0003_m_000000_3: Committed. Elapsed time: 7 ms.
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2785 bytes result sent to driver
2025-03-28 18:30:35 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 216 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:35 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at mysql_config_project.scala:49) finished in 0.249 s
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:30:35 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at mysql_config_project.scala:49, took 0.254983 s
2025-03-28 18:30:35 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 7f5c397c-3855-4e2e-ba79-91fd6ff448a6.
2025-03-28 18:30:35 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 7f5c397c-3855-4e2e-ba79-91fd6ff448a6 committed. Elapsed time: 21 ms.
2025-03-28 18:30:35 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 7f5c397c-3855-4e2e-ba79-91fd6ff448a6.
2025-03-28 18:30:35 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:30:35 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:35 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:35 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:35 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:35 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:35 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:35 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.1299 ms
2025-03-28 18:30:35 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:49)
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-28 18:30:35 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:56153 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 18:30:35 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:30:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281830355595367920210610979_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503281830355595367920210610979_0004_m_000000
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281830355595367920210610979_0004_m_000000_4: Committed. Elapsed time: 5 ms.
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2785 bytes result sent to driver
2025-03-28 18:30:36 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 968 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:36 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:49) finished in 1.009 s
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 18:30:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:49, took 1.013260 s
2025-03-28 18:30:36 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 232e649f-2c65-42b2-bc4e-75cf195855c0.
2025-03-28 18:30:36 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 232e649f-2c65-42b2-bc4e-75cf195855c0 committed. Elapsed time: 17 ms.
2025-03-28 18:30:36 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 232e649f-2c65-42b2-bc4e-75cf195855c0.
2025-03-28 18:30:36 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:30:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.5731 ms
2025-03-28 18:30:36 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at mysql_config_project.scala:52)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:30:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:56153 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 18:30:36 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 4233 bytes result sent to driver
2025-03-28 18:30:36 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 39 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:36 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at mysql_config_project.scala:52) finished in 0.048 s
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 18:30:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at mysql_config_project.scala:52, took 0.051675 s
2025-03-28 18:30:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.0054 ms
2025-03-28 18:30:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.4566 ms
2025-03-28 18:30:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.5747 ms
2025-03-28 18:30:36 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (first at mysql_config_project.scala:60)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:30:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:56153 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-28 18:30:36 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-28 18:30:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on YAU:56153 in memory (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1691 bytes result sent to driver
2025-03-28 18:30:36 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 72 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:36 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (first at mysql_config_project.scala:60) finished in 0.080 s
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-28 18:30:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: first at mysql_config_project.scala:60, took 0.083408 s
2025-03-28 18:30:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.9444 ms
2025-03-28 18:30:36 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-28 18:30:36 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 30 ms to list leaf files for 1 paths.
2025-03-28 18:30:36 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (load at update_parquet.scala:18) with 1 output partitions
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (load at update_parquet.scala:18)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[23] at load at update_parquet.scala:18), which has no missing parents
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 4.5 GiB)
2025-03-28 18:30:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:56153 (size: 36.9 KiB, free: 4.5 GiB)
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-28 18:30:36 [dispatcher-event-loop-14] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9092 bytes) 
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-28 18:30:36 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2420 bytes result sent to driver
2025-03-28 18:30:36 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 116 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:36 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (load at update_parquet.scala:18) finished in 0.133 s
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-28 18:30:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: load at update_parquet.scala:18, took 0.137306 s
2025-03-28 18:30:37 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-28 18:30:37 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-28 18:30:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.25 ms
2025-03-28 18:30:37 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 200.0 KiB, free 4.5 GiB)
2025-03-28 18:30:37 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 4.5 GiB)
2025-03-28 18:30:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:56153 (size: 34.6 KiB, free: 4.5 GiB)
2025-03-28 18:30:37 [main] INFO  org.apache.spark.SparkContext - Created broadcast 8 from isEmpty at update_parquet.scala:19
2025-03-28 18:30:37 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-28 18:30:37 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at update_parquet.scala:19
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (isEmpty at update_parquet.scala:19) with 1 output partitions
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (isEmpty at update_parquet.scala:19)
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[27] at isEmpty at update_parquet.scala:19), which has no missing parents
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 11.3 KiB, free 4.5 GiB)
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 4.5 GiB)
2025-03-28 18:30:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:56153 (size: 5.4 KiB, free: 4.5 GiB)
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at isEmpty at update_parquet.scala:19) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-28 18:30:37 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, NODE_LOCAL, 9450 bytes) 
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-45eaa340-c61b-4776-8217-9727bec8ed77-c000.snappy.parquet, range: 0-125172, partition values: [empty row]
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1796 bytes result sent to driver
2025-03-28 18:30:37 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 108 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:37 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (isEmpty at update_parquet.scala:19) finished in 0.126 s
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-28 18:30:37 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: isEmpty at update_parquet.scala:19, took 0.131974 s
2025-03-28 18:30:37 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-28 18:30:37 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-28 18:30:37 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-28 18:30:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.7934 ms
2025-03-28 18:30:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.9862 ms
2025-03-28 18:30:37 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 201.1 KiB, free 4.5 GiB)
2025-03-28 18:30:37 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 4.5 GiB)
2025-03-28 18:30:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:56153 (size: 35.0 KiB, free: 4.5 GiB)
2025-03-28 18:30:37 [main] INFO  org.apache.spark.SparkContext - Created broadcast 10 from save at update_parquet.scala:46
2025-03-28 18:30:37 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-28 18:30:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.6414 ms
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 35 (save at update_parquet.scala:46) as input to shuffle 0
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got map stage job 9 (save at update_parquet.scala:46) with 2 output partitions
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 9 (save at update_parquet.scala:46)
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at save at update_parquet.scala:46), which has no missing parents
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 46.8 KiB, free 4.5 GiB)
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 4.5 GiB)
2025-03-28 18:30:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:56153 (size: 18.9 KiB, free: 4.5 GiB)
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2025-03-28 18:30:37 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 2 tasks resource profile 0
2025-03-28 18:30:37 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, NODE_LOCAL, 9548 bytes) 
2025-03-28 18:30:37 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 9.0 (TID 10) (YAU, executor driver, partition 1, PROCESS_LOCAL, 8765 bytes) 
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-28 18:30:37 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 9.0 (TID 10)
2025-03-28 18:30:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on YAU:56153 in memory (size: 36.9 KiB, free: 4.5 GiB)
2025-03-28 18:30:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on YAU:56153 in memory (size: 34.6 KiB, free: 4.5 GiB)
2025-03-28 18:30:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on YAU:56153 in memory (size: 5.4 KiB, free: 4.5 GiB)
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.1619 ms
2025-03-28 18:30:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on YAU:56153 in memory (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.5169 ms
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.0684 ms
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-45eaa340-c61b-4776-8217-9727bec8ed77-c000.snappy.parquet, range: 0-125172, partition values: [empty row]
2025-03-28 18:30:37 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:30:37 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new decompressor [.snappy]
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 3320 bytes result sent to driver
2025-03-28 18:30:40 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 9.0 (TID 10). 3277 bytes result sent to driver
2025-03-28 18:30:40 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 2466 ms on YAU (executor driver) (1/2)
2025-03-28 18:30:40 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 9.0 (TID 10) in 2463 ms on YAU (executor driver) (2/2)
2025-03-28 18:30:40 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 9 (save at update_parquet.scala:46) finished in 2.487 s
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: HashSet()
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: HashSet()
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: HashSet()
2025-03-28 18:30:40 [main] INFO  o.a.s.s.e.a.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-03-28 18:30:40 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:40 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:40 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:40 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:40 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:40 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:40 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:40 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-28 18:30:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.7315 ms
2025-03-28 18:30:40 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:46
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (save at update_parquet.scala:46) with 1 output partitions
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (save at update_parquet.scala:46)
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[38] at save at update_parquet.scala:46), which has no missing parents
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 243.5 KiB, free 4.5 GiB)
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 4.5 GiB)
2025-03-28 18:30:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:56153 (size: 89.0 KiB, free: 4.5 GiB)
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[38] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-03-28 18:30:40 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, NODE_LOCAL, 8821 bytes) 
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-03-28 18:30:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_11_piece0 on YAU:56153 in memory (size: 18.9 KiB, free: 4.5 GiB)
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 2 (1173.7 KiB) non-empty blocks including 2 (1173.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 38 ms
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281830404775439380288814303_0011_m_000000_11' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202503281830404775439380288814303_0011_m_000000
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281830404775439380288814303_0011_m_000000_11: Committed. Elapsed time: 6 ms.
2025-03-28 18:30:40 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 6827 bytes result sent to driver
2025-03-28 18:30:40 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 256 ms on YAU (executor driver) (1/1)
2025-03-28 18:30:40 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (save at update_parquet.scala:46) finished in 0.282 s
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:30:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-03-28 18:30:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: save at update_parquet.scala:46, took 0.297731 s
2025-03-28 18:30:40 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job cb3a8e8f-c248-4018-9276-dda8aff108f3.
2025-03-28 18:30:40 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job cb3a8e8f-c248-4018-9276-dda8aff108f3 committed. Elapsed time: 23 ms.
2025-03-28 18:30:40 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job cb3a8e8f-c248-4018-9276-dda8aff108f3.
2025-03-28 18:30:40 [main] INFO  functions.update_parquet$ - Delta load completed for timestamp
2025-03-28 18:30:40 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:30:40 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:30:40 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:30:40 [dispatcher-event-loop-15] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:30:40 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:30:40 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:30:40 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:30:40 [dispatcher-event-loop-5] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:30:40 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:30:40 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:30:40 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-dd147cde-7ac5-4321-ae81-b7a8c3d39d10
2025-03-28 18:33:06 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-28 18:33:06 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:33:06 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-28 18:33:06 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-28 18:33:06 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-28 18:33:06 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-28 18:33:06 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-28 18:33:06 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-28 18:33:07 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 56242.
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-28 18:33:07 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-28 18:33:07 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-28 18:33:07 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-31075fbc-81ba-4f91-ab5a-18127c87258f
2025-03-28 18:33:07 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-28 18:33:07 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-28 18:33:08 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2622ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-28 18:33:08 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-28 18:33:08 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-28 18:33:08 [main] INFO  o.sparkproject.jetty.server.Server - Started @2753ms
2025-03-28 18:33:08 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:33:08 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-28 18:33:08 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-28 18:33:08 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56293.
2025-03-28 18:33:08 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:56293
2025-03-28 18:33:08 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-28 18:33:08 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 56293, None)
2025-03-28 18:33:08 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:56293 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 56293, None)
2025-03-28 18:33:08 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 56293, None)
2025-03-28 18:33:08 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 56293, None)
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-28 18:33:08 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-28 18:33:08 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-28 18:33:08 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-28 18:33:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-28 18:33:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 368.7401 ms
2025-03-28 18:33:13 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:29
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:29) with 1 output partitions
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:29)
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29), which has no missing parents
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-28 18:33:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:56293 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:29) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-28 18:33:14 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:33:14 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-28 18:33:14 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:33:14 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-28 18:33:14 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 197 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:14 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:29) finished in 0.542 s
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-28 18:33:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:29, took 0.586179 s
2025-03-28 18:33:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 35.7828 ms
2025-03-28 18:33:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.5038 ms
2025-03-28 18:33:14 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:32
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:32) with 1 output partitions
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:32)
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32), which has no missing parents
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-28 18:33:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:56293 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-28 18:33:14 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:33:14 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-28 18:33:14 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:33:14 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1822 bytes result sent to driver
2025-03-28 18:33:14 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:14 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:32) finished in 0.044 s
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-28 18:33:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:32, took 0.047681 s
2025-03-28 18:33:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.1425 ms
2025-03-28 18:33:14 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-28 18:33:15 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:15 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:15 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:15 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:15 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:15 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:15 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.5415 ms
2025-03-28 18:33:15 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at mysql_config_project.scala:49)
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-28 18:33:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:56293 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-28 18:33:15 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:33:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:56293 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-28 18:33:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:56293 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-28 18:33:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281833152579995263698619420_0002_m_000000_2' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503281833152579995263698619420_0002_m_000000
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281833152579995263698619420_0002_m_000000_2: Committed. Elapsed time: 12 ms.
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2828 bytes result sent to driver
2025-03-28 18:33:16 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1081 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:16 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at mysql_config_project.scala:49) finished in 1.133 s
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-28 18:33:16 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at mysql_config_project.scala:49, took 1.137695 s
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job a65f70f6-1be7-4b9b-8313-52430a2fa476.
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job a65f70f6-1be7-4b9b-8313-52430a2fa476 committed. Elapsed time: 25 ms.
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job a65f70f6-1be7-4b9b-8313-52430a2fa476.
2025-03-28 18:33:16 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.6401 ms
2025-03-28 18:33:16 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at mysql_config_project.scala:49)
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-28 18:33:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:56293 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-28 18:33:16 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281833167387601412104592534_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503281833167387601412104592534_0003_m_000000
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281833167387601412104592534_0003_m_000000_3: Committed. Elapsed time: 6 ms.
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2742 bytes result sent to driver
2025-03-28 18:33:16 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 208 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:16 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at mysql_config_project.scala:49) finished in 0.243 s
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-28 18:33:16 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at mysql_config_project.scala:49, took 0.247599 s
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 40d5e14a-4ecb-4fa7-8414-eeaf00c93888.
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 40d5e14a-4ecb-4fa7-8414-eeaf00c93888 committed. Elapsed time: 21 ms.
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 40d5e14a-4ecb-4fa7-8414-eeaf00c93888.
2025-03-28 18:33:16 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:16 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.5552 ms
2025-03-28 18:33:16 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:49
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:49) with 1 output partitions
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:49)
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49), which has no missing parents
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-28 18:33:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:56293 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at save at mysql_config_project.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-28 18:33:16 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:33:16 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-28 18:33:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:56293 in memory (size: 77.6 KiB, free: 4.5 GiB)
2025-03-28 18:33:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:56293 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281833165158924339733102267_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503281833165158924339733102267_0004_m_000000
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281833165158924339733102267_0004_m_000000_4: Committed. Elapsed time: 5 ms.
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2742 bytes result sent to driver
2025-03-28 18:33:17 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 935 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:17 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:49) finished in 0.965 s
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-28 18:33:17 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:49, took 0.969954 s
2025-03-28 18:33:17 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job e32059b3-30d5-4cee-a2cc-897d31255526.
2025-03-28 18:33:17 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job e32059b3-30d5-4cee-a2cc-897d31255526 committed. Elapsed time: 13 ms.
2025-03-28 18:33:17 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job e32059b3-30d5-4cee-a2cc-897d31255526.
2025-03-28 18:33:17 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-28 18:33:17 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.1257 ms
2025-03-28 18:33:17 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:52
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at mysql_config_project.scala:52) with 1 output partitions
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at mysql_config_project.scala:52)
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52), which has no missing parents
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-28 18:33:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:56293 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at mysql_config_project.scala:52) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-28 18:33:17 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:33:17 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 4233 bytes result sent to driver
2025-03-28 18:33:17 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 47 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:17 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at mysql_config_project.scala:52) finished in 0.054 s
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-28 18:33:17 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at mysql_config_project.scala:52, took 0.056717 s
2025-03-28 18:33:17 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.4779 ms
2025-03-28 18:33:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.6571 ms
2025-03-28 18:33:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.2517 ms
2025-03-28 18:33:18 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:60
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (first at mysql_config_project.scala:60) with 1 output partitions
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (first at mysql_config_project.scala:60)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:60), which has no missing parents
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-28 18:33:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:56293 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at mysql_config_project.scala:60) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-28 18:33:18 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-28 18:33:18 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-28 18:33:18 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:33:18 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1648 bytes result sent to driver
2025-03-28 18:33:18 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 77 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:18 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (first at mysql_config_project.scala:60) finished in 0.091 s
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-28 18:33:18 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: first at mysql_config_project.scala:60, took 0.095144 s
2025-03-28 18:33:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.6587 ms
2025-03-28 18:33:18 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-28 18:33:18 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 23 ms to list leaf files for 1 paths.
2025-03-28 18:33:18 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (load at update_parquet.scala:18) with 1 output partitions
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (load at update_parquet.scala:18)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[23] at load at update_parquet.scala:18), which has no missing parents
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 4.5 GiB)
2025-03-28 18:33:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:56293 (size: 36.9 KiB, free: 4.5 GiB)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-28 18:33:18 [dispatcher-event-loop-14] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9092 bytes) 
2025-03-28 18:33:18 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-28 18:33:18 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2377 bytes result sent to driver
2025-03-28 18:33:18 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 130 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:18 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (load at update_parquet.scala:18) finished in 0.144 s
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-28 18:33:18 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: load at update_parquet.scala:18, took 0.148349 s
2025-03-28 18:33:18 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-28 18:33:18 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-28 18:33:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.4511 ms
2025-03-28 18:33:18 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 200.0 KiB, free 4.5 GiB)
2025-03-28 18:33:18 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 4.5 GiB)
2025-03-28 18:33:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:56293 (size: 34.6 KiB, free: 4.5 GiB)
2025-03-28 18:33:18 [main] INFO  org.apache.spark.SparkContext - Created broadcast 8 from isEmpty at update_parquet.scala:19
2025-03-28 18:33:18 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-28 18:33:18 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at update_parquet.scala:19
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (isEmpty at update_parquet.scala:19) with 1 output partitions
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (isEmpty at update_parquet.scala:19)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[27] at isEmpty at update_parquet.scala:19), which has no missing parents
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 11.3 KiB, free 4.5 GiB)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 4.5 GiB)
2025-03-28 18:33:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:56293 (size: 5.4 KiB, free: 4.5 GiB)
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at isEmpty at update_parquet.scala:19) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-28 18:33:18 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, NODE_LOCAL, 9450 bytes) 
2025-03-28 18:33:18 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-28 18:33:18 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-c04aea58-0acb-4576-b2f2-049bac2695cc-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-28 18:33:18 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1753 bytes result sent to driver
2025-03-28 18:33:18 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 80 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:18 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (isEmpty at update_parquet.scala:19) finished in 0.099 s
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-28 18:33:18 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: isEmpty at update_parquet.scala:19, took 0.105754 s
2025-03-28 18:33:18 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-28 18:33:18 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-28 18:33:18 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-28 18:33:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 36.6266 ms
2025-03-28 18:33:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.4668 ms
2025-03-28 18:33:19 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 201.1 KiB, free 4.5 GiB)
2025-03-28 18:33:19 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 4.5 GiB)
2025-03-28 18:33:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:56293 (size: 35.0 KiB, free: 4.5 GiB)
2025-03-28 18:33:19 [main] INFO  org.apache.spark.SparkContext - Created broadcast 10 from save at update_parquet.scala:46
2025-03-28 18:33:19 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-28 18:33:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.8438 ms
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 35 (save at update_parquet.scala:46) as input to shuffle 0
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got map stage job 9 (save at update_parquet.scala:46) with 2 output partitions
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 9 (save at update_parquet.scala:46)
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at save at update_parquet.scala:46), which has no missing parents
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 46.8 KiB, free 4.5 GiB)
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 4.5 GiB)
2025-03-28 18:33:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:56293 (size: 18.9 KiB, free: 4.5 GiB)
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2025-03-28 18:33:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 2 tasks resource profile 0
2025-03-28 18:33:19 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, NODE_LOCAL, 9548 bytes) 
2025-03-28 18:33:19 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 9.0 (TID 10) (YAU, executor driver, partition 1, PROCESS_LOCAL, 8765 bytes) 
2025-03-28 18:33:19 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-28 18:33:19 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 9.0 (TID 10)
2025-03-28 18:33:19 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.0875 ms
2025-03-28 18:33:19 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 3.7343 ms
2025-03-28 18:33:19 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.1308 ms
2025-03-28 18:33:19 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-c04aea58-0acb-4576-b2f2-049bac2695cc-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-28 18:33:19 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new decompressor [.snappy]
2025-03-28 18:33:19 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 3277 bytes result sent to driver
2025-03-28 18:33:20 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 9.0 (TID 10). 3234 bytes result sent to driver
2025-03-28 18:33:20 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 9.0 (TID 10) in 793 ms on YAU (executor driver) (1/2)
2025-03-28 18:33:20 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 796 ms on YAU (executor driver) (2/2)
2025-03-28 18:33:20 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 9 (save at update_parquet.scala:46) finished in 0.818 s
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: HashSet()
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: HashSet()
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: HashSet()
2025-03-28 18:33:20 [main] INFO  o.a.s.s.e.a.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-03-28 18:33:20 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:20 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:20 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:20 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:20 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:20 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:20 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:20 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-28 18:33:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.6618 ms
2025-03-28 18:33:20 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:46
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (save at update_parquet.scala:46) with 1 output partitions
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (save at update_parquet.scala:46)
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[38] at save at update_parquet.scala:46), which has no missing parents
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 243.5 KiB, free 4.5 GiB)
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 4.5 GiB)
2025-03-28 18:33:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:56293 (size: 89.0 KiB, free: 4.5 GiB)
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[38] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0))
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-03-28 18:33:20 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, NODE_LOCAL, 8821 bytes) 
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 2 (1173.7 KiB) non-empty blocks including 2 (1173.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 14 ms
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503281833201835828353186259576_0011_m_000000_11' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202503281833201835828353186259576_0011_m_000000
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503281833201835828353186259576_0011_m_000000_11: Committed. Elapsed time: 4 ms.
2025-03-28 18:33:20 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 6741 bytes result sent to driver
2025-03-28 18:33:20 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 177 ms on YAU (executor driver) (1/1)
2025-03-28 18:33:20 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (save at update_parquet.scala:46) finished in 0.198 s
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-28 18:33:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-03-28 18:33:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: save at update_parquet.scala:46, took 0.215906 s
2025-03-28 18:33:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job a1deab8d-af7a-4b45-9aa0-0af61e04f327.
2025-03-28 18:33:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job a1deab8d-af7a-4b45-9aa0-0af61e04f327 committed. Elapsed time: 16 ms.
2025-03-28 18:33:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job a1deab8d-af7a-4b45-9aa0-0af61e04f327.
2025-03-28 18:33:20 [main] INFO  functions.update_parquet$ - Delta load completed for timestamp
2025-03-28 18:33:20 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-28 18:33:20 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-28 18:33:20 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-28 18:33:20 [dispatcher-event-loop-15] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-28 18:33:20 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-28 18:33:20 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-28 18:33:20 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-28 18:33:20 [dispatcher-event-loop-1] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-28 18:33:20 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-28 18:33:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-28 18:33:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-ac82d4e6-b4c6-4425-9c39-526390c8e522
2025-03-29 11:24:02 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 11:24:02 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 11:24:02 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 11:24:02 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 11:24:02 [main] INFO  org.apache.spark.SparkContext - Submitted application: test mysql load
2025-03-29 11:24:02 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 11:24:02 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 11:24:02 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 11:24:02 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 11:24:02 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 11:24:02 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 11:24:02 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 11:24:02 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 11:24:03 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50524.
2025-03-29 11:24:03 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 11:24:03 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 11:24:03 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 11:24:03 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 11:24:03 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 11:24:03 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-4fe0fb19-cd21-4710-ad15-32e5d30fa7e9
2025-03-29 11:24:03 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 11:24:03 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 11:24:03 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2754ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 11:24:03 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 11:24:03 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 11:24:03 [main] INFO  o.sparkproject.jetty.server.Server - Started @2890ms
2025-03-29 11:24:03 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 11:24:03 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 11:24:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 11:24:03 [main] ERROR org.apache.spark.SparkContext - Error initializing SparkContext.
org.apache.spark.SparkException: Could not parse Master URL: 'local[*}'
	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:3028)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:563)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2735)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1026)
	at scala.Option.getOrElse(Option.scala:201)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1020)
	at test_logging$.main(test_logging.scala:15)
	at test_logging.main(test_logging.scala)
2025-03-29 11:24:03 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 11:24:03 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 11:24:03 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 11:24:03 [dispatcher-event-loop-4] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 11:24:03 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 11:24:03 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 11:24:03 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 11:24:03 [main] WARN  o.apache.spark.metrics.MetricsSystem - Stopping a MetricsSystem that is not running
2025-03-29 11:24:03 [dispatcher-event-loop-8] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 11:24:03 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 11:24:03 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 11:24:03 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-bae6190d-28c4-446f-8414-9a8244739052
2025-03-29 11:25:46 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 11:25:46 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 11:25:46 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 11:25:46 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 11:25:46 [main] INFO  org.apache.spark.SparkContext - Submitted application: test mysql load
2025-03-29 11:25:46 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 11:25:46 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 11:25:46 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 11:25:46 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 11:25:46 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 11:25:46 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 11:25:46 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 11:25:46 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 11:25:47 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50587.
2025-03-29 11:25:47 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 11:25:47 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 11:25:47 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 11:25:47 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 11:25:47 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 11:25:47 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-770a2959-87d9-4aa2-917b-6e85050a1503
2025-03-29 11:25:47 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 11:25:47 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 11:25:47 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2469ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 11:25:47 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 11:25:47 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 11:25:47 [main] INFO  o.sparkproject.jetty.server.Server - Started @2596ms
2025-03-29 11:25:47 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 11:25:47 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 11:25:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 11:25:47 [main] ERROR org.apache.spark.SparkContext - Error initializing SparkContext.
org.apache.spark.SparkException: Could not parse Master URL: 'local[*}'
	at org.apache.spark.SparkContext$.org$apache$spark$SparkContext$$createTaskScheduler(SparkContext.scala:3028)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:563)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2735)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1026)
	at scala.Option.getOrElse(Option.scala:201)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1020)
	at test_logging$.main(test_logging.scala:15)
	at test_logging.main(test_logging.scala)
2025-03-29 11:25:47 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 11:25:47 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 11:25:47 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 11:25:47 [dispatcher-event-loop-4] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 11:25:47 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 11:25:47 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 11:25:47 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 11:25:47 [main] WARN  o.apache.spark.metrics.MetricsSystem - Stopping a MetricsSystem that is not running
2025-03-29 11:25:47 [dispatcher-event-loop-8] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 11:25:47 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 11:25:47 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 11:25:47 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-b9812046-f2b3-4927-b0bf-27725a157819
2025-03-29 11:26:11 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 11:26:12 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 11:26:12 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 11:26:12 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 11:26:12 [main] INFO  org.apache.spark.SparkContext - Submitted application: test mysql load
2025-03-29 11:26:12 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 11:26:12 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 11:26:12 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 11:26:12 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 11:26:12 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 11:26:12 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 11:26:12 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 11:26:12 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 11:26:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50646.
2025-03-29 11:26:13 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 11:26:13 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 11:26:13 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 11:26:13 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 11:26:13 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 11:26:13 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-18a2e77c-fd95-498d-8d55-520e260b1b2d
2025-03-29 11:26:13 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 11:26:13 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 11:26:13 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2393ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 11:26:13 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 11:26:13 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 11:26:13 [main] INFO  o.sparkproject.jetty.server.Server - Started @2516ms
2025-03-29 11:26:13 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 11:26:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 11:26:13 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 11:26:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50697.
2025-03-29 11:26:13 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:50697
2025-03-29 11:26:13 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 11:26:13 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 50697, None)
2025-03-29 11:26:13 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:50697 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 50697, None)
2025-03-29 11:26:13 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 50697, None)
2025-03-29 11:26:13 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 50697, None)
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 11:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:14 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 11:26:14 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 11:26:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7645f03e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 11:26:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20ead579{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 11:26:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 11:26:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c52552f{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 11:26:15 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 38 ms to list leaf files for 1 paths.
2025-03-29 11:26:15 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 2 ms to list leaf files for 1 paths.
2025-03-29 11:26:17 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 11:26:17 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-03-29 11:26:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 264.1394 ms
2025-03-29 11:26:18 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 198.7 KiB, free 4.5 GiB)
2025-03-29 11:26:18 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 4.5 GiB)
2025-03-29 11:26:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:50697 (size: 34.1 KiB, free: 4.5 GiB)
2025-03-29 11:26:18 [main] INFO  org.apache.spark.SparkContext - Created broadcast 0 from load at test_logging.scala:22
2025-03-29 11:26:18 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 11:26:18 [main] INFO  org.apache.spark.SparkContext - Starting job: load at test_logging.scala:22
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (load at test_logging.scala:22) with 1 output partitions
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (load at test_logging.scala:22)
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[3] at load at test_logging.scala:22), which has no missing parents
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 4.5 GiB)
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 4.5 GiB)
2025-03-29 11:26:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:50697 (size: 6.1 KiB, free: 4.5 GiB)
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 11:26:18 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9390 bytes) 
2025-03-29 11:26:18 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 11:26:18 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: file:///C:/Users/shres/Desktop/csv/household_pop.csv, range: 0-5980, partition values: [empty row]
2025-03-29 11:26:18 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.0214 ms
2025-03-29 11:26:18 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1835 bytes result sent to driver
2025-03-29 11:26:18 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 232 ms on YAU (executor driver) (1/1)
2025-03-29 11:26:18 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (load at test_logging.scala:22) finished in 0.349 s
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 11:26:18 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: load at test_logging.scala:22, took 0.386791 s
2025-03-29 11:26:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.1005 ms
2025-03-29 11:26:18 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 11:26:18 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 11:26:18 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 198.7 KiB, free 4.5 GiB)
2025-03-29 11:26:18 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 4.5 GiB)
2025-03-29 11:26:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:50697 (size: 34.1 KiB, free: 4.5 GiB)
2025-03-29 11:26:18 [main] INFO  org.apache.spark.SparkContext - Created broadcast 2 from load at test_logging.scala:22
2025-03-29 11:26:18 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 11:26:18 [main] INFO  org.apache.spark.SparkContext - Starting job: load at test_logging.scala:22
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (load at test_logging.scala:22) with 1 output partitions
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (load at test_logging.scala:22)
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[9] at load at test_logging.scala:22), which has no missing parents
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 20.0 KiB, free 4.5 GiB)
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 4.5 GiB)
2025-03-29 11:26:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:50697 (size: 9.2 KiB, free: 4.5 GiB)
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 11:26:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 11:26:18 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9390 bytes) 
2025-03-29 11:26:18 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 11:26:19 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: file:///C:/Users/shres/Desktop/csv/household_pop.csv, range: 0-5980, partition values: [empty row]
2025-03-29 11:26:19 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1743 bytes result sent to driver
2025-03-29 11:26:19 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 73 ms on YAU (executor driver) (1/1)
2025-03-29 11:26:19 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (load at test_logging.scala:22) finished in 0.111 s
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 11:26:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: load at test_logging.scala:22, took 0.114948 s
2025-03-29 11:26:19 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 11:26:19 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 11:26:19 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 198.7 KiB, free 4.5 GiB)
2025-03-29 11:26:19 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 4.5 GiB)
2025-03-29 11:26:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:50697 (size: 34.1 KiB, free: 4.5 GiB)
2025-03-29 11:26:19 [main] INFO  org.apache.spark.SparkContext - Created broadcast 4 from show at test_logging.scala:24
2025-03-29 11:26:19 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 11:26:19 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:24
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at test_logging.scala:24) with 1 output partitions
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at test_logging.scala:24)
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[12] at show at test_logging.scala:24), which has no missing parents
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 12.1 KiB, free 4.5 GiB)
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-29 11:26:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:50697 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at test_logging.scala:24) (first 15 tasks are for partitions Vector(0))
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 11:26:19 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9390 bytes) 
2025-03-29 11:26:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 11:26:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: file:///C:/Users/shres/Desktop/csv/household_pop.csv, range: 0-5980, partition values: [empty row]
2025-03-29 11:26:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.4648 ms
2025-03-29 11:26:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] WARN  o.a.s.s.c.csv.CSVHeaderChecker - CSV header does not conform to the schema.
 Header: Table 15: Number of households, population by sex, average household size, sex ratio, population density and annual population  growth rate, NPHC 2021, , , , , , , , , , 
 Schema: Table 15: Number of households, population by sex, average household size, sex ratio, population density and annual population  growth rate, NPHC 2021, _c1, _c2, _c3, _c4, _c5, _c6, _c7, _c8, _c9, _c10
Expected: _c1 but found: 
CSV file: file:///C:/Users/shres/Desktop/csv/household_pop.csv
2025-03-29 11:26:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2253 bytes result sent to driver
2025-03-29 11:26:19 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 74 ms on YAU (executor driver) (1/1)
2025-03-29 11:26:19 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at test_logging.scala:24) finished in 0.086 s
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 11:26:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 11:26:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at test_logging.scala:24, took 0.095958 s
2025-03-29 11:26:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.4622 ms
2025-03-29 11:26:19 [main] ERROR test_logging$ - ERROR IS >>>>>>>>>>>>>>>> Identifier name 'Table 15: Number of households, population by sex, average household size, sex ratio, population den' is too long <<<<<<<<<<<<<<<
2025-03-29 11:26:19 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 11:26:19 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 11:26:19 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 11:26:19 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 11:26:19 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 11:26:19 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 11:26:19 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 11:26:19 [dispatcher-event-loop-5] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 11:26:19 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 11:26:19 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 11:26:19 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-68b2ae9d-766c-4153-9e0e-84e037b01dd2
2025-03-29 11:27:19 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 11:27:19 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 11:27:19 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 11:27:19 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 11:27:19 [main] INFO  org.apache.spark.SparkContext - Submitted application: test mysql load
2025-03-29 11:27:20 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 11:27:20 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 11:27:20 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 11:27:20 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 11:27:20 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 11:27:20 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 11:27:20 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 11:27:20 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 11:27:20 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50739.
2025-03-29 11:27:20 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 11:27:20 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 11:27:20 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 11:27:20 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 11:27:20 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 11:27:20 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-2028c463-5173-46d6-abef-1a211ee43aae
2025-03-29 11:27:20 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 11:27:21 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 11:27:21 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2530ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 11:27:21 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 11:27:21 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 11:27:21 [main] INFO  o.sparkproject.jetty.server.Server - Started @2646ms
2025-03-29 11:27:21 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 11:27:21 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 11:27:21 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 11:27:21 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50790.
2025-03-29 11:27:21 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:50790
2025-03-29 11:27:21 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 11:27:21 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 50790, None)
2025-03-29 11:27:21 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:50790 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 50790, None)
2025-03-29 11:27:21 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 50790, None)
2025-03-29 11:27:21 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 50790, None)
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 11:27:21 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7645f03e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20ead579{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 11:27:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c52552f{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 11:27:22 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 39 ms to list leaf files for 1 paths.
2025-03-29 11:27:22 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 2 ms to list leaf files for 1 paths.
2025-03-29 11:27:25 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 11:27:25 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: (length(trim(value#0, None)) > 0)
2025-03-29 11:27:25 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 242.8231 ms
2025-03-29 11:27:25 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 198.7 KiB, free 4.5 GiB)
2025-03-29 11:27:26 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 4.5 GiB)
2025-03-29 11:27:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:50790 (size: 34.1 KiB, free: 4.5 GiB)
2025-03-29 11:27:26 [main] INFO  org.apache.spark.SparkContext - Created broadcast 0 from load at test_logging.scala:22
2025-03-29 11:27:26 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 11:27:26 [main] INFO  org.apache.spark.SparkContext - Starting job: load at test_logging.scala:22
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (load at test_logging.scala:22) with 1 output partitions
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (load at test_logging.scala:22)
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[3] at load at test_logging.scala:22), which has no missing parents
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 12.3 KiB, free 4.5 GiB)
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 4.5 GiB)
2025-03-29 11:27:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:50790 (size: 6.1 KiB, free: 4.5 GiB)
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 11:27:26 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9390 bytes) 
2025-03-29 11:27:26 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 11:27:26 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: file:///C:/Users/shres/Desktop/csv/household_pop.csv, range: 0-5816, partition values: [empty row]
2025-03-29 11:27:26 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.1989 ms
2025-03-29 11:27:26 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1855 bytes result sent to driver
2025-03-29 11:27:26 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 238 ms on YAU (executor driver) (1/1)
2025-03-29 11:27:26 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (load at test_logging.scala:22) finished in 0.350 s
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 11:27:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: load at test_logging.scala:22, took 0.389448 s
2025-03-29 11:27:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.2252 ms
2025-03-29 11:27:26 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 11:27:26 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 11:27:26 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 198.7 KiB, free 4.5 GiB)
2025-03-29 11:27:26 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 4.5 GiB)
2025-03-29 11:27:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:50790 (size: 34.1 KiB, free: 4.5 GiB)
2025-03-29 11:27:26 [main] INFO  org.apache.spark.SparkContext - Created broadcast 2 from load at test_logging.scala:22
2025-03-29 11:27:26 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 11:27:26 [main] INFO  org.apache.spark.SparkContext - Starting job: load at test_logging.scala:22
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (load at test_logging.scala:22) with 1 output partitions
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (load at test_logging.scala:22)
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[9] at load at test_logging.scala:22), which has no missing parents
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 20.0 KiB, free 4.5 GiB)
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 4.5 GiB)
2025-03-29 11:27:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:50790 (size: 9.2 KiB, free: 4.5 GiB)
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 11:27:26 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9390 bytes) 
2025-03-29 11:27:26 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 11:27:26 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: file:///C:/Users/shres/Desktop/csv/household_pop.csv, range: 0-5816, partition values: [empty row]
2025-03-29 11:27:26 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1899 bytes result sent to driver
2025-03-29 11:27:26 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 88 ms on YAU (executor driver) (1/1)
2025-03-29 11:27:26 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (load at test_logging.scala:22) finished in 0.132 s
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 11:27:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 11:27:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: load at test_logging.scala:22, took 0.138426 s
2025-03-29 11:27:26 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 11:27:26 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 11:27:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.7697 ms
2025-03-29 11:27:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 198.7 KiB, free 4.5 GiB)
2025-03-29 11:27:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 4.5 GiB)
2025-03-29 11:27:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:50790 (size: 34.1 KiB, free: 4.5 GiB)
2025-03-29 11:27:27 [main] INFO  org.apache.spark.SparkContext - Created broadcast 4 from show at test_logging.scala:24
2025-03-29 11:27:27 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 11:27:27 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:24
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at test_logging.scala:24) with 1 output partitions
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at test_logging.scala:24)
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[13] at show at test_logging.scala:24), which has no missing parents
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 19.7 KiB, free 4.5 GiB)
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 4.5 GiB)
2025-03-29 11:27:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:50790 (size: 8.6 KiB, free: 4.5 GiB)
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at show at test_logging.scala:24) (first 15 tasks are for partitions Vector(0))
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 11:27:27 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9390 bytes) 
2025-03-29 11:27:27 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 11:27:27 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: file:///C:/Users/shres/Desktop/csv/household_pop.csv, range: 0-5816, partition values: [empty row]
2025-03-29 11:27:27 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.5283 ms
2025-03-29 11:27:27 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2170 bytes result sent to driver
2025-03-29 11:27:27 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 75 ms on YAU (executor driver) (1/1)
2025-03-29 11:27:27 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at test_logging.scala:24) finished in 0.089 s
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 11:27:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at test_logging.scala:24, took 0.089673 s
2025-03-29 11:27:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.3686 ms
2025-03-29 11:27:27 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 11:27:27 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 11:27:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 198.7 KiB, free 4.5 GiB)
2025-03-29 11:27:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 4.5 GiB)
2025-03-29 11:27:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:50790 (size: 34.1 KiB, free: 4.5 GiB)
2025-03-29 11:27:27 [main] INFO  org.apache.spark.SparkContext - Created broadcast 6 from save at test_logging.scala:36
2025-03-29 11:27:27 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 11:27:27 [main] INFO  org.apache.spark.SparkContext - Starting job: save at test_logging.scala:36
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at test_logging.scala:36) with 1 output partitions
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at test_logging.scala:36)
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[18] at save at test_logging.scala:36), which has no missing parents
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 23.6 KiB, free 4.5 GiB)
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 4.5 GiB)
2025-03-29 11:27:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:50790 (size: 10.7 KiB, free: 4.5 GiB)
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at save at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 11:27:27 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9390 bytes) 
2025-03-29 11:27:27 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 11:27:27 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.0424 ms
2025-03-29 11:27:27 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: file:///C:/Users/shres/Desktop/csv/household_pop.csv, range: 0-5816, partition values: [empty row]
2025-03-29 11:27:27 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1570 bytes result sent to driver
2025-03-29 11:27:27 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 205 ms on YAU (executor driver) (1/1)
2025-03-29 11:27:27 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at test_logging.scala:36) finished in 0.209 s
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 11:27:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 11:27:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at test_logging.scala:36, took 0.212934 s
2025-03-29 11:27:27 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 11:27:27 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 11:27:27 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 11:27:27 [dispatcher-event-loop-4] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 11:27:28 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 11:27:28 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 11:27:28 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 11:27:28 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 11:27:28 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 11:27:28 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 11:27:28 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-80268553-2d32-479d-9489-68de59fa0e20
2025-03-29 12:22:51 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:22:51 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:22:51 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:22:51 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:22:51 [main] INFO  org.apache.spark.SparkContext - Submitted application: test mysql load
2025-03-29 12:22:51 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:22:51 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:22:51 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:22:51 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:22:51 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:22:51 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:22:51 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:22:51 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:22:59 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:22:59 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:22:59 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:22:59 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:22:59 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:22:59 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:22:59 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:22:59 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:22:59 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:22:59 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:22:59 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:22:59 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:22:59 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:23:00 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50942.
2025-03-29 12:23:00 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:23:00 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:23:00 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:23:00 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:23:00 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:23:00 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-5958766f-2d82-412c-9ce0-fcd26938a864
2025-03-29 12:23:00 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:23:00 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:23:00 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2538ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:23:00 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:23:00 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:23:00 [main] INFO  o.sparkproject.jetty.server.Server - Started @2667ms
2025-03-29 12:23:00 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@34eed5de{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:23:00 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:23:00 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cea0110{/,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:23:01 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:23:01 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50993.
2025-03-29 12:23:01 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:50993
2025-03-29 12:23:01 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:23:01 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 50993, None)
2025-03-29 12:23:01 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:50993 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 50993, None)
2025-03-29 12:23:01 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 50993, None)
2025-03-29 12:23:01 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 50993, None)
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7cea0110{/,null,STOPPED,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@61514735{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@655f69da{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e86807a{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@590f0c50{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5befbac1{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a565afb{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/static,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c1447b5{/,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24a2e565{/api,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48a663e9{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3178219a{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@465b38e6{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-29 12:23:01 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-29 12:23:01 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:23:01 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7645f03e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20ead579{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:23:01 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c52552f{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:23:05 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 243.961 ms
2025-03-29 12:23:05 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:32
2025-03-29 12:23:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:32) with 1 output partitions
2025-03-29 12:23:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:32)
2025-03-29 12:23:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:23:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:23:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32), which has no missing parents
2025-03-29 12:23:05 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:23:06 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:50993 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:23:06 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1958 bytes result sent to driver
2025-03-29 12:23:06 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 195 ms on YAU (executor driver) (1/1)
2025-03-29 12:23:06 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:32) finished in 0.444 s
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:23:06 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:32, took 0.490231 s
2025-03-29 12:23:06 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.78 ms
2025-03-29 12:23:06 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.2221 ms
2025-03-29 12:23:06 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:35
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:35) with 1 output partitions
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:35)
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35), which has no missing parents
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-29 12:23:06 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:50993 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 12:23:06 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1908 bytes result sent to driver
2025-03-29 12:23:06 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-29 12:23:06 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:35) finished in 0.044 s
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 12:23:06 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:35, took 0.046816 s
2025-03-29 12:23:06 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.0342 ms
2025-03-29 12:23:06 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-29 12:23:06 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.1713 ms
2025-03-29 12:23:06 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:44)
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:23:06 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:50993 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 12:23:06 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:23:06 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1319 bytes result sent to driver
2025-03-29 12:23:06 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 72 ms on YAU (executor driver) (1/1)
2025-03-29 12:23:06 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:44) finished in 0.115 s
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:23:06 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 12:23:06 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:44, took 0.115801 s
2025-03-29 12:23:07 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:50993 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:23:07 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:50993 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:23:07 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:50993 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:23:07 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:23:07 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:23:07 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:23:07 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:23:07 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:23:07 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:23:07 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:23:07 [main] INFO  task1.mysql_config_project$ - ERROR IS >>>>>>>>>>>>>>>>>>>>> Call From YAU/192.168.1.14 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused: no further information; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused <<<<<<<<<<<<<<<<<
2025-03-29 12:23:07 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:23:07 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@34eed5de{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:23:07 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:23:07 [dispatcher-event-loop-1] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:23:07 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:23:07 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:23:07 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:23:07 [dispatcher-event-loop-4] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:23:07 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:23:07 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:23:07 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-4247c491-8a92-4464-ba97-d67c76bc32f5
2025-03-29 12:26:10 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:26:10 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:26:10 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:26:10 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:26:10 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:26:10 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:26:10 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:26:10 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:26:10 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:26:10 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:26:10 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:26:10 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:26:10 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:26:11 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51332.
2025-03-29 12:26:11 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:26:11 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:26:11 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:26:11 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:26:11 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:26:11 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-cf323b37-4bd5-4bbf-b98d-9af5fad51017
2025-03-29 12:26:11 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:26:11 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:26:11 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @3155ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:26:12 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:26:12 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:26:12 [main] INFO  o.sparkproject.jetty.server.Server - Started @3322ms
2025-03-29 12:26:12 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:26:12 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:26:12 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:26:12 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51383.
2025-03-29 12:26:12 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:51383
2025-03-29 12:26:12 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:26:12 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 51383, None)
2025-03-29 12:26:12 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:51383 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 51383, None)
2025-03-29 12:26:12 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 51383, None)
2025-03-29 12:26:12 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 51383, None)
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:26:12 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:13 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-29 12:26:13 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-29 12:26:13 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:26:13 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:26:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:26:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 337.4852 ms
2025-03-29 12:26:18 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:32
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:32) with 1 output partitions
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:32)
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32), which has no missing parents
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:26:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:51383 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:26:18 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:26:18 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:26:18 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:26:18 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1541 bytes result sent to driver
2025-03-29 12:26:18 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 217 ms on YAU (executor driver) (1/1)
2025-03-29 12:26:18 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:32) finished in 0.541 s
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:26:18 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:32, took 0.591580 s
2025-03-29 12:26:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.2376 ms
2025-03-29 12:26:18 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:35
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:35) with 1 output partitions
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:35)
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35), which has no missing parents
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-29 12:26:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:51383 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 12:26:18 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:26:18 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 12:26:18 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:26:18 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1534 bytes result sent to driver
2025-03-29 12:26:18 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on YAU (executor driver) (1/1)
2025-03-29 12:26:18 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:35) finished in 0.053 s
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:26:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 12:26:18 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:35, took 0.057094 s
2025-03-29 12:26:18 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:26:19 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:26:19 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:26:19 [dispatcher-event-loop-13] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:26:19 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:26:19 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:26:19 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:26:19 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:26:19 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:26:19 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:26:19 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-f68893da-845c-4431-af5d-f82f6da399f4
2025-03-29 12:35:32 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:35:32 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:35:32 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:35:32 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:35:32 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:35:32 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:35:32 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:35:32 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:35:32 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:35:32 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:35:32 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:35:32 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:35:32 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:35:33 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51434.
2025-03-29 12:35:33 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:35:33 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:35:33 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:35:33 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:35:33 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:35:33 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-62cff914-2425-4145-821a-10f00e964aa0
2025-03-29 12:35:33 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:35:33 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:35:33 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2588ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:35:33 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:35:33 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:35:33 [main] INFO  o.sparkproject.jetty.server.Server - Started @2706ms
2025-03-29 12:35:33 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:35:33 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:35:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-29 12:35:33 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:35:33 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:35:34 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51485.
2025-03-29 12:35:34 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:51485
2025-03-29 12:35:34 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:35:34 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 51485, None)
2025-03-29 12:35:34 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:51485 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 51485, None)
2025-03-29 12:35:34 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 51485, None)
2025-03-29 12:35:34 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 51485, None)
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-29 12:35:34 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-29 12:35:34 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:35:34 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:35:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:35:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 259.934 ms
2025-03-29 12:35:38 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:32
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:32) with 1 output partitions
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:32)
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32), which has no missing parents
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:35:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:51485 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:35:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:35:38 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:35:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:35:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:35:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1843 bytes result sent to driver
2025-03-29 12:35:39 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 194 ms on YAU (executor driver) (1/1)
2025-03-29 12:35:39 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:35:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:32) finished in 0.467 s
2025-03-29 12:35:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:35:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:35:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:32, took 0.512239 s
2025-03-29 12:35:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.5086 ms
2025-03-29 12:35:39 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 12:35:39 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:35:39 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:35:39 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:35:39 [dispatcher-event-loop-10] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:35:39 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:35:39 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:35:39 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:35:39 [dispatcher-event-loop-14] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:35:39 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:35:39 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:35:39 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-d814191b-7490-4432-9a12-b9d45fdf929e
2025-03-29 12:38:08 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:38:08 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:38:08 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:38:08 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:38:08 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:38:08 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:38:08 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:38:08 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:38:08 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:38:08 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:38:08 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:38:08 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:38:08 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:38:09 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51608.
2025-03-29 12:38:09 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:38:09 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:38:09 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:38:09 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:38:09 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:38:09 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-2048b69a-b6b4-4ff0-9340-aa42d29ec876
2025-03-29 12:38:09 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:38:09 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:38:09 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2543ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:38:09 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:38:09 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:38:09 [main] INFO  o.sparkproject.jetty.server.Server - Started @2666ms
2025-03-29 12:38:09 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:38:09 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:38:09 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:38:10 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:38:10 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51659.
2025-03-29 12:38:10 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:51659
2025-03-29 12:38:10 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:38:10 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 51659, None)
2025-03-29 12:38:10 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:51659 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 51659, None)
2025-03-29 12:38:10 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 51659, None)
2025-03-29 12:38:10 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 51659, None)
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-29 12:38:10 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-29 12:38:10 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:38:10 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:38:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:38:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 272.5438 ms
2025-03-29 12:38:14 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:32
2025-03-29 12:38:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:32) with 1 output partitions
2025-03-29 12:38:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:32)
2025-03-29 12:38:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32), which has no missing parents
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:38:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:51659 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:38:15 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:38:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1843 bytes result sent to driver
2025-03-29 12:38:15 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 183 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:15 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:32) finished in 0.472 s
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:38:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:32, took 0.517535 s
2025-03-29 12:38:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 33.0185 ms
2025-03-29 12:38:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.0398 ms
2025-03-29 12:38:15 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:35
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:35) with 1 output partitions
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:35)
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35), which has no missing parents
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-29 12:38:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:51659 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 12:38:15 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:15 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 12:38:15 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:15 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1764 bytes result sent to driver
2025-03-29 12:38:15 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:15 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:35) finished in 0.040 s
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 12:38:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:35, took 0.043985 s
2025-03-29 12:38:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.8891 ms
2025-03-29 12:38:15 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-29 12:38:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.1687 ms
2025-03-29 12:38:15 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:44)
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:38:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:51659 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 12:38:15 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:15 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1276 bytes result sent to driver
2025-03-29 12:38:16 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 56 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:16 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:44) finished in 0.095 s
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 12:38:16 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:44, took 0.099685 s
2025-03-29 12:38:16 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:16 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:16 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:16 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.2886 ms
2025-03-29 12:38:16 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:70
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at mysql_config_project.scala:70) with 1 output partitions
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at mysql_config_project.scala:70)
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at mysql_config_project.scala:70), which has no missing parents
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-29 12:38:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:51659 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at mysql_config_project.scala:70) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 12:38:16 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:38:16 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-29 12:38:17 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-29 12:38:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:51659 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:38:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:51659 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:38:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:51659 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:38:17 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:18 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291238162866344980327402415_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503291238162866344980327402415_0003_m_000000
2025-03-29 12:38:18 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291238162866344980327402415_0003_m_000000_3: Committed. Elapsed time: 13 ms.
2025-03-29 12:38:18 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2828 bytes result sent to driver
2025-03-29 12:38:18 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 1573 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:18 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at mysql_config_project.scala:70) finished in 1.618 s
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 12:38:18 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at mysql_config_project.scala:70, took 1.622529 s
2025-03-29 12:38:18 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 221ea766-b503-4824-86cb-c7257e3e4b53.
2025-03-29 12:38:18 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 221ea766-b503-4824-86cb-c7257e3e4b53 committed. Elapsed time: 34 ms.
2025-03-29 12:38:18 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 221ea766-b503-4824-86cb-c7257e3e4b53.
2025-03-29 12:38:18 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-29 12:38:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.7142 ms
2025-03-29 12:38:18 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at get_df_from_tablename.scala:44)
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[18] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:38:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:51659 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-29 12:38:18 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:18 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-29 12:38:18 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:18 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1233 bytes result sent to driver
2025-03-29 12:38:18 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:18 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at get_df_from_tablename.scala:44) finished in 0.051 s
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-29 12:38:18 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at get_df_from_tablename.scala:44, took 0.056386 s
2025-03-29 12:38:18 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:18 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:18 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:18 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:18 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:18 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:18 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.9751 ms
2025-03-29 12:38:18 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:70
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (save at mysql_config_project.scala:70) with 1 output partitions
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (save at mysql_config_project.scala:70)
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[21] at save at mysql_config_project.scala:70), which has no missing parents
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-29 12:38:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:51659 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at save at mysql_config_project.scala:70) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-29 12:38:18 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:18 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-29 12:38:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on YAU:51659 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:38:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:51659 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291238183897710835652466525_0005_m_000000_5' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503291238183897710835652466525_0005_m_000000
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291238183897710835652466525_0005_m_000000_5: Committed. Elapsed time: 7 ms.
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 2785 bytes result sent to driver
2025-03-29 12:38:19 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 1040 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:19 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (save at mysql_config_project.scala:70) finished in 1.074 s
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-29 12:38:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: save at mysql_config_project.scala:70, took 1.077244 s
2025-03-29 12:38:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 71c759b0-d685-42d1-b320-9ed259948941.
2025-03-29 12:38:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 71c759b0-d685-42d1-b320-9ed259948941 committed. Elapsed time: 20 ms.
2025-03-29 12:38:19 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 71c759b0-d685-42d1-b320-9ed259948941.
2025-03-29 12:38:19 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-29 12:38:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.5216 ms
2025-03-29 12:38:19 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (save at get_df_from_tablename.scala:44)
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[26] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:38:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:51659 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-29 12:38:19 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:19 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1233 bytes result sent to driver
2025-03-29 12:38:20 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:20 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (save at get_df_from_tablename.scala:44) finished in 0.042 s
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-29 12:38:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: save at get_df_from_tablename.scala:44, took 0.047463 s
2025-03-29 12:38:20 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:20 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:20 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:20 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:20 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:20 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:20 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.9522 ms
2025-03-29 12:38:20 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:70
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (save at mysql_config_project.scala:70) with 1 output partitions
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (save at mysql_config_project.scala:70)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[29] at save at mysql_config_project.scala:70), which has no missing parents
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-29 12:38:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:51659 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[29] at save at mysql_config_project.scala:70) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-29 12:38:20 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291238205329371635556356849_0007_m_000000_7' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503291238205329371635556356849_0007_m_000000
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291238205329371635556356849_0007_m_000000_7: Committed. Elapsed time: 8 ms.
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2742 bytes result sent to driver
2025-03-29 12:38:20 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 164 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:20 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (save at mysql_config_project.scala:70) finished in 0.195 s
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-29 12:38:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: save at mysql_config_project.scala:70, took 0.199599 s
2025-03-29 12:38:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 934ccb4f-5f8d-4f66-9ca6-b81e3c943fa9.
2025-03-29 12:38:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 934ccb4f-5f8d-4f66-9ca6-b81e3c943fa9 committed. Elapsed time: 23 ms.
2025-03-29 12:38:20 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 934ccb4f-5f8d-4f66-9ca6-b81e3c943fa9.
2025-03-29 12:38:20 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-29 12:38:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.8718 ms
2025-03-29 12:38:20 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (save at get_df_from_tablename.scala:44)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[34] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:38:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:51659 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[34] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-29 12:38:20 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1233 bytes result sent to driver
2025-03-29 12:38:20 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 29 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:20 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (save at get_df_from_tablename.scala:44) finished in 0.041 s
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-29 12:38:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: save at get_df_from_tablename.scala:44, took 0.045653 s
2025-03-29 12:38:20 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:73
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (show at mysql_config_project.scala:73) with 1 output partitions
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (show at mysql_config_project.scala:73)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[37] at show at mysql_config_project.scala:73), which has no missing parents
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 12.9 KiB, free 4.5 GiB)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 4.5 GiB)
2025-03-29 12:38:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:51659 (size: 6.1 KiB, free: 4.5 GiB)
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[37] at show at mysql_config_project.scala:73) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
2025-03-29 12:38:20 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:38:20 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 2931 bytes result sent to driver
2025-03-29 12:38:20 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 34 ms on YAU (executor driver) (1/1)
2025-03-29 12:38:20 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 9 (show at mysql_config_project.scala:73) finished in 0.041 s
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:38:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished
2025-03-29 12:38:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: show at mysql_config_project.scala:73, took 0.044485 s
2025-03-29 12:38:20 [main] INFO  task1.mysql_config_project$ - ERROR IS >>>>>>>>>>>>>>>>>>>>> [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `timestamp` cannot be resolved. Did you mean one of the following? [`item`, `location`, `quantity`, `Total Spent`, `transaction_date`].;
'Project ['timestamp]
+- Relation [Transaction ID#329,item#330,quantity#331,Price Per Unit#332,Total Spent#333,Payment Method#334,location#335,transaction_date#336] JDBCRelation(dirty_cafe_sales) [numPartitions=1]
 <<<<<<<<<<<<<<<<<
2025-03-29 12:38:20 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:38:20 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:38:20 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:38:20 [dispatcher-event-loop-8] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:38:20 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:38:20 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:38:20 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:38:20 [dispatcher-event-loop-12] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:38:20 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:38:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:38:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-1a9b5ae0-e635-478e-8e57-39622bb6d4cc
2025-03-29 12:44:29 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:44:29 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:44:29 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:44:29 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:44:29 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:44:29 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:44:29 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:44:29 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:44:29 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:44:29 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:44:29 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:44:29 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:44:29 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:44:30 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51742.
2025-03-29 12:44:30 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:44:30 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:44:30 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:44:30 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:44:30 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:44:30 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-9b16ed92-51d9-41ec-bb62-ec87c46ca52b
2025-03-29 12:44:30 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:44:30 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:44:30 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2611ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:44:30 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:44:30 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:44:30 [main] INFO  o.sparkproject.jetty.server.Server - Started @2735ms
2025-03-29 12:44:31 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:44:31 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:44:31 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:44:31 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51793.
2025-03-29 12:44:31 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:51793
2025-03-29 12:44:31 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:44:31 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 51793, None)
2025-03-29 12:44:31 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:51793 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 51793, None)
2025-03-29 12:44:31 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 51793, None)
2025-03-29 12:44:31 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 51793, None)
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@655f69da{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@28369db0{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@590f0c50{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cf78c85{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5befbac1{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a565afb{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/static,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24a2e565{/,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60c1663c{/api,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3178219a{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56476c16{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b13467c{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-29 12:44:31 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-29 12:44:31 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:44:31 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@daf22f0{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d299393{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:44:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0e9707{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:44:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 263.9459 ms
2025-03-29 12:44:35 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:32
2025-03-29 12:44:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:32) with 1 output partitions
2025-03-29 12:44:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:32)
2025-03-29 12:44:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32), which has no missing parents
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:44:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:51793 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:44:36 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 12:44:36 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 191 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:36 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:32) finished in 0.454 s
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:44:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:32, took 0.496642 s
2025-03-29 12:44:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 37.5674 ms
2025-03-29 12:44:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.0156 ms
2025-03-29 12:44:36 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:35
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:35) with 1 output partitions
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:35)
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35), which has no missing parents
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-29 12:44:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:51793 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 12:44:36 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1816 bytes result sent to driver
2025-03-29 12:44:36 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:36 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:35) finished in 0.041 s
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 12:44:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:35, took 0.045666 s
2025-03-29 12:44:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.2715 ms
2025-03-29 12:44:36 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-29 12:44:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.5441 ms
2025-03-29 12:44:36 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:58)
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:44:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:51793 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 12:44:36 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1828 bytes result sent to driver
2025-03-29 12:44:36 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:36 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:58) finished in 0.046 s
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 12:44:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:58, took 0.051403 s
2025-03-29 12:44:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.9101 ms
2025-03-29 12:44:37 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:44)
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:44:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:51793 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 12:44:37 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:37 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 12:44:37 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:37 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1276 bytes result sent to driver
2025-03-29 12:44:37 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 62 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:37 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:44) finished in 0.111 s
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 12:44:37 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:44, took 0.116420 s
2025-03-29 12:44:37 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:37 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:37 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:37 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:37 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:37 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:37 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:51793 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:51793 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:51793 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.5492 ms
2025-03-29 12:44:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:51793 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:44:37 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:71)
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[16] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:44:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-29 12:44:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-29 12:44:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:51793 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-29 12:44:38 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-29 12:44:38 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291244371340846959298001004_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503291244371340846959298001004_0004_m_000000
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291244371340846959298001004_0004_m_000000_4: Committed. Elapsed time: 8 ms.
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2785 bytes result sent to driver
2025-03-29 12:44:39 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 1029 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:39 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:71) finished in 1.079 s
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-29 12:44:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:71, took 1.083731 s
2025-03-29 12:44:39 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 8153d9a7-f1e8-426b-a85b-ee09f89611ba.
2025-03-29 12:44:39 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 8153d9a7-f1e8-426b-a85b-ee09f89611ba committed. Elapsed time: 30 ms.
2025-03-29 12:44:39 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 8153d9a7-f1e8-426b-a85b-ee09f89611ba.
2025-03-29 12:44:39 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-29 12:44:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.5502 ms
2025-03-29 12:44:39 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at mysql_config_project.scala:58)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[19] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:44:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:51793 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-29 12:44:39 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1412 bytes result sent to driver
2025-03-29 12:44:39 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 22 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:39 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at mysql_config_project.scala:58) finished in 0.031 s
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-29 12:44:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at mysql_config_project.scala:58, took 0.034873 s
2025-03-29 12:44:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.2534 ms
2025-03-29 12:44:39 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (save at get_df_from_tablename.scala:44)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[24] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:44:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:51793 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-29 12:44:39 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1190 bytes result sent to driver
2025-03-29 12:44:39 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 28 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:39 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (save at get_df_from_tablename.scala:44) finished in 0.040 s
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-29 12:44:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: save at get_df_from_tablename.scala:44, took 0.044970 s
2025-03-29 12:44:39 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:39 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:39 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:39 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:39 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:39 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:39 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.4158 ms
2025-03-29 12:44:39 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (save at mysql_config_project.scala:71)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[27] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-29 12:44:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:51793 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-29 12:44:39 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:44:39 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-29 12:44:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on YAU:51793 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on YAU:51793 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on YAU:51793 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291244393500022288600473123_0007_m_000000_7' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503291244393500022288600473123_0007_m_000000
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291244393500022288600473123_0007_m_000000_7: Committed. Elapsed time: 6 ms.
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2785 bytes result sent to driver
2025-03-29 12:44:40 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 1016 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:40 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (save at mysql_config_project.scala:71) finished in 1.046 s
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-29 12:44:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: save at mysql_config_project.scala:71, took 1.050502 s
2025-03-29 12:44:40 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job b11be5f1-7d8a-44c8-abbd-617f0684e04f.
2025-03-29 12:44:40 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job b11be5f1-7d8a-44c8-abbd-617f0684e04f committed. Elapsed time: 23 ms.
2025-03-29 12:44:40 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job b11be5f1-7d8a-44c8-abbd-617f0684e04f.
2025-03-29 12:44:40 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-29 12:44:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.8626 ms
2025-03-29 12:44:40 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (show at mysql_config_project.scala:58)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[30] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:44:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:51793 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[30] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-29 12:44:40 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1455 bytes result sent to driver
2025-03-29 12:44:40 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:40 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (show at mysql_config_project.scala:58) finished in 0.038 s
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-29 12:44:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: show at mysql_config_project.scala:58, took 0.041237 s
2025-03-29 12:44:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.2925 ms
2025-03-29 12:44:40 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (save at get_df_from_tablename.scala:44)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[35] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:44:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:51793 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[35] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
2025-03-29 12:44:40 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 1233 bytes result sent to driver
2025-03-29 12:44:40 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:40 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 9 (save at get_df_from_tablename.scala:44) finished in 0.040 s
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished
2025-03-29 12:44:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: save at get_df_from_tablename.scala:44, took 0.044167 s
2025-03-29 12:44:40 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:40 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:40 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:40 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:40 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:40 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:40 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.6711 ms
2025-03-29 12:44:40 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (save at mysql_config_project.scala:71)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[38] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 77.7 KiB, free 4.5 GiB)
2025-03-29 12:44:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:51793 (size: 77.7 KiB, free: 4.5 GiB)
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 1 tasks resource profile 0
2025-03-29 12:44:40 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 10) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:40 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 10)
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291244401391632227641475319_0010_m_000000_10' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503291244401391632227641475319_0010_m_000000
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291244401391632227641475319_0010_m_000000_10: Committed. Elapsed time: 6 ms.
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 10). 2742 bytes result sent to driver
2025-03-29 12:44:41 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 10) in 117 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:41 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 10 (save at mysql_config_project.scala:71) finished in 0.144 s
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 10: Stage finished
2025-03-29 12:44:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: save at mysql_config_project.scala:71, took 0.149889 s
2025-03-29 12:44:41 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 5bbc6151-cc53-4344-89f2-ffd6e698bb77.
2025-03-29 12:44:41 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 5bbc6151-cc53-4344-89f2-ffd6e698bb77 committed. Elapsed time: 22 ms.
2025-03-29 12:44:41 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 5bbc6151-cc53-4344-89f2-ffd6e698bb77.
2025-03-29 12:44:41 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-29 12:44:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.2366 ms
2025-03-29 12:44:41 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 11 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (show at mysql_config_project.scala:58)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[41] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:51793 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-03-29 12:44:41 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 1455 bytes result sent to driver
2025-03-29 12:44:41 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 21 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:41 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (show at mysql_config_project.scala:58) finished in 0.030 s
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-03-29 12:44:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 finished: show at mysql_config_project.scala:58, took 0.031115 s
2025-03-29 12:44:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.7892 ms
2025-03-29 12:44:41 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 12 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 12 (save at get_df_from_tablename.scala:44)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[46] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:51793 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
2025-03-29 12:44:41 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 12.0 (TID 12) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 12)
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 12). 1233 bytes result sent to driver
2025-03-29 12:44:41 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 12.0 (TID 12) in 25 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:41 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 12 (save at get_df_from_tablename.scala:44) finished in 0.037 s
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
2025-03-29 12:44:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 finished: save at get_df_from_tablename.scala:44, took 0.040976 s
2025-03-29 12:44:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.2324 ms
2025-03-29 12:44:41 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:74
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 13 (show at mysql_config_project.scala:74) with 1 output partitions
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 13 (show at mysql_config_project.scala:74)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[49] at show at mysql_config_project.scala:74), which has no missing parents
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on YAU:51793 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[49] at show at mysql_config_project.scala:74) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
2025-03-29 12:44:41 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 13.0 (TID 13) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 13)
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 13). 4233 bytes result sent to driver
2025-03-29 12:44:41 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 13.0 (TID 13) in 50 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:41 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 13 (show at mysql_config_project.scala:74) finished in 0.060 s
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
2025-03-29 12:44:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 finished: show at mysql_config_project.scala:74, took 0.062710 s
2025-03-29 12:44:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.3294 ms
2025-03-29 12:44:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.2735 ms
2025-03-29 12:44:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.4707 ms
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on YAU:51793 in memory (size: 6.3 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on YAU:51793 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:82
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 14 (first at mysql_config_project.scala:82) with 1 output partitions
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 14 (first at mysql_config_project.scala:82)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[53] at first at mysql_config_project.scala:82), which has no missing parents
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on YAU:51793 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on YAU:51793 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on YAU:51793 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[53] at first at mysql_config_project.scala:82) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
2025-03-29 12:44:41 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 14.0 (TID 14) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 14)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_11_piece0 on YAU:51793 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_10_piece0 on YAU:51793 in memory (size: 77.7 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 14). 1648 bytes result sent to driver
2025-03-29 12:44:41 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 14.0 (TID 14) in 57 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:41 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 14 (first at mysql_config_project.scala:82) finished in 0.066 s
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
2025-03-29 12:44:41 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 finished: first at mysql_config_project.scala:82, took 0.068060 s
2025-03-29 12:44:41 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.6504 ms
2025-03-29 12:44:41 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-29 12:44:41 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 29 ms to list leaf files for 1 paths.
2025-03-29 12:44:41 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 15 (load at update_parquet.scala:18) with 1 output partitions
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 15 (load at update_parquet.scala:18)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[55] at load at update_parquet.scala:18), which has no missing parents
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 4.5 GiB)
2025-03-29 12:44:41 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on YAU:51793 (size: 36.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[55] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:41 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
2025-03-29 12:44:41 [dispatcher-event-loop-7] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 15.0 (TID 15) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9092 bytes) 
2025-03-29 12:44:41 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 15)
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 15). 2377 bytes result sent to driver
2025-03-29 12:44:42 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 15.0 (TID 15) in 165 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:42 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 15 (load at update_parquet.scala:18) finished in 0.182 s
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
2025-03-29 12:44:42 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 finished: load at update_parquet.scala:18, took 0.185581 s
2025-03-29 12:44:42 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 12:44:42 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 12:44:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.3873 ms
2025-03-29 12:44:42 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 200.0 KiB, free 4.5 GiB)
2025-03-29 12:44:42 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 4.5 GiB)
2025-03-29 12:44:42 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on YAU:51793 (size: 34.6 KiB, free: 4.5 GiB)
2025-03-29 12:44:42 [main] INFO  org.apache.spark.SparkContext - Created broadcast 16 from isEmpty at update_parquet.scala:19
2025-03-29 12:44:42 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 12:44:42 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at update_parquet.scala:19
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 16 (isEmpty at update_parquet.scala:19) with 1 output partitions
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 16 (isEmpty at update_parquet.scala:19)
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 16 (MapPartitionsRDD[59] at isEmpty at update_parquet.scala:19), which has no missing parents
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 11.3 KiB, free 4.5 GiB)
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 4.5 GiB)
2025-03-29 12:44:42 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on YAU:51793 (size: 5.4 KiB, free: 4.5 GiB)
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at isEmpty at update_parquet.scala:19) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 16.0 with 1 tasks resource profile 0
2025-03-29 12:44:42 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 16.0 (TID 16) (YAU, executor driver, partition 0, NODE_LOCAL, 9450 bytes) 
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 16)
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-76f978f1-28f8-4dac-9b25-c1c0bb11ac73-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 16). 1796 bytes result sent to driver
2025-03-29 12:44:42 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 16.0 (TID 16) in 97 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:42 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 16 (isEmpty at update_parquet.scala:19) finished in 0.110 s
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 16: Stage finished
2025-03-29 12:44:42 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 finished: isEmpty at update_parquet.scala:19, took 0.116218 s
2025-03-29 12:44:42 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 12:44:42 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 12:44:42 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-29 12:44:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.7242 ms
2025-03-29 12:44:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.9125 ms
2025-03-29 12:44:42 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 201.1 KiB, free 4.5 GiB)
2025-03-29 12:44:42 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 4.5 GiB)
2025-03-29 12:44:42 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_18_piece0 in memory on YAU:51793 (size: 35.0 KiB, free: 4.5 GiB)
2025-03-29 12:44:42 [main] INFO  org.apache.spark.SparkContext - Created broadcast 18 from save at update_parquet.scala:46
2025-03-29 12:44:42 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 12:44:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.3996 ms
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 67 (save at update_parquet.scala:46) as input to shuffle 0
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got map stage job 17 (save at update_parquet.scala:46) with 2 output partitions
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 17 (save at update_parquet.scala:46)
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 17 (MapPartitionsRDD[67] at save at update_parquet.scala:46), which has no missing parents
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 46.8 KiB, free 4.5 GiB)
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 4.5 GiB)
2025-03-29 12:44:42 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_19_piece0 in memory on YAU:51793 (size: 18.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[67] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2025-03-29 12:44:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 17.0 with 2 tasks resource profile 0
2025-03-29 12:44:42 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 17.0 (TID 17) (YAU, executor driver, partition 0, NODE_LOCAL, 9548 bytes) 
2025-03-29 12:44:42 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 17.0 (TID 18) (YAU, executor driver, partition 1, PROCESS_LOCAL, 8765 bytes) 
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 17)
2025-03-29 12:44:42 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 17.0 (TID 18)
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.9237 ms
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.3299 ms
2025-03-29 12:44:42 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.4333 ms
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-76f978f1-28f8-4dac-9b25-c1c0bb11ac73-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-29 12:44:42 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:42 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new decompressor [.snappy]
2025-03-29 12:44:44 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 17.0 (TID 18). 3234 bytes result sent to driver
2025-03-29 12:44:44 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 17). 3277 bytes result sent to driver
2025-03-29 12:44:44 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 17.0 (TID 18) in 2127 ms on YAU (executor driver) (1/2)
2025-03-29 12:44:44 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 17.0 (TID 17) in 2129 ms on YAU (executor driver) (2/2)
2025-03-29 12:44:44 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 17 (save at update_parquet.scala:46) finished in 2.145 s
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: HashSet()
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: HashSet()
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: HashSet()
2025-03-29 12:44:44 [main] INFO  o.a.s.s.e.a.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-03-29 12:44:44 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:44 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:44 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:44 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:44 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-29 12:44:44 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.9416 ms
2025-03-29 12:44:44 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:46
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 18 (save at update_parquet.scala:46) with 1 output partitions
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 19 (save at update_parquet.scala:46)
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 18)
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 19 (MapPartitionsRDD[70] at save at update_parquet.scala:46), which has no missing parents
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 243.5 KiB, free 4.5 GiB)
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 4.5 GiB)
2025-03-29 12:44:45 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_20_piece0 in memory on YAU:51793 (size: 89.0 KiB, free: 4.5 GiB)
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[70] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 19.0 with 1 tasks resource profile 0
2025-03-29 12:44:45 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 19.0 (TID 19) (YAU, executor driver, partition 0, NODE_LOCAL, 8821 bytes) 
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 19.0 (TID 19)
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 2 (1173.7 KiB) non-empty blocks including 2 (1173.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 11 ms
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291244446880280968862560556_0019_m_000000_19' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202503291244446880280968862560556_0019_m_000000
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291244446880280968862560556_0019_m_000000_19: Committed. Elapsed time: 5 ms.
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 19.0 (TID 19). 6784 bytes result sent to driver
2025-03-29 12:44:45 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 19.0 (TID 19) in 175 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:45 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 19 (save at update_parquet.scala:46) finished in 0.197 s
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 19: Stage finished
2025-03-29 12:44:45 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 finished: save at update_parquet.scala:46, took 0.207600 s
2025-03-29 12:44:45 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 88d1edfb-6729-4e3c-9152-08f2d7bb1480.
2025-03-29 12:44:45 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 88d1edfb-6729-4e3c-9152-08f2d7bb1480 committed. Elapsed time: 15 ms.
2025-03-29 12:44:45 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 88d1edfb-6729-4e3c-9152-08f2d7bb1480.
2025-03-29 12:44:45 [main] INFO  functions.update_parquet$ - Delta load completed for timestamp
2025-03-29 12:44:45 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.4539 ms
2025-03-29 12:44:45 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 19 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 20 (save at get_df_from_tablename.scala:44)
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 20 (MapPartitionsRDD[75] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:44:45 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_21_piece0 in memory on YAU:51793 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[75] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 20.0 with 1 tasks resource profile 0
2025-03-29 12:44:45 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 20.0 (TID 20) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 20.0 (TID 20)
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:44:45 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 20.0 (TID 20). 1233 bytes result sent to driver
2025-03-29 12:44:45 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 20.0 (TID 20) in 23 ms on YAU (executor driver) (1/1)
2025-03-29 12:44:45 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 20 (save at get_df_from_tablename.scala:44) finished in 0.037 s
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:44:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 20: Stage finished
2025-03-29 12:44:45 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 finished: save at get_df_from_tablename.scala:44, took 0.039151 s
2025-03-29 12:44:45 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:44:45 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:44:45 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:44:45 [dispatcher-event-loop-10] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:44:45 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:44:45 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:44:45 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:44:45 [dispatcher-event-loop-14] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:44:45 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:44:45 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:44:45 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-b049a0ec-dfd6-4c52-b814-b8ec9692c062
2025-03-29 12:46:57 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:47:14 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:47:15 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:47:15 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:47:15 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:47:15 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:47:15 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:47:15 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:47:15 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51890.
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:47:15 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:47:15 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:47:15 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:47:16 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-1b400738-773b-4d00-9222-4242d8662865
2025-03-29 12:47:16 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:47:16 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:47:16 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2455ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:47:16 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:47:16 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:47:16 [main] INFO  o.sparkproject.jetty.server.Server - Started @2590ms
2025-03-29 12:47:16 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:47:16 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:47:16 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:47:16 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51941.
2025-03-29 12:47:16 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:51941
2025-03-29 12:47:16 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:47:16 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 51941, None)
2025-03-29 12:47:16 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:51941 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 51941, None)
2025-03-29 12:47:16 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 51941, None)
2025-03-29 12:47:16 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 51941, None)
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@655f69da{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@28369db0{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@590f0c50{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cf78c85{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5befbac1{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a565afb{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/static,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24a2e565{/,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60c1663c{/api,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3178219a{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56476c16{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b13467c{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:16 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-29 12:47:16 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-29 12:47:17 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:47:17 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:47:17 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:47:17 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@daf22f0{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:17 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:47:17 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d299393{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:47:17 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0e9707{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:47:21 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 277.7927 ms
2025-03-29 12:47:21 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:32
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:32) with 1 output partitions
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:32)
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32), which has no missing parents
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:47:21 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:51941 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:47:21 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:21 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:47:21 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:21 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 12:47:21 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 193 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:21 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:32) finished in 0.473 s
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:21 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:47:21 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:32, took 0.520567 s
2025-03-29 12:47:21 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.1506 ms
2025-03-29 12:47:21 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.1558 ms
2025-03-29 12:47:22 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:35
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:35) with 1 output partitions
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:35)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35), which has no missing parents
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-29 12:47:22 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:51941 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 12:47:22 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1773 bytes result sent to driver
2025-03-29 12:47:22 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:22 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:35) finished in 0.044 s
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 12:47:22 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:35, took 0.046907 s
2025-03-29 12:47:22 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.1153 ms
2025-03-29 12:47:22 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-29 12:47:22 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.1687 ms
2025-03-29 12:47:22 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:58)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:47:22 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:51941 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 12:47:22 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1871 bytes result sent to driver
2025-03-29 12:47:22 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 32 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:22 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:58) finished in 0.044 s
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 12:47:22 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:58, took 0.049379 s
2025-03-29 12:47:22 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.6922 ms
2025-03-29 12:47:22 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:44)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:47:22 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:51941 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 12:47:22 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:22 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1276 bytes result sent to driver
2025-03-29 12:47:22 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 62 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:22 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:44) finished in 0.109 s
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:22 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 12:47:22 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:44, took 0.116418 s
2025-03-29 12:47:23 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:23 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:23 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:23 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:23 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:23 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:23 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:23 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.0869 ms
2025-03-29 12:47:23 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:71)
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[16] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-29 12:47:23 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:51941 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:23 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-29 12:47:23 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-29 12:47:23 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:51941 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:51941 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:51941 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:47:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:51941 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291247231154472724189928547_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503291247231154472724189928547_0004_m_000000
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291247231154472724189928547_0004_m_000000_4: Committed. Elapsed time: 9 ms.
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2828 bytes result sent to driver
2025-03-29 12:47:24 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 1095 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:24 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:71) finished in 1.142 s
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-29 12:47:24 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:71, took 1.146615 s
2025-03-29 12:47:24 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 07c9e321-5899-4d66-8883-f5840376d8a9.
2025-03-29 12:47:24 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 07c9e321-5899-4d66-8883-f5840376d8a9 committed. Elapsed time: 32 ms.
2025-03-29 12:47:24 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 07c9e321-5899-4d66-8883-f5840376d8a9.
2025-03-29 12:47:24 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-29 12:47:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.9106 ms
2025-03-29 12:47:24 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at mysql_config_project.scala:58)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[19] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:47:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:51941 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-29 12:47:24 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1455 bytes result sent to driver
2025-03-29 12:47:24 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 21 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:24 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at mysql_config_project.scala:58) finished in 0.030 s
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-29 12:47:24 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at mysql_config_project.scala:58, took 0.034446 s
2025-03-29 12:47:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.6866 ms
2025-03-29 12:47:24 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (save at get_df_from_tablename.scala:44)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[24] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:47:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:51941 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-29 12:47:24 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1233 bytes result sent to driver
2025-03-29 12:47:24 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 35 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:24 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (save at get_df_from_tablename.scala:44) finished in 0.053 s
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-29 12:47:24 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: save at get_df_from_tablename.scala:44, took 0.057793 s
2025-03-29 12:47:24 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:24 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:24 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:24 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:24 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:24 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:24 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.1453 ms
2025-03-29 12:47:24 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (save at mysql_config_project.scala:71)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[27] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-29 12:47:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:51941 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-29 12:47:24 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:24 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-29 12:47:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on YAU:51941 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on YAU:51941 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on YAU:51941 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291247246371200697256717181_0007_m_000000_7' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503291247246371200697256717181_0007_m_000000
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291247246371200697256717181_0007_m_000000_7: Committed. Elapsed time: 5 ms.
2025-03-29 12:47:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2785 bytes result sent to driver
2025-03-29 12:47:25 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 957 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:25 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-29 12:47:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (save at mysql_config_project.scala:71) finished in 0.987 s
2025-03-29 12:47:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:25 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-29 12:47:25 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: save at mysql_config_project.scala:71, took 0.990806 s
2025-03-29 12:47:25 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job dfb75dee-b16c-423a-a4f3-a0eb0ff57893.
2025-03-29 12:47:25 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job dfb75dee-b16c-423a-a4f3-a0eb0ff57893 committed. Elapsed time: 18 ms.
2025-03-29 12:47:25 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job dfb75dee-b16c-423a-a4f3-a0eb0ff57893.
2025-03-29 12:47:25 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.7272 ms
2025-03-29 12:47:26 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (show at mysql_config_project.scala:58)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[30] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:51941 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[30] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-29 12:47:26 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1455 bytes result sent to driver
2025-03-29 12:47:26 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 28 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:26 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (show at mysql_config_project.scala:58) finished in 0.039 s
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-29 12:47:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: show at mysql_config_project.scala:58, took 0.043295 s
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.2024 ms
2025-03-29 12:47:26 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (save at get_df_from_tablename.scala:44)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[35] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:51941 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[35] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
2025-03-29 12:47:26 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 1233 bytes result sent to driver
2025-03-29 12:47:26 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 34 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:26 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 9 (save at get_df_from_tablename.scala:44) finished in 0.047 s
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished
2025-03-29 12:47:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: save at get_df_from_tablename.scala:44, took 0.050277 s
2025-03-29 12:47:26 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:26 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:26 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:26 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:26 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:26 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:26 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.5122 ms
2025-03-29 12:47:26 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (save at mysql_config_project.scala:71)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[38] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 77.7 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:51941 (size: 77.7 KiB, free: 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 1 tasks resource profile 0
2025-03-29 12:47:26 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 10) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 10)
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291247266671268870780726725_0010_m_000000_10' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503291247266671268870780726725_0010_m_000000
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291247266671268870780726725_0010_m_000000_10: Committed. Elapsed time: 5 ms.
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 10). 2699 bytes result sent to driver
2025-03-29 12:47:26 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 10) in 122 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:26 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 10 (save at mysql_config_project.scala:71) finished in 0.153 s
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 10: Stage finished
2025-03-29 12:47:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: save at mysql_config_project.scala:71, took 0.157403 s
2025-03-29 12:47:26 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 8c16a481-91eb-4106-9706-85db7ef0c640.
2025-03-29 12:47:26 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 8c16a481-91eb-4106-9706-85db7ef0c640 committed. Elapsed time: 18 ms.
2025-03-29 12:47:26 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 8c16a481-91eb-4106-9706-85db7ef0c640.
2025-03-29 12:47:26 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.5375 ms
2025-03-29 12:47:26 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 11 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (show at mysql_config_project.scala:58)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[41] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:51941 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-03-29 12:47:26 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 1455 bytes result sent to driver
2025-03-29 12:47:26 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 18 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:26 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (show at mysql_config_project.scala:58) finished in 0.024 s
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-03-29 12:47:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 finished: show at mysql_config_project.scala:58, took 0.026155 s
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.3282 ms
2025-03-29 12:47:26 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 12 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 12 (save at get_df_from_tablename.scala:44)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[46] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:51941 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
2025-03-29 12:47:26 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 12.0 (TID 12) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 12)
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 12). 1190 bytes result sent to driver
2025-03-29 12:47:26 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 12.0 (TID 12) in 31 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:26 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 12 (save at get_df_from_tablename.scala:44) finished in 0.043 s
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
2025-03-29 12:47:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 finished: save at get_df_from_tablename.scala:44, took 0.045781 s
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.8443 ms
2025-03-29 12:47:26 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:74
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 13 (show at mysql_config_project.scala:74) with 1 output partitions
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 13 (show at mysql_config_project.scala:74)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[49] at show at mysql_config_project.scala:74), which has no missing parents
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-29 12:47:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on YAU:51941 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[49] at show at mysql_config_project.scala:74) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
2025-03-29 12:47:26 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 13.0 (TID 13) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 13)
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:26 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 13). 4233 bytes result sent to driver
2025-03-29 12:47:26 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 13.0 (TID 13) in 35 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:26 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 13 (show at mysql_config_project.scala:74) finished in 0.043 s
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
2025-03-29 12:47:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 finished: show at mysql_config_project.scala:74, took 0.045392 s
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.6054 ms
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.915 ms
2025-03-29 12:47:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.5192 ms
2025-03-29 12:47:27 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:82
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 14 (first at mysql_config_project.scala:82) with 1 output partitions
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 14 (first at mysql_config_project.scala:82)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[53] at first at mysql_config_project.scala:82), which has no missing parents
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on YAU:51941 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[53] at first at mysql_config_project.scala:82) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
2025-03-29 12:47:27 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 14.0 (TID 14) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:27 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 14)
2025-03-29 12:47:27 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:27 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 14). 1605 bytes result sent to driver
2025-03-29 12:47:27 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 14.0 (TID 14) in 59 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:27 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 14 (first at mysql_config_project.scala:82) finished in 0.066 s
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
2025-03-29 12:47:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 finished: first at mysql_config_project.scala:82, took 0.069501 s
2025-03-29 12:47:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.119 ms
2025-03-29 12:47:27 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-29 12:47:27 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 26 ms to list leaf files for 1 paths.
2025-03-29 12:47:27 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 15 (load at update_parquet.scala:18) with 1 output partitions
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 15 (load at update_parquet.scala:18)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[55] at load at update_parquet.scala:18), which has no missing parents
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on YAU:51941 (size: 36.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[55] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
2025-03-29 12:47:27 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 15.0 (TID 15) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9092 bytes) 
2025-03-29 12:47:27 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 15)
2025-03-29 12:47:27 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 15). 2377 bytes result sent to driver
2025-03-29 12:47:27 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 15.0 (TID 15) in 121 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:27 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 15 (load at update_parquet.scala:18) finished in 0.138 s
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
2025-03-29 12:47:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 finished: load at update_parquet.scala:18, took 0.142165 s
2025-03-29 12:47:27 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 12:47:27 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 12:47:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.1191 ms
2025-03-29 12:47:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 200.0 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on YAU:51941 (size: 34.6 KiB, free: 4.5 GiB)
2025-03-29 12:47:27 [main] INFO  org.apache.spark.SparkContext - Created broadcast 16 from isEmpty at update_parquet.scala:19
2025-03-29 12:47:27 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 12:47:27 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at update_parquet.scala:19
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 16 (isEmpty at update_parquet.scala:19) with 1 output partitions
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 16 (isEmpty at update_parquet.scala:19)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 16 (MapPartitionsRDD[59] at isEmpty at update_parquet.scala:19), which has no missing parents
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 11.3 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on YAU:51941 (size: 5.4 KiB, free: 4.5 GiB)
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at isEmpty at update_parquet.scala:19) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 16.0 with 1 tasks resource profile 0
2025-03-29 12:47:27 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 16.0 (TID 16) (YAU, executor driver, partition 0, NODE_LOCAL, 9450 bytes) 
2025-03-29 12:47:27 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 16)
2025-03-29 12:47:27 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-d3be3c84-515c-4629-aa70-c50c249c9681-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-29 12:47:27 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 16). 1796 bytes result sent to driver
2025-03-29 12:47:27 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 16.0 (TID 16) in 104 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:27 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 16 (isEmpty at update_parquet.scala:19) finished in 0.119 s
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 16: Stage finished
2025-03-29 12:47:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 finished: isEmpty at update_parquet.scala:19, took 0.123915 s
2025-03-29 12:47:27 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 12:47:27 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 12:47:27 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-29 12:47:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.5459 ms
2025-03-29 12:47:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.145 ms
2025-03-29 12:47:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 201.1 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 4.5 GiB)
2025-03-29 12:47:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_18_piece0 in memory on YAU:51941 (size: 35.0 KiB, free: 4.5 GiB)
2025-03-29 12:47:27 [main] INFO  org.apache.spark.SparkContext - Created broadcast 18 from save at update_parquet.scala:46
2025-03-29 12:47:27 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 12:47:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.0569 ms
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 67 (save at update_parquet.scala:46) as input to shuffle 0
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got map stage job 17 (save at update_parquet.scala:46) with 2 output partitions
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 17 (save at update_parquet.scala:46)
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 17 (MapPartitionsRDD[67] at save at update_parquet.scala:46), which has no missing parents
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 46.8 KiB, free 4.5 GiB)
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_19_piece0 in memory on YAU:51941 (size: 18.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[67] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2025-03-29 12:47:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 17.0 with 2 tasks resource profile 0
2025-03-29 12:47:28 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 17.0 (TID 17) (YAU, executor driver, partition 0, NODE_LOCAL, 9548 bytes) 
2025-03-29 12:47:28 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 17.0 (TID 18) (YAU, executor driver, partition 1, PROCESS_LOCAL, 8765 bytes) 
2025-03-29 12:47:28 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 17)
2025-03-29 12:47:28 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 17.0 (TID 18)
2025-03-29 12:47:28 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.9677 ms
2025-03-29 12:47:28 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 3.5496 ms
2025-03-29 12:47:28 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.8339 ms
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on YAU:51941 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-d3be3c84-515c-4629-aa70-c50c249c9681-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_10_piece0 on YAU:51941 in memory (size: 77.7 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_17_piece0 on YAU:51941 in memory (size: 5.4 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_16_piece0 on YAU:51941 in memory (size: 34.6 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_15_piece0 on YAU:51941 in memory (size: 36.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on YAU:51941 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on YAU:51941 in memory (size: 6.3 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_14_piece0 on YAU:51941 in memory (size: 6.4 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_11_piece0 on YAU:51941 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on YAU:51941 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:47:28 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:28 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new decompressor [.snappy]
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 17). 3320 bytes result sent to driver
2025-03-29 12:47:29 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 17.0 (TID 18). 3277 bytes result sent to driver
2025-03-29 12:47:29 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 17.0 (TID 18) in 926 ms on YAU (executor driver) (1/2)
2025-03-29 12:47:29 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 17.0 (TID 17) in 928 ms on YAU (executor driver) (2/2)
2025-03-29 12:47:29 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 17 (save at update_parquet.scala:46) finished in 0.950 s
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: HashSet()
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: HashSet()
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: HashSet()
2025-03-29 12:47:29 [main] INFO  o.a.s.s.e.a.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-03-29 12:47:29 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:29 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:29 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:29 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:29 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:29 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:29 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:29 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-29 12:47:29 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.5978 ms
2025-03-29 12:47:29 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:46
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 18 (save at update_parquet.scala:46) with 1 output partitions
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 19 (save at update_parquet.scala:46)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 18)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 19 (MapPartitionsRDD[70] at save at update_parquet.scala:46), which has no missing parents
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 243.5 KiB, free 4.5 GiB)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 4.5 GiB)
2025-03-29 12:47:29 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_20_piece0 in memory on YAU:51941 (size: 89.0 KiB, free: 4.5 GiB)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[70] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 19.0 with 1 tasks resource profile 0
2025-03-29 12:47:29 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 19.0 (TID 19) (YAU, executor driver, partition 0, NODE_LOCAL, 8821 bytes) 
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 19.0 (TID 19)
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 2 (1173.7 KiB) non-empty blocks including 2 (1173.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 20 ms
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291247294067133495777637596_0019_m_000000_19' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202503291247294067133495777637596_0019_m_000000
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291247294067133495777637596_0019_m_000000_19: Committed. Elapsed time: 5 ms.
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 19.0 (TID 19). 6784 bytes result sent to driver
2025-03-29 12:47:29 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 19.0 (TID 19) in 214 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:29 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 19 (save at update_parquet.scala:46) finished in 0.236 s
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 19: Stage finished
2025-03-29 12:47:29 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 finished: save at update_parquet.scala:46, took 0.247020 s
2025-03-29 12:47:29 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 6a9344e8-cb05-4088-9c92-4ad56091534a.
2025-03-29 12:47:29 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 6a9344e8-cb05-4088-9c92-4ad56091534a committed. Elapsed time: 15 ms.
2025-03-29 12:47:29 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 6a9344e8-cb05-4088-9c92-4ad56091534a.
2025-03-29 12:47:29 [main] INFO  functions.update_parquet$ - Delta load completed for timestamp
2025-03-29 12:47:29 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.4573 ms
2025-03-29 12:47:29 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:117
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 19 (show at mysql_config_project.scala:117) with 1 output partitions
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 20 (show at mysql_config_project.scala:117)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 20 (MapPartitionsRDD[73] at show at mysql_config_project.scala:117), which has no missing parents
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 4.5 GiB)
2025-03-29 12:47:29 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_21_piece0 in memory on YAU:51941 (size: 7.3 KiB, free: 4.5 GiB)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[73] at show at mysql_config_project.scala:117) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 20.0 with 1 tasks resource profile 0
2025-03-29 12:47:29 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 20.0 (TID 20) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 20.0 (TID 20)
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 20.0 (TID 20). 1455 bytes result sent to driver
2025-03-29 12:47:29 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 20.0 (TID 20) in 23 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:29 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 20 (show at mysql_config_project.scala:117) finished in 0.032 s
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 20: Stage finished
2025-03-29 12:47:29 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 finished: show at mysql_config_project.scala:117, took 0.034616 s
2025-03-29 12:47:29 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.2089 ms
2025-03-29 12:47:29 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 20 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 21 (save at get_df_from_tablename.scala:44)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 21 (MapPartitionsRDD[78] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_22 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:47:29 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_22_piece0 in memory on YAU:51941 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 22 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[78] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 21.0 with 1 tasks resource profile 0
2025-03-29 12:47:29 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 21.0 (TID 21) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 21.0 (TID 21)
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:47:29 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 21.0 (TID 21). 1233 bytes result sent to driver
2025-03-29 12:47:29 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 21.0 (TID 21) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 12:47:29 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 21 (save at get_df_from_tablename.scala:44) finished in 0.040 s
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:47:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 21: Stage finished
2025-03-29 12:47:29 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 20 finished: save at get_df_from_tablename.scala:44, took 0.042092 s
2025-03-29 12:47:29 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:47:29 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:47:29 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:47:29 [dispatcher-event-loop-12] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:47:29 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:47:29 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:47:29 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:47:29 [dispatcher-event-loop-15] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:47:29 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:47:29 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:47:29 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-97ef2ae0-a764-49dc-9503-ef7b1ea7a999
2025-03-29 12:50:46 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:50:46 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:50:46 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:50:46 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:50:46 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:50:46 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:50:46 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:50:46 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:50:46 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:50:46 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:50:46 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:50:46 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:50:46 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:50:47 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52034.
2025-03-29 12:50:47 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:50:47 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:50:47 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:50:47 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:50:47 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:50:47 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-e9806036-fa16-48e2-b218-755902e6d27b
2025-03-29 12:50:47 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:50:47 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:50:47 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2567ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:50:47 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:50:47 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:50:47 [main] INFO  o.sparkproject.jetty.server.Server - Started @2679ms
2025-03-29 12:50:47 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:50:47 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:50:47 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:50:47 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52085.
2025-03-29 12:50:47 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52085
2025-03-29 12:50:47 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:50:47 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52085, None)
2025-03-29 12:50:47 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52085 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52085, None)
2025-03-29 12:50:47 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52085, None)
2025-03-29 12:50:47 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52085, None)
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:50:47 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:48 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-29 12:50:48 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-29 12:50:48 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:50:48 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:50:48 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:50:48 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:48 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:50:48 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:50:48 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:50:52 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 252.9703 ms
2025-03-29 12:50:52 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:32
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:32) with 1 output partitions
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:32)
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32), which has no missing parents
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:50:52 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:52085 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:52 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:50:52 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 12:50:53 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 195 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:53 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:32) finished in 0.487 s
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:50:53 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:32, took 0.532736 s
2025-03-29 12:50:53 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 37.431 ms
2025-03-29 12:50:53 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.7119 ms
2025-03-29 12:50:53 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:35
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:35) with 1 output partitions
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:35)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35), which has no missing parents
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-29 12:50:53 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:52085 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 12:50:53 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1859 bytes result sent to driver
2025-03-29 12:50:53 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:53 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:35) finished in 0.044 s
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 12:50:53 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:35, took 0.046862 s
2025-03-29 12:50:53 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 23.3486 ms
2025-03-29 12:50:53 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-29 12:50:53 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 18.43 ms
2025-03-29 12:50:53 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:58)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:50:53 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:52085 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 12:50:53 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1819 bytes result sent to driver
2025-03-29 12:50:53 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:53 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:58) finished in 0.043 s
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 12:50:53 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:58, took 0.046898 s
2025-03-29 12:50:53 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.2163 ms
2025-03-29 12:50:53 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:44)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:50:53 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:52085 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 12:50:53 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:53 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1276 bytes result sent to driver
2025-03-29 12:50:53 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 68 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:53 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:44) finished in 0.124 s
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:53 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 12:50:53 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:44, took 0.127828 s
2025-03-29 12:50:54 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:54 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:54 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:54 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:54 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:54 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:54 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:54 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.5517 ms
2025-03-29 12:50:54 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at mysql_config_project.scala:71)
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[16] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-29 12:50:54 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:52085 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:54 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-29 12:50:54 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:50:54 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-29 12:50:55 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-29 12:50:55 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:52085 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:55 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:52085 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:55 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:52085 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:55 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:52085 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:50:55 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:55 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291250545745259080963710749_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503291250545745259080963710749_0004_m_000000
2025-03-29 12:50:55 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291250545745259080963710749_0004_m_000000_4: Committed. Elapsed time: 8 ms.
2025-03-29 12:50:55 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2828 bytes result sent to driver
2025-03-29 12:50:55 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 1184 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:55 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-29 12:50:55 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at mysql_config_project.scala:71) finished in 1.228 s
2025-03-29 12:50:55 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:55 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-29 12:50:55 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at mysql_config_project.scala:71, took 1.232537 s
2025-03-29 12:50:55 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 05217cdd-0895-4ed8-af80-bee0d2f2df8b.
2025-03-29 12:50:55 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 05217cdd-0895-4ed8-af80-bee0d2f2df8b committed. Elapsed time: 29 ms.
2025-03-29 12:50:55 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 05217cdd-0895-4ed8-af80-bee0d2f2df8b.
2025-03-29 12:50:55 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-29 12:50:56 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.1714 ms
2025-03-29 12:50:56 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at mysql_config_project.scala:58)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[19] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:50:56 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:52085 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-29 12:50:56 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1455 bytes result sent to driver
2025-03-29 12:50:56 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 24 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:56 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at mysql_config_project.scala:58) finished in 0.033 s
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-29 12:50:56 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at mysql_config_project.scala:58, took 0.038418 s
2025-03-29 12:50:56 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.1367 ms
2025-03-29 12:50:56 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (save at get_df_from_tablename.scala:44)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[24] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:50:56 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:52085 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-29 12:50:56 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1233 bytes result sent to driver
2025-03-29 12:50:56 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 32 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:56 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (save at get_df_from_tablename.scala:44) finished in 0.048 s
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-29 12:50:56 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: save at get_df_from_tablename.scala:44, took 0.052062 s
2025-03-29 12:50:56 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:56 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:56 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:56 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:56 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:56 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:56 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:56 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 23.2298 ms
2025-03-29 12:50:56 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (save at mysql_config_project.scala:71)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[27] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 77.3 KiB, free 4.5 GiB)
2025-03-29 12:50:56 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:52085 (size: 77.3 KiB, free: 4.5 GiB)
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-29 12:50:56 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:50:56 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-29 12:50:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on YAU:52085 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on YAU:52085 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on YAU:52085 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_20250329125056507841379550276698_0007_m_000000_7' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_20250329125056507841379550276698_0007_m_000000
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_20250329125056507841379550276698_0007_m_000000_7: Committed. Elapsed time: 8 ms.
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2742 bytes result sent to driver
2025-03-29 12:50:57 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 951 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:57 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (save at mysql_config_project.scala:71) finished in 0.985 s
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-29 12:50:57 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: save at mysql_config_project.scala:71, took 0.991388 s
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job da350887-7685-451b-8a01-e51b6816cf91.
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job da350887-7685-451b-8a01-e51b6816cf91 committed. Elapsed time: 24 ms.
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job da350887-7685-451b-8a01-e51b6816cf91.
2025-03-29 12:50:57 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-29 12:50:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.9403 ms
2025-03-29 12:50:57 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (show at mysql_config_project.scala:58)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[30] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:50:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:52085 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[30] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-29 12:50:57 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1498 bytes result sent to driver
2025-03-29 12:50:57 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 23 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:57 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (show at mysql_config_project.scala:58) finished in 0.032 s
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-29 12:50:57 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: show at mysql_config_project.scala:58, took 0.034778 s
2025-03-29 12:50:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.5687 ms
2025-03-29 12:50:57 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (save at get_df_from_tablename.scala:44)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[35] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 12:50:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:52085 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[35] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
2025-03-29 12:50:57 [dispatcher-event-loop-7] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 1276 bytes result sent to driver
2025-03-29 12:50:57 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 29 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:57 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 9 (save at get_df_from_tablename.scala:44) finished in 0.043 s
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished
2025-03-29 12:50:57 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: save at get_df_from_tablename.scala:44, took 0.046473 s
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:57 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:57 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:57 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:57 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.9326 ms
2025-03-29 12:50:57 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (save at mysql_config_project.scala:71)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[38] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-29 12:50:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:52085 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 1 tasks resource profile 0
2025-03-29 12:50:57 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 10) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 10)
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291250574733289748929772055_0010_m_000000_10' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202503291250574733289748929772055_0010_m_000000
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291250574733289748929772055_0010_m_000000_10: Committed. Elapsed time: 5 ms.
2025-03-29 12:50:57 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 10). 2785 bytes result sent to driver
2025-03-29 12:50:57 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 10) in 115 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:57 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 10 (save at mysql_config_project.scala:71) finished in 0.139 s
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 10: Stage finished
2025-03-29 12:50:57 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: save at mysql_config_project.scala:71, took 0.142349 s
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 4a352893-f7b8-45b8-b0a9-35f2d185d46c.
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 4a352893-f7b8-45b8-b0a9-35f2d185d46c committed. Elapsed time: 16 ms.
2025-03-29 12:50:57 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 4a352893-f7b8-45b8-b0a9-35f2d185d46c.
2025-03-29 12:50:57 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-29 12:50:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.9196 ms
2025-03-29 12:50:58 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 11 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (show at mysql_config_project.scala:58)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[41] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:52085 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-03-29 12:50:58 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 1455 bytes result sent to driver
2025-03-29 12:50:58 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 18 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:58 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (show at mysql_config_project.scala:58) finished in 0.026 s
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-03-29 12:50:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 finished: show at mysql_config_project.scala:58, took 0.027481 s
2025-03-29 12:50:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.4898 ms
2025-03-29 12:50:58 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 12 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 12 (save at get_df_from_tablename.scala:44)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[46] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:52085 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
2025-03-29 12:50:58 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 12.0 (TID 12) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 12)
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 12). 1233 bytes result sent to driver
2025-03-29 12:50:58 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 12.0 (TID 12) in 28 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:58 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 12 (save at get_df_from_tablename.scala:44) finished in 0.039 s
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
2025-03-29 12:50:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 finished: save at get_df_from_tablename.scala:44, took 0.041840 s
2025-03-29 12:50:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.4218 ms
2025-03-29 12:50:58 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:74
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 13 (show at mysql_config_project.scala:74) with 1 output partitions
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 13 (show at mysql_config_project.scala:74)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[49] at show at mysql_config_project.scala:74), which has no missing parents
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on YAU:52085 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[49] at show at mysql_config_project.scala:74) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
2025-03-29 12:50:58 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 13.0 (TID 13) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 13)
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 13). 4233 bytes result sent to driver
2025-03-29 12:50:58 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 13.0 (TID 13) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:58 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 13 (show at mysql_config_project.scala:74) finished in 0.043 s
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
2025-03-29 12:50:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 finished: show at mysql_config_project.scala:74, took 0.045553 s
2025-03-29 12:50:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.6676 ms
2025-03-29 12:50:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 34.935 ms
2025-03-29 12:50:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.4271 ms
2025-03-29 12:50:58 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:82
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 14 (first at mysql_config_project.scala:82) with 1 output partitions
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 14 (first at mysql_config_project.scala:82)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[53] at first at mysql_config_project.scala:82), which has no missing parents
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on YAU:52085 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[53] at first at mysql_config_project.scala:82) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
2025-03-29 12:50:58 [dispatcher-event-loop-7] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 14.0 (TID 14) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 14)
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 14). 1648 bytes result sent to driver
2025-03-29 12:50:58 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 14.0 (TID 14) in 69 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:58 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 14 (first at mysql_config_project.scala:82) finished in 0.078 s
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
2025-03-29 12:50:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 finished: first at mysql_config_project.scala:82, took 0.080973 s
2025-03-29 12:50:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.9518 ms
2025-03-29 12:50:58 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-29 12:50:58 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 21 ms to list leaf files for 1 paths.
2025-03-29 12:50:58 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 15 (load at update_parquet.scala:18) with 1 output partitions
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 15 (load at update_parquet.scala:18)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[55] at load at update_parquet.scala:18), which has no missing parents
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on YAU:52085 (size: 37.0 KiB, free: 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[55] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
2025-03-29 12:50:58 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 15.0 (TID 15) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9092 bytes) 
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 15)
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 15). 2377 bytes result sent to driver
2025-03-29 12:50:58 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 15.0 (TID 15) in 126 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:58 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 15 (load at update_parquet.scala:18) finished in 0.139 s
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
2025-03-29 12:50:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 finished: load at update_parquet.scala:18, took 0.141514 s
2025-03-29 12:50:58 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 12:50:58 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 12:50:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.5881 ms
2025-03-29 12:50:58 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 200.0 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on YAU:52085 (size: 34.6 KiB, free: 4.5 GiB)
2025-03-29 12:50:58 [main] INFO  org.apache.spark.SparkContext - Created broadcast 16 from isEmpty at update_parquet.scala:19
2025-03-29 12:50:58 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 12:50:58 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at update_parquet.scala:19
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 16 (isEmpty at update_parquet.scala:19) with 1 output partitions
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 16 (isEmpty at update_parquet.scala:19)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 16 (MapPartitionsRDD[59] at isEmpty at update_parquet.scala:19), which has no missing parents
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 11.3 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 4.5 GiB)
2025-03-29 12:50:58 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on YAU:52085 (size: 5.4 KiB, free: 4.5 GiB)
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at isEmpty at update_parquet.scala:19) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 16.0 with 1 tasks resource profile 0
2025-03-29 12:50:58 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 16.0 (TID 16) (YAU, executor driver, partition 0, NODE_LOCAL, 9450 bytes) 
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 16)
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-b837f4eb-d6b0-4765-872e-60d44cddfa97-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-29 12:50:58 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 16). 1753 bytes result sent to driver
2025-03-29 12:50:58 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 16.0 (TID 16) in 103 ms on YAU (executor driver) (1/1)
2025-03-29 12:50:58 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 16 (isEmpty at update_parquet.scala:19) finished in 0.119 s
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:50:58 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 16: Stage finished
2025-03-29 12:50:58 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 finished: isEmpty at update_parquet.scala:19, took 0.123661 s
2025-03-29 12:50:59 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 12:50:59 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 12:50:59 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-29 12:50:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.9002 ms
2025-03-29 12:50:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.829 ms
2025-03-29 12:50:59 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 201.1 KiB, free 4.5 GiB)
2025-03-29 12:50:59 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_18_piece0 in memory on YAU:52085 (size: 35.0 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [main] INFO  org.apache.spark.SparkContext - Created broadcast 18 from save at update_parquet.scala:46
2025-03-29 12:50:59 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 12:50:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.2604 ms
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 67 (save at update_parquet.scala:46) as input to shuffle 0
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got map stage job 17 (save at update_parquet.scala:46) with 2 output partitions
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 17 (save at update_parquet.scala:46)
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 17 (MapPartitionsRDD[67] at save at update_parquet.scala:46), which has no missing parents
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 46.8 KiB, free 4.5 GiB)
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_19_piece0 in memory on YAU:52085 (size: 18.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[67] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2025-03-29 12:50:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 17.0 with 2 tasks resource profile 0
2025-03-29 12:50:59 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 17.0 (TID 17) (YAU, executor driver, partition 0, NODE_LOCAL, 9548 bytes) 
2025-03-29 12:50:59 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 17.0 (TID 18) (YAU, executor driver, partition 1, PROCESS_LOCAL, 8765 bytes) 
2025-03-29 12:50:59 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 17)
2025-03-29 12:50:59 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 17.0 (TID 18)
2025-03-29 12:50:59 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.6133 ms
2025-03-29 12:50:59 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.1174 ms
2025-03-29 12:50:59 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.8697 ms
2025-03-29 12:50:59 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-b837f4eb-d6b0-4765-872e-60d44cddfa97-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on YAU:52085 in memory (size: 6.3 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_17_piece0 on YAU:52085 in memory (size: 5.4 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_10_piece0 on YAU:52085 in memory (size: 77.6 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new decompressor [.snappy]
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_14_piece0 on YAU:52085 in memory (size: 6.4 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_12_piece0 on YAU:52085 in memory (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_15_piece0 on YAU:52085 in memory (size: 37.0 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on YAU:52085 in memory (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on YAU:52085 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_16_piece0 on YAU:52085 in memory (size: 34.6 KiB, free: 4.5 GiB)
2025-03-29 12:50:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_11_piece0 on YAU:52085 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 17). 3320 bytes result sent to driver
2025-03-29 12:51:00 [Executor task launch worker for task 1.0 in stage 17.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 17.0 (TID 18). 3277 bytes result sent to driver
2025-03-29 12:51:00 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 17.0 (TID 18) in 870 ms on YAU (executor driver) (1/2)
2025-03-29 12:51:00 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 17.0 (TID 17) in 873 ms on YAU (executor driver) (2/2)
2025-03-29 12:51:00 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 17 (save at update_parquet.scala:46) finished in 0.892 s
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: HashSet()
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: HashSet()
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: HashSet()
2025-03-29 12:51:00 [main] INFO  o.a.s.s.e.a.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-03-29 12:51:00 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:51:00 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:51:00 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:51:00 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:51:00 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:51:00 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:51:00 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:51:00 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-29 12:51:00 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.0674 ms
2025-03-29 12:51:00 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:46
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 18 (save at update_parquet.scala:46) with 1 output partitions
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 19 (save at update_parquet.scala:46)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 18)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 19 (MapPartitionsRDD[70] at save at update_parquet.scala:46), which has no missing parents
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 243.5 KiB, free 4.5 GiB)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 4.5 GiB)
2025-03-29 12:51:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_20_piece0 in memory on YAU:52085 (size: 89.0 KiB, free: 4.5 GiB)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[70] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 19.0 with 1 tasks resource profile 0
2025-03-29 12:51:00 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 19.0 (TID 19) (YAU, executor driver, partition 0, NODE_LOCAL, 8821 bytes) 
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 19.0 (TID 19)
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 2 (1173.7 KiB) non-empty blocks including 2 (1173.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 12 ms
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291251006126010526541214720_0019_m_000000_19' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202503291251006126010526541214720_0019_m_000000
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291251006126010526541214720_0019_m_000000_19: Committed. Elapsed time: 7 ms.
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 19.0 (TID 19). 6741 bytes result sent to driver
2025-03-29 12:51:00 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 19.0 (TID 19) in 187 ms on YAU (executor driver) (1/1)
2025-03-29 12:51:00 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 19 (save at update_parquet.scala:46) finished in 0.204 s
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 19: Stage finished
2025-03-29 12:51:00 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 finished: save at update_parquet.scala:46, took 0.214557 s
2025-03-29 12:51:00 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job bfc1dcea-9540-4936-892e-9bceaf43480c.
2025-03-29 12:51:00 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job bfc1dcea-9540-4936-892e-9bceaf43480c committed. Elapsed time: 16 ms.
2025-03-29 12:51:00 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job bfc1dcea-9540-4936-892e-9bceaf43480c.
2025-03-29 12:51:00 [main] INFO  functions.update_parquet$ - Delta load completed for timestamp
2025-03-29 12:51:00 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.3293 ms
2025-03-29 12:51:00 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:118
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 19 (show at mysql_config_project.scala:118) with 1 output partitions
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 20 (show at mysql_config_project.scala:118)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 20 (MapPartitionsRDD[73] at show at mysql_config_project.scala:118), which has no missing parents
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 4.5 GiB)
2025-03-29 12:51:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_21_piece0 in memory on YAU:52085 (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[73] at show at mysql_config_project.scala:118) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 20.0 with 1 tasks resource profile 0
2025-03-29 12:51:00 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 20.0 (TID 20) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 20.0 (TID 20)
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 20.0 (TID 20). 1455 bytes result sent to driver
2025-03-29 12:51:00 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 20.0 (TID 20) in 21 ms on YAU (executor driver) (1/1)
2025-03-29 12:51:00 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 20 (show at mysql_config_project.scala:118) finished in 0.030 s
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 20: Stage finished
2025-03-29 12:51:00 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 finished: show at mysql_config_project.scala:118, took 0.032124 s
2025-03-29 12:51:00 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.1217 ms
2025-03-29 12:51:00 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 20 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 21 (save at get_df_from_tablename.scala:44)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 21 (MapPartitionsRDD[78] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_22 stored as values in memory (estimated size 25.7 KiB, free 4.5 GiB)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)
2025-03-29 12:51:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_22_piece0 in memory on YAU:52085 (size: 11.1 KiB, free: 4.5 GiB)
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 22 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[78] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 21.0 with 1 tasks resource profile 0
2025-03-29 12:51:00 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 21.0 (TID 21) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 21.0 (TID 21)
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:51:00 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 21.0 (TID 21). 1190 bytes result sent to driver
2025-03-29 12:51:00 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 21.0 (TID 21) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 12:51:00 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 21 (save at get_df_from_tablename.scala:44) finished in 0.038 s
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:51:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 21: Stage finished
2025-03-29 12:51:00 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 20 finished: save at get_df_from_tablename.scala:44, took 0.040445 s
2025-03-29 12:51:00 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:51:00 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:51:00 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:51:00 [dispatcher-event-loop-13] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:51:01 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:51:01 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:51:01 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:51:01 [dispatcher-event-loop-5] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:51:01 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:51:01 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:51:01 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-3e74e303-1be3-4e0f-a6a7-2feaaf593d1e
2025-03-29 12:55:03 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:55:03 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:55:03 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:55:03 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:55:03 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:55:03 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:55:03 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:55:03 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:55:03 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:55:03 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:55:03 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:55:03 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:55:03 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:55:04 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52192.
2025-03-29 12:55:04 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:55:04 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:55:04 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:55:04 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:55:04 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:55:04 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-b1ae4fab-8a09-4c97-856c-02043fc97592
2025-03-29 12:55:04 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:55:04 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:55:04 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2569ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:55:04 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:55:04 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:55:04 [main] INFO  o.sparkproject.jetty.server.Server - Started @2694ms
2025-03-29 12:55:04 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:55:04 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:55:04 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:55:05 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:55:05 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52243.
2025-03-29 12:55:05 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52243
2025-03-29 12:55:05 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:55:05 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52243, None)
2025-03-29 12:55:05 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52243 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52243, None)
2025-03-29 12:55:05 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52243, None)
2025-03-29 12:55:05 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52243, None)
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6badba10{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52a33c3f{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19a20bb2{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3eb3232b{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60bb7995{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67774e29{/static,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e8b3b79{/,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@518ddd3b{/api,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@239f017e{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@772caabe{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1acb74ad{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:55:05 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@daf22f0{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d299393{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0e9707{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:55:09 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 12:55:09 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:55:09 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:55:09 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:55:09 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:55:09 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:55:09 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:55:09 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:55:09 [dispatcher-event-loop-11] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:55:09 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:55:09 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:55:09 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-e237e2b3-8cbf-4ea9-b84c-7936b20c66b4
2025-03-29 12:55:19 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:55:19 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:55:19 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:55:19 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:55:19 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:55:19 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:55:19 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:55:19 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:55:20 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52285.
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:55:20 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:55:20 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:55:20 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-e61cf3dd-a397-4dde-a059-9709e64d7f87
2025-03-29 12:55:20 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:55:20 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:55:20 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2513ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:55:21 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:55:21 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:55:21 [main] INFO  o.sparkproject.jetty.server.Server - Started @2640ms
2025-03-29 12:55:21 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:55:21 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:55:21 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:55:21 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52336.
2025-03-29 12:55:21 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52336
2025-03-29 12:55:21 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:55:21 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52336, None)
2025-03-29 12:55:21 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52336 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52336, None)
2025-03-29 12:55:21 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52336, None)
2025-03-29 12:55:21 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52336, None)
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:55:21 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:55:21 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:55:25 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 262.3785 ms
2025-03-29 12:55:26 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:23
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:23) with 1 output partitions
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:23)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:23), which has no missing parents
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:55:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:52336 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:23) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:55:26 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 12:55:26 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 187 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:26 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:23) finished in 0.465 s
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:55:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:23, took 0.508941 s
2025-03-29 12:55:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 33.5798 ms
2025-03-29 12:55:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.1908 ms
2025-03-29 12:55:26 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at test_logging.scala:26
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at test_logging.scala:26) with 1 output partitions
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at test_logging.scala:26)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at test_logging.scala:26), which has no missing parents
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-29 12:55:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:52336 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at test_logging.scala:26) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 12:55:26 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1773 bytes result sent to driver
2025-03-29 12:55:26 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:26 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at test_logging.scala:26) finished in 0.041 s
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 12:55:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at test_logging.scala:26, took 0.043894 s
2025-03-29 12:55:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.2937 ms
2025-03-29 12:55:26 [main] INFO  test_logging$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-29 12:55:26 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 18.8073 ms
2025-03-29 12:55:26 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:49
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at test_logging.scala:49) with 1 output partitions
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at test_logging.scala:49)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at test_logging.scala:49), which has no missing parents
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:55:26 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:52336 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at test_logging.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 12:55:26 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:26 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1828 bytes result sent to driver
2025-03-29 12:55:26 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 35 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:26 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at test_logging.scala:49) finished in 0.048 s
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:26 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 12:55:26 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at test_logging.scala:49, took 0.051100 s
2025-03-29 12:55:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.7229 ms
2025-03-29 12:55:27 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:44)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:52336 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 12:55:27 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1276 bytes result sent to driver
2025-03-29 12:55:27 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 71 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:27 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:44) finished in 0.099 s
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 12:55:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:44, took 0.105476 s
2025-03-29 12:55:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.2438 ms
2025-03-29 12:55:27 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:70
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (show at test_logging.scala:70) with 1 output partitions
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (show at test_logging.scala:70)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[16] at show at test_logging.scala:70), which has no missing parents
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:52336 (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at show at test_logging.scala:70) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-29 12:55:27 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1455 bytes result sent to driver
2025-03-29 12:55:27 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:27 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (show at test_logging.scala:70) finished in 0.041 s
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-29 12:55:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: show at test_logging.scala:70, took 0.043991 s
2025-03-29 12:55:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.3367 ms
2025-03-29 12:55:27 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (save at get_df_from_tablename.scala:44)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[21] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 25.7 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:52336 (size: 11.1 KiB, free: 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-29 12:55:27 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1276 bytes result sent to driver
2025-03-29 12:55:27 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 35 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:27 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (save at get_df_from_tablename.scala:44) finished in 0.046 s
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-29 12:55:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: save at get_df_from_tablename.scala:44, took 0.049933 s
2025-03-29 12:55:27 [main] INFO  test_logging$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-29 12:55:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.5006 ms
2025-03-29 12:55:27 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:49
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (show at test_logging.scala:49) with 1 output partitions
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (show at test_logging.scala:49)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[24] at show at test_logging.scala:49), which has no missing parents
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:52336 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at show at test_logging.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-29 12:55:27 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1412 bytes result sent to driver
2025-03-29 12:55:27 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:27 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (show at test_logging.scala:49) finished in 0.034 s
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-29 12:55:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: show at test_logging.scala:49, took 0.034101 s
2025-03-29 12:55:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.3786 ms
2025-03-29 12:55:27 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (save at get_df_from_tablename.scala:44)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[29] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:55:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:52336 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[29] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-29 12:55:27 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:27 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 1276 bytes result sent to driver
2025-03-29 12:55:27 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 29 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:27 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (save at get_df_from_tablename.scala:44) finished in 0.046 s
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-29 12:55:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: save at get_df_from_tablename.scala:44, took 0.050807 s
2025-03-29 12:55:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.3331 ms
2025-03-29 12:55:28 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:70
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (show at test_logging.scala:70) with 1 output partitions
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (show at test_logging.scala:70)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[32] at show at test_logging.scala:70), which has no missing parents
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:52336 (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[32] at show at test_logging.scala:70) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-29 12:55:28 [dispatcher-event-loop-14] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1455 bytes result sent to driver
2025-03-29 12:55:28 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 25 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:28 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (show at test_logging.scala:70) finished in 0.033 s
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-29 12:55:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: show at test_logging.scala:70, took 0.036569 s
2025-03-29 12:55:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.8406 ms
2025-03-29 12:55:28 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (save at get_df_from_tablename.scala:44)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[37] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 25.7 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:52336 (size: 11.1 KiB, free: 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[37] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
2025-03-29 12:55:28 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 1233 bytes result sent to driver
2025-03-29 12:55:28 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 32 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:28 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 9 (save at get_df_from_tablename.scala:44) finished in 0.046 s
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished
2025-03-29 12:55:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: save at get_df_from_tablename.scala:44, took 0.049699 s
2025-03-29 12:55:28 [main] INFO  test_logging$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-29 12:55:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.1878 ms
2025-03-29 12:55:28 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:49
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (show at test_logging.scala:49) with 1 output partitions
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (show at test_logging.scala:49)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[40] at show at test_logging.scala:49), which has no missing parents
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:52336 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[40] at show at test_logging.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 1 tasks resource profile 0
2025-03-29 12:55:28 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 10) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 10)
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 10). 1455 bytes result sent to driver
2025-03-29 12:55:28 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 10) in 29 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:28 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 10 (show at test_logging.scala:49) finished in 0.029 s
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 10: Stage finished
2025-03-29 12:55:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: show at test_logging.scala:49, took 0.032514 s
2025-03-29 12:55:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.8114 ms
2025-03-29 12:55:28 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 11 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (save at get_df_from_tablename.scala:44)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[45] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:52336 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[45] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-03-29 12:55:28 [dispatcher-event-loop-7] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 1233 bytes result sent to driver
2025-03-29 12:55:28 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:28 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (save at get_df_from_tablename.scala:44) finished in 0.048 s
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-03-29 12:55:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 finished: save at get_df_from_tablename.scala:44, took 0.042755 s
2025-03-29 12:55:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.3542 ms
2025-03-29 12:55:28 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:70
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 12 (show at test_logging.scala:70) with 1 output partitions
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 12 (show at test_logging.scala:70)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[48] at show at test_logging.scala:70), which has no missing parents
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:52336 (size: 7.3 KiB, free: 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[48] at show at test_logging.scala:70) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
2025-03-29 12:55:28 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 12.0 (TID 12) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 12)
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 12). 1455 bytes result sent to driver
2025-03-29 12:55:28 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 12.0 (TID 12) in 23 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:28 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 12 (show at test_logging.scala:70) finished in 0.037 s
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
2025-03-29 12:55:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 finished: show at test_logging.scala:70, took 0.033103 s
2025-03-29 12:55:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.6197 ms
2025-03-29 12:55:28 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 13 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 13 (save at get_df_from_tablename.scala:44)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[53] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 25.7 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on YAU:52336 (size: 11.1 KiB, free: 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[53] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
2025-03-29 12:55:28 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 13.0 (TID 13) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 13)
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 13). 1233 bytes result sent to driver
2025-03-29 12:55:28 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 13.0 (TID 13) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:28 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 13 (save at get_df_from_tablename.scala:44) finished in 0.038 s
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
2025-03-29 12:55:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 finished: save at get_df_from_tablename.scala:44, took 0.039420 s
2025-03-29 12:55:28 [main] INFO  test_logging$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-29 12:55:28 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.675 ms
2025-03-29 12:55:28 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:49
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 14 (show at test_logging.scala:49) with 1 output partitions
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 14 (show at test_logging.scala:49)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[56] at show at test_logging.scala:49), which has no missing parents
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:55:28 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on YAU:52336 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at show at test_logging.scala:49) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
2025-03-29 12:55:28 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 14.0 (TID 14) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 14)
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:28 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 14). 1455 bytes result sent to driver
2025-03-29 12:55:28 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 14.0 (TID 14) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:28 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 14 (show at test_logging.scala:49) finished in 0.032 s
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:28 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
2025-03-29 12:55:28 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 finished: show at test_logging.scala:49, took 0.035357 s
2025-03-29 12:55:29 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.9693 ms
2025-03-29 12:55:29 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 15 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 15 (save at get_df_from_tablename.scala:44)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[61] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 12:55:29 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on YAU:52336 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[61] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
2025-03-29 12:55:29 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 15.0 (TID 15) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 15)
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 15). 1233 bytes result sent to driver
2025-03-29 12:55:29 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 15.0 (TID 15) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:29 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 15 (save at get_df_from_tablename.scala:44) finished in 0.042 s
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
2025-03-29 12:55:29 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 finished: save at get_df_from_tablename.scala:44, took 0.046355 s
2025-03-29 12:55:29 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.5142 ms
2025-03-29 12:55:29 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:70
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 16 (show at test_logging.scala:70) with 1 output partitions
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 16 (show at test_logging.scala:70)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 16 (MapPartitionsRDD[64] at show at test_logging.scala:70), which has no missing parents
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 4.5 GiB)
2025-03-29 12:55:29 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on YAU:52336 (size: 7.3 KiB, free: 4.5 GiB)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 16 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[64] at show at test_logging.scala:70) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 16.0 with 1 tasks resource profile 0
2025-03-29 12:55:29 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 16.0 (TID 16) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 16)
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 16). 1412 bytes result sent to driver
2025-03-29 12:55:29 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 16.0 (TID 16) in 15 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:29 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 16 (show at test_logging.scala:70) finished in 0.019 s
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 16: Stage finished
2025-03-29 12:55:29 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 finished: show at test_logging.scala:70, took 0.029387 s
2025-03-29 12:55:29 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.4937 ms
2025-03-29 12:55:29 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 17 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 17 (save at get_df_from_tablename.scala:44)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 17 (MapPartitionsRDD[69] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 25.7 KiB, free 4.5 GiB)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)
2025-03-29 12:55:29 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on YAU:52336 (size: 11.1 KiB, free: 4.5 GiB)
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[69] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 17.0 with 1 tasks resource profile 0
2025-03-29 12:55:29 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 17.0 (TID 17) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 17)
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:55:29 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 17). 1233 bytes result sent to driver
2025-03-29 12:55:29 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 17.0 (TID 17) in 34 ms on YAU (executor driver) (1/1)
2025-03-29 12:55:29 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 17 (save at get_df_from_tablename.scala:44) finished in 0.043 s
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:55:29 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 17: Stage finished
2025-03-29 12:55:29 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 17 finished: save at get_df_from_tablename.scala:44, took 0.041619 s
2025-03-29 12:55:29 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:55:29 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:55:29 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:55:29 [dispatcher-event-loop-13] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:55:29 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:55:29 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:55:29 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:55:29 [dispatcher-event-loop-3] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:55:29 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:55:29 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:55:29 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-4b97b31c-feed-4901-b672-b0a8b3b6e156
2025-03-29 12:59:31 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 12:59:31 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:59:31 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 12:59:31 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 12:59:31 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 12:59:31 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 12:59:31 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 12:59:31 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 12:59:31 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 12:59:31 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 12:59:31 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 12:59:31 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 12:59:31 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 12:59:32 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52429.
2025-03-29 12:59:32 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 12:59:32 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 12:59:32 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 12:59:32 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 12:59:32 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 12:59:32 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-6e416d4f-9dcd-4f71-b11f-fb8aa6907c74
2025-03-29 12:59:32 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 12:59:32 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 12:59:32 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2560ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 12:59:32 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 12:59:32 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 12:59:32 [main] INFO  o.sparkproject.jetty.server.Server - Started @2686ms
2025-03-29 12:59:32 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:59:32 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 12:59:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 12:59:33 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 12:59:33 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52480.
2025-03-29 12:59:33 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52480
2025-03-29 12:59:33 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 12:59:33 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52480, None)
2025-03-29 12:59:33 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52480 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52480, None)
2025-03-29 12:59:33 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52480, None)
2025-03-29 12:59:33 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52480, None)
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 12:59:33 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 12:59:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 12:59:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 250.1483 ms
2025-03-29 12:59:37 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 12:59:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:52480 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:59:37 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 12:59:37 [dispatcher-event-loop-7] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1541 bytes result sent to driver
2025-03-29 12:59:38 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 197 ms on YAU (executor driver) (1/1)
2025-03-29 12:59:38 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.477 s
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 12:59:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.518539 s
2025-03-29 12:59:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.3813 ms
2025-03-29 12:59:38 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:33
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:33) with 1 output partitions
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:33)
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:33), which has no missing parents
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 12:59:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:52480 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:33) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 12:59:38 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1455 bytes result sent to driver
2025-03-29 12:59:38 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on YAU (executor driver) (1/1)
2025-03-29 12:59:38 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:33) finished in 0.048 s
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 12:59:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:33, took 0.050388 s
2025-03-29 12:59:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.4624 ms
2025-03-29 12:59:38 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:44)
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 12:59:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:52480 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 12:59:38 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.083 ms
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 12:59:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1276 bytes result sent to driver
2025-03-29 12:59:38 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 113 ms on YAU (executor driver) (1/1)
2025-03-29 12:59:38 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:44) finished in 0.179 s
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 12:59:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 12:59:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:44, took 0.180034 s
2025-03-29 12:59:38 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 12:59:38 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 12:59:38 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 12:59:38 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 12:59:38 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 12:59:38 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 12:59:38 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 12:59:38 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 12:59:38 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 12:59:38 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 12:59:38 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 12:59:38 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-e6a9984f-a89e-4186-92ee-791478ccf177
2025-03-29 13:00:04 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:00:05 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:00:05 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:00:05 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:00:05 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:00:05 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:00:05 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:00:05 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:00:05 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:00:05 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:00:05 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:00:05 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:00:05 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:00:06 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52528.
2025-03-29 13:00:06 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:00:06 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:00:06 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:00:06 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:00:06 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:00:06 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-f2300d85-c72b-4aa9-bb50-c35264eb675c
2025-03-29 13:00:06 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:00:06 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:00:06 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2491ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:00:06 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:00:06 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:00:06 [main] INFO  o.sparkproject.jetty.server.Server - Started @2610ms
2025-03-29 13:00:06 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:00:06 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:00:06 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:00:06 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52579.
2025-03-29 13:00:06 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52579
2025-03-29 13:00:06 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:00:06 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52579, None)
2025-03-29 13:00:06 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52579 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52579, None)
2025-03-29 13:00:06 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52579, None)
2025-03-29 13:00:06 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52579, None)
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:00:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:07 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:00:07 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:00:07 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:00:07 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:07 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:00:07 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:00:07 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:00:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 259.1468 ms
2025-03-29 13:00:11 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:00:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:52579 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:00:11 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:00:11 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:00:11 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:00:11 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:00:11 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 190 ms on YAU (executor driver) (1/1)
2025-03-29 13:00:11 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.481 s
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:00:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:00:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.522589 s
2025-03-29 13:00:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 33.2859 ms
2025-03-29 13:00:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.7802 ms
2025-03-29 13:00:12 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:33
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:33) with 1 output partitions
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:33)
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:33), which has no missing parents
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:00:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:52579 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:33) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:00:12 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:00:12 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:00:12 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:00:12 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1867 bytes result sent to driver
2025-03-29 13:00:12 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on YAU (executor driver) (1/1)
2025-03-29 13:00:12 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:33) finished in 0.062 s
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:00:12 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:33, took 0.053225 s
2025-03-29 13:00:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.5627 ms
2025-03-29 13:00:12 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:44)
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 13:00:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:52579 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:00:12 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:00:12 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:00:12 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.225 ms
2025-03-29 13:00:12 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:00:12 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1319 bytes result sent to driver
2025-03-29 13:00:12 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 109 ms on YAU (executor driver) (1/1)
2025-03-29 13:00:12 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:44) finished in 0.161 s
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:00:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:00:12 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:44, took 0.166224 s
2025-03-29 13:00:12 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:00:12 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:00:12 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:00:12 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:00:12 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:00:12 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:00:12 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:00:12 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:00:12 [dispatcher-event-loop-3] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:00:12 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:00:12 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:00:12 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-e9cbae22-e909-48bd-aafd-952a67a46d78
2025-03-29 13:02:41 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:02:41 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:02:41 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:02:41 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:02:41 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:02:41 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:02:41 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:02:41 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:02:41 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:02:41 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:02:41 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:02:41 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:02:41 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:02:42 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52630.
2025-03-29 13:02:42 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:02:42 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:02:42 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:02:42 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:02:42 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:02:42 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-6e136a01-5c13-4d7a-b340-8fb4b4bbe2ea
2025-03-29 13:02:42 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:02:42 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:02:42 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2550ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:02:42 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:02:42 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:02:42 [main] INFO  o.sparkproject.jetty.server.Server - Started @2680ms
2025-03-29 13:02:42 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:02:42 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:02:42 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:02:42 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:02:42 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:02:42 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52681.
2025-03-29 13:02:42 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52681
2025-03-29 13:02:42 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:02:42 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52681, None)
2025-03-29 13:02:42 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52681 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52681, None)
2025-03-29 13:02:42 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52681, None)
2025-03-29 13:02:42 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52681, None)
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:02:43 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:02:43 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:02:47 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 252.2249 ms
2025-03-29 13:02:47 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:02:47 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:52681 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:02:47 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:02:48 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:02:48 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 190 ms on YAU (executor driver) (1/1)
2025-03-29 13:02:48 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.464 s
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:02:48 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.502356 s
2025-03-29 13:02:48 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.8928 ms
2025-03-29 13:02:48 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.7958 ms
2025-03-29 13:02:48 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:02:48 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:52681 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:02:48 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1823 bytes result sent to driver
2025-03-29 13:02:48 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 38 ms on YAU (executor driver) (1/1)
2025-03-29 13:02:48 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.048 s
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:02:48 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.053271 s
2025-03-29 13:02:48 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.8891 ms
2025-03-29 13:02:48 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:44
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:44) with 1 output partitions
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:44)
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44), which has no missing parents
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 13:02:48 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:52681 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:44) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:02:48 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 18.8269 ms
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:02:48 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1276 bytes result sent to driver
2025-03-29 13:02:48 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 87 ms on YAU (executor driver) (1/1)
2025-03-29 13:02:48 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:44) finished in 0.144 s
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:02:48 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:02:48 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:44, took 0.149716 s
2025-03-29 13:02:48 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:02:48 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:02:48 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:02:48 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:02:48 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:02:48 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:02:48 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:02:48 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:02:48 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:02:48 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:02:48 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:02:48 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-2eac6265-503f-4316-84ad-0cd128a4db28
2025-03-29 13:08:37 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:08:38 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:08:38 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:08:38 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:08:38 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:08:38 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:08:38 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:08:38 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52739.
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:08:38 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:08:38 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:08:38 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:08:38 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-4bf490ba-4d9e-4d63-a58a-7d787ab6bac2
2025-03-29 13:08:39 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:08:39 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:08:39 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2572ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:08:39 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:08:39 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:08:39 [main] INFO  o.sparkproject.jetty.server.Server - Started @2700ms
2025-03-29 13:08:39 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:08:39 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:08:39 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:08:39 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52790.
2025-03-29 13:08:39 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52790
2025-03-29 13:08:39 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:08:39 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52790, None)
2025-03-29 13:08:39 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52790 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52790, None)
2025-03-29 13:08:39 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52790, None)
2025-03-29 13:08:39 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52790, None)
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:08:39 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:08:39 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:08:44 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 259.5827 ms
2025-03-29 13:08:44 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:08:44 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:52790 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:08:44 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:08:44 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:08:44 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:08:44 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1541 bytes result sent to driver
2025-03-29 13:08:44 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 198 ms on YAU (executor driver) (1/1)
2025-03-29 13:08:44 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.479 s
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:08:44 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.518818 s
2025-03-29 13:08:44 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.0335 ms
2025-03-29 13:08:44 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:08:44 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:52790 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:08:44 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:08:44 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:08:44 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:08:44 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1455 bytes result sent to driver
2025-03-29 13:08:44 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 13:08:44 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.045 s
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:08:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:08:44 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.048242 s
2025-03-29 13:08:45 [main] INFO  org.apache.spark.SparkContext - Starting job: show at get_df_from_tablename.scala:34
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at get_df_from_tablename.scala:34) with 1 output partitions
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at get_df_from_tablename.scala:34)
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34), which has no missing parents
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:08:45 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:52790 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:08:45 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:08:45 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:08:45 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:08:45 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1455 bytes result sent to driver
2025-03-29 13:08:45 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 24 ms on YAU (executor driver) (1/1)
2025-03-29 13:08:45 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at get_df_from_tablename.scala:34) finished in 0.032 s
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:08:45 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at get_df_from_tablename.scala:34, took 0.037031 s
2025-03-29 13:08:45 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.1149 ms
2025-03-29 13:08:45 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:45
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:45) with 1 output partitions
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:45)
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:45), which has no missing parents
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 13:08:45 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:52790 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:45) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:08:45 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:08:45 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:08:45 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 35.4628 ms
2025-03-29 13:08:45 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:08:45 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1276 bytes result sent to driver
2025-03-29 13:08:45 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 111 ms on YAU (executor driver) (1/1)
2025-03-29 13:08:45 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:45) finished in 0.149 s
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:08:45 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:08:45 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:45, took 0.153674 s
2025-03-29 13:08:45 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:08:45 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:08:45 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:08:45 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:08:45 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:08:45 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:08:45 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:08:45 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:08:45 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:08:45 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:08:45 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:08:45 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-7b5edde8-ef6b-4aa6-9c67-adfbfc4a461b
2025-03-29 13:09:35 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:09:36 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:09:36 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:09:36 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:09:36 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:09:36 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:09:36 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:09:36 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:09:36 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:09:36 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:09:36 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:09:36 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:09:36 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:09:36 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52839.
2025-03-29 13:09:36 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:09:37 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:09:37 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:09:37 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:09:37 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:09:37 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-af449b34-a1a0-4499-97d9-4e66d3f743f9
2025-03-29 13:09:37 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:09:37 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:09:37 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2472ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:09:37 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:09:37 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:09:37 [main] INFO  o.sparkproject.jetty.server.Server - Started @2599ms
2025-03-29 13:09:37 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:09:37 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:09:37 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:09:37 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52890.
2025-03-29 13:09:37 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:52890
2025-03-29 13:09:37 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:09:37 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 52890, None)
2025-03-29 13:09:37 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:52890 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 52890, None)
2025-03-29 13:09:37 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 52890, None)
2025-03-29 13:09:37 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 52890, None)
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:09:37 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:09:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:09:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:09:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 265.7392 ms
2025-03-29 13:09:42 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:09:42 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:52890 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:09:42 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:09:42 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:09:42 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:09:42 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:09:42 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 189 ms on YAU (executor driver) (1/1)
2025-03-29 13:09:42 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.445 s
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:09:42 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:09:42 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.484211 s
2025-03-29 13:09:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 35.4101 ms
2025-03-29 13:09:43 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.7789 ms
2025-03-29 13:09:43 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:09:43 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:52890 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:09:43 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1824 bytes result sent to driver
2025-03-29 13:09:43 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on YAU (executor driver) (1/1)
2025-03-29 13:09:43 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.045 s
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:09:43 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.048934 s
2025-03-29 13:09:43 [main] INFO  org.apache.spark.SparkContext - Starting job: show at get_df_from_tablename.scala:34
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at get_df_from_tablename.scala:34) with 1 output partitions
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at get_df_from_tablename.scala:34)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34), which has no missing parents
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:09:43 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:52890 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:09:43 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1871 bytes result sent to driver
2025-03-29 13:09:43 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 13:09:43 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at get_df_from_tablename.scala:34) finished in 0.036 s
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:09:43 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at get_df_from_tablename.scala:34, took 0.039067 s
2025-03-29 13:09:43 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.8143 ms
2025-03-29 13:09:43 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:45
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:45) with 1 output partitions
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:45)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:45), which has no missing parents
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 13:09:43 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:52890 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:45) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:09:43 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.7586 ms
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:09:43 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1319 bytes result sent to driver
2025-03-29 13:09:43 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 93 ms on YAU (executor driver) (1/1)
2025-03-29 13:09:43 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:45) finished in 0.135 s
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:09:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:09:43 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:45, took 0.139867 s
2025-03-29 13:09:43 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:09:43 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:09:43 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:09:43 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:09:43 [dispatcher-event-loop-7] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:09:43 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:09:43 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:09:43 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:09:43 [dispatcher-event-loop-9] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:09:43 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:09:43 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:09:43 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-9be14a31-67dd-40f1-b4ae-0a80cdd76b32
2025-03-29 13:13:03 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:13:04 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:13:04 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:13:04 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:13:04 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:13:04 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:13:04 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:13:04 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:13:04 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:13:04 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:13:04 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:13:04 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:13:04 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:13:05 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52956.
2025-03-29 13:13:05 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:13:05 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:13:05 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:13:05 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:13:05 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:13:05 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-08589b08-9146-43b7-9eca-ef0d5e698720
2025-03-29 13:13:05 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:13:05 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:13:05 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2598ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:13:05 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:13:05 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:13:05 [main] INFO  o.sparkproject.jetty.server.Server - Started @2724ms
2025-03-29 13:13:05 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:13:05 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:13:05 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:13:05 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53007.
2025-03-29 13:13:05 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53007
2025-03-29 13:13:05 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:13:05 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53007, None)
2025-03-29 13:13:05 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53007 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53007, None)
2025-03-29 13:13:05 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53007, None)
2025-03-29 13:13:05 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53007, None)
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:13:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:06 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:13:06 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:13:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:13:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:13:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:13:10 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 274.3797 ms
2025-03-29 13:13:10 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:13:10 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53007 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:13:10 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:13:10 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:13:10 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1541 bytes result sent to driver
2025-03-29 13:13:11 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 200 ms on YAU (executor driver) (1/1)
2025-03-29 13:13:11 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.506 s
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:13:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.553174 s
2025-03-29 13:13:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.7653 ms
2025-03-29 13:13:11 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:13:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53007 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:13:11 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1412 bytes result sent to driver
2025-03-29 13:13:11 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on YAU (executor driver) (1/1)
2025-03-29 13:13:11 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.049 s
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:13:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.052650 s
2025-03-29 13:13:11 [main] INFO  org.apache.spark.SparkContext - Starting job: show at get_df_from_tablename.scala:34
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at get_df_from_tablename.scala:34) with 1 output partitions
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at get_df_from_tablename.scala:34)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34), which has no missing parents
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:13:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53007 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:13:11 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1412 bytes result sent to driver
2025-03-29 13:13:11 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on YAU (executor driver) (1/1)
2025-03-29 13:13:11 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at get_df_from_tablename.scala:34) finished in 0.039 s
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:13:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at get_df_from_tablename.scala:34, took 0.043039 s
2025-03-29 13:13:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.892 ms
2025-03-29 13:13:11 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:46
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:46) with 1 output partitions
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:46)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:46), which has no missing parents
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 13:13:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:53007 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:46) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:13:11 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 34.5129 ms
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:13:11 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1319 bytes result sent to driver
2025-03-29 13:13:11 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 120 ms on YAU (executor driver) (1/1)
2025-03-29 13:13:11 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:46) finished in 0.167 s
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:13:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:13:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:46, took 0.172463 s
2025-03-29 13:13:11 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:13:11 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:13:11 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:13:11 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:13:11 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:13:12 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:13:12 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:13:12 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:13:12 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:13:12 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:13:12 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:13:12 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-6810ef26-3053-4d7f-8b59-a3778d9671dc
2025-03-29 13:13:31 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:13:31 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:13:31 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:13:31 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:13:31 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:13:31 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:13:31 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:13:31 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:13:31 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:13:31 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:13:31 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:13:31 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:13:31 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:13:32 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53056.
2025-03-29 13:13:32 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:13:32 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:13:32 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:13:32 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:13:32 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:13:32 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-84ca309a-f695-4dad-b1ab-7d34f14eec98
2025-03-29 13:13:32 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:13:32 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:13:32 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2444ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:13:32 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:13:32 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:13:32 [main] INFO  o.sparkproject.jetty.server.Server - Started @2568ms
2025-03-29 13:13:32 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:13:32 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:13:32 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:13:32 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53107.
2025-03-29 13:13:32 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53107
2025-03-29 13:13:32 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:13:32 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53107, None)
2025-03-29 13:13:32 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53107 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53107, None)
2025-03-29 13:13:32 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53107, None)
2025-03-29 13:13:32 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53107, None)
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:13:33 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:13:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:13:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 277.7971 ms
2025-03-29 13:13:37 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:13:37 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53107 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:13:37 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:13:37 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:13:37 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:13:38 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 197 ms on YAU (executor driver) (1/1)
2025-03-29 13:13:38 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.463 s
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:13:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.507366 s
2025-03-29 13:13:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 35.5769 ms
2025-03-29 13:13:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.9817 ms
2025-03-29 13:13:38 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:13:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53107 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:13:38 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1823 bytes result sent to driver
2025-03-29 13:13:38 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 13:13:38 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.045 s
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:13:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.049173 s
2025-03-29 13:13:38 [main] INFO  org.apache.spark.SparkContext - Starting job: show at get_df_from_tablename.scala:34
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at get_df_from_tablename.scala:34) with 1 output partitions
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at get_df_from_tablename.scala:34)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34), which has no missing parents
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:13:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53107 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:13:38 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1828 bytes result sent to driver
2025-03-29 13:13:38 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 24 ms on YAU (executor driver) (1/1)
2025-03-29 13:13:38 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at get_df_from_tablename.scala:34) finished in 0.032 s
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:13:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at get_df_from_tablename.scala:34, took 0.035303 s
2025-03-29 13:13:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.8275 ms
2025-03-29 13:13:38 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:46
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:46) with 1 output partitions
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:46)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:46), which has no missing parents
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.1 KiB, free 4.5 GiB)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 4.5 GiB)
2025-03-29 13:13:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:53107 (size: 10.9 KiB, free: 4.5 GiB)
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:46) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:13:38 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.4826 ms
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:13:38 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1319 bytes result sent to driver
2025-03-29 13:13:38 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 86 ms on YAU (executor driver) (1/1)
2025-03-29 13:13:38 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:46) finished in 0.136 s
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:13:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:13:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:46, took 0.140058 s
2025-03-29 13:13:38 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:13:38 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:13:39 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:13:39 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:13:39 [dispatcher-event-loop-1] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:13:39 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:13:39 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:13:39 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:13:39 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:13:39 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:13:39 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:13:39 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-3b4fea4a-02d6-4de7-9a7e-85ef83006ae9
2025-03-29 13:15:06 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:15:06 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:15:06 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:15:06 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:15:06 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:15:06 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:15:06 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:15:06 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:15:06 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:15:06 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:15:06 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:15:06 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:15:06 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:15:07 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53158.
2025-03-29 13:15:07 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:15:07 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:15:07 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:15:07 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:15:07 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:15:07 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-4fdca764-22b5-4620-a322-cfbb194564de
2025-03-29 13:15:07 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:15:07 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:15:07 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2501ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:15:07 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:15:07 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:15:07 [main] INFO  o.sparkproject.jetty.server.Server - Started @2624ms
2025-03-29 13:15:07 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:15:07 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:15:07 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:15:08 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:15:08 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53209.
2025-03-29 13:15:08 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53209
2025-03-29 13:15:08 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:15:08 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53209, None)
2025-03-29 13:15:08 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53209 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53209, None)
2025-03-29 13:15:08 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53209, None)
2025-03-29 13:15:08 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53209, None)
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:15:08 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:15:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 267.0533 ms
2025-03-29 13:15:12 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:15:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:15:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:15:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:15:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:15:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:15:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53209 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:15:13 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:15:13 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 202 ms on YAU (executor driver) (1/1)
2025-03-29 13:15:13 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.482 s
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:15:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.522763 s
2025-03-29 13:15:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.2699 ms
2025-03-29 13:15:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.602 ms
2025-03-29 13:15:13 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:15:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53209 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:15:13 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:15:13 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 13:15:13 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.043 s
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:15:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.047051 s
2025-03-29 13:15:13 [main] INFO  org.apache.spark.SparkContext - Starting job: show at get_df_from_tablename.scala:34
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at get_df_from_tablename.scala:34) with 1 output partitions
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at get_df_from_tablename.scala:34)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34), which has no missing parents
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:15:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53209 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:15:13 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:15:13 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1828 bytes result sent to driver
2025-03-29 13:15:13 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 13:15:13 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at get_df_from_tablename.scala:34) finished in 0.034 s
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:15:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at get_df_from_tablename.scala:34, took 0.038216 s
2025-03-29 13:15:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.0058 ms
2025-03-29 13:15:13 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:47
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:47) with 1 output partitions
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:47)
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:47), which has no missing parents
2025-03-29 13:15:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:15:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:15:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:53209 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:15:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:15:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:47) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:15:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:15:14 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:15:14 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:15:14 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.5778 ms
2025-03-29 13:15:14 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:15:14 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1362 bytes result sent to driver
2025-03-29 13:15:14 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 247 ms on YAU (executor driver) (1/1)
2025-03-29 13:15:14 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:15:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:47) finished in 0.304 s
2025-03-29 13:15:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:15:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:15:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:47, took 0.308664 s
2025-03-29 13:15:14 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:15:14 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:15:14 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:15:14 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:15:14 [dispatcher-event-loop-1] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:15:14 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:15:14 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:15:14 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:15:14 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:15:14 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:15:14 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:15:14 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-eef67340-4e37-4d5e-a4cf-8e431e70e89a
2025-03-29 13:15:49 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:15:49 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:15:49 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:15:49 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:15:49 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:15:49 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:15:49 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:15:49 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:15:49 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:15:49 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:15:49 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:15:49 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:15:49 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:15:50 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53261.
2025-03-29 13:15:50 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:15:50 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:15:50 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:15:50 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:15:50 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:15:50 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-4afe8bcf-5afc-4156-9e54-1a8ee13af153
2025-03-29 13:15:50 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:15:50 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:15:50 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2432ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:15:50 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:15:50 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:15:50 [main] INFO  o.sparkproject.jetty.server.Server - Started @2537ms
2025-03-29 13:15:50 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:15:50 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:15:50 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:15:51 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:15:51 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53312.
2025-03-29 13:15:51 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53312
2025-03-29 13:15:51 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:15:51 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53312, None)
2025-03-29 13:15:51 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53312 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53312, None)
2025-03-29 13:15:51 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53312, None)
2025-03-29 13:15:51 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53312, None)
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:15:51 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:15:51 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:15:55 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 259.8216 ms
2025-03-29 13:15:55 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:15:55 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:15:55 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:15:55 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:15:55 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:15:55 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:15:56 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53312 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:15:56 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1901 bytes result sent to driver
2025-03-29 13:15:56 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 276 ms on YAU (executor driver) (1/1)
2025-03-29 13:15:56 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.560 s
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:15:56 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.607137 s
2025-03-29 13:15:56 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.2352 ms
2025-03-29 13:15:56 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.0589 ms
2025-03-29 13:15:56 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:15:56 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53312 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:15:56 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1829 bytes result sent to driver
2025-03-29 13:15:56 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on YAU (executor driver) (1/1)
2025-03-29 13:15:56 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.046 s
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:15:56 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.049983 s
2025-03-29 13:15:56 [main] INFO  org.apache.spark.SparkContext - Starting job: show at get_df_from_tablename.scala:34
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at get_df_from_tablename.scala:34) with 1 output partitions
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at get_df_from_tablename.scala:34)
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34), which has no missing parents
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:15:56 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53312 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at get_df_from_tablename.scala:34) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:15:56 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:15:56 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1834 bytes result sent to driver
2025-03-29 13:15:56 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on YAU (executor driver) (1/1)
2025-03-29 13:15:56 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at get_df_from_tablename.scala:34) finished in 0.037 s
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:15:56 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:15:56 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at get_df_from_tablename.scala:34, took 0.040867 s
2025-03-29 13:15:57 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.3759 ms
2025-03-29 13:15:57 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:47
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:47) with 1 output partitions
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:47)
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:47), which has no missing parents
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:15:57 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:53312 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:47) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:15:57 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:15:57 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:15:57 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.5509 ms
2025-03-29 13:15:57 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:15:57 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1276 bytes result sent to driver
2025-03-29 13:15:57 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 71 ms on YAU (executor driver) (1/1)
2025-03-29 13:15:57 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:47) finished in 0.112 s
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:15:57 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:15:57 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:47, took 0.117410 s
2025-03-29 13:15:57 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:15:57 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:15:57 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:15:57 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:15:57 [dispatcher-event-loop-2] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:15:57 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:15:57 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:15:57 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:15:57 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:15:57 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:15:57 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:15:57 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-36e33f1a-eb6c-4228-85c3-63e1f3c1848b
2025-03-29 13:19:29 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:19:29 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:19:29 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:19:29 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:19:29 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:19:29 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:19:29 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:19:29 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:19:29 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:19:29 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:19:29 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:19:29 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:19:29 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:19:30 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53365.
2025-03-29 13:19:30 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:19:30 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:19:30 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:19:30 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:19:30 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:19:30 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-b202bd92-c866-4165-b653-dc7701c85a1b
2025-03-29 13:19:30 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:19:30 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:19:30 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2436ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:19:30 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:19:30 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:19:30 [main] INFO  o.sparkproject.jetty.server.Server - Started @2564ms
2025-03-29 13:19:30 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:19:30 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:19:30 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:19:30 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53416.
2025-03-29 13:19:30 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53416
2025-03-29 13:19:30 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:19:30 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53416, None)
2025-03-29 13:19:30 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53416 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53416, None)
2025-03-29 13:19:30 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53416, None)
2025-03-29 13:19:30 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53416, None)
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:19:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:19:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:31 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:19:31 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:19:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:19:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:19:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:19:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:19:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 248.3006 ms
2025-03-29 13:19:35 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:19:35 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53416 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:19:35 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:19:35 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:19:35 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:19:35 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:19:35 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 195 ms on YAU (executor driver) (1/1)
2025-03-29 13:19:35 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.474 s
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:19:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:19:35 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.514072 s
2025-03-29 13:19:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.8407 ms
2025-03-29 13:19:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.0261 ms
2025-03-29 13:19:36 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:19:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53416 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:19:36 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:19:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:19:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:19:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:19:36 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-29 13:19:36 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.047 s
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:19:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.051122 s
2025-03-29 13:19:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.2602 ms
2025-03-29 13:19:36 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:56
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:56) with 1 output partitions
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:56)
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:56), which has no missing parents
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:19:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53416 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:56) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:19:36 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:19:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:19:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.0678 ms
2025-03-29 13:19:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:19:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1319 bytes result sent to driver
2025-03-29 13:19:36 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 89 ms on YAU (executor driver) (1/1)
2025-03-29 13:19:36 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:56) finished in 0.134 s
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:19:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:19:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:56, took 0.138875 s
2025-03-29 13:19:36 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:19:36 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:19:36 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:19:36 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:19:36 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:19:36 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:19:36 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:19:36 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:19:36 [dispatcher-event-loop-4] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:19:36 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:19:36 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:19:36 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-53613626-bd08-434b-9474-a8634acafc1f
2025-03-29 13:20:16 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:20:17 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:20:17 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:20:17 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:20:17 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:20:17 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:20:17 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:20:17 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:20:17 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:20:17 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:20:17 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:20:17 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:20:17 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:20:17 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53467.
2025-03-29 13:20:18 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:20:18 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:20:18 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:20:18 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:20:18 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:20:18 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-f79b3d52-e799-4713-aa0c-c279ab38a904
2025-03-29 13:20:18 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:20:18 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:20:18 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2529ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:20:18 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:20:18 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:20:18 [main] INFO  o.sparkproject.jetty.server.Server - Started @2628ms
2025-03-29 13:20:18 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:20:18 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c9e07c6{/,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:20:18 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:20:18 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53518.
2025-03-29 13:20:18 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53518
2025-03-29 13:20:18 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:20:18 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53518, None)
2025-03-29 13:20:18 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53518 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53518, None)
2025-03-29 13:20:18 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53518, None)
2025-03-29 13:20:18 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53518, None)
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1c9e07c6{/,null,STOPPED,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ebe067d{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6badba10{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52a33c3f{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19a20bb2{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3eb3232b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60bb7995{/static,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@345d053b{/,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e8b3b79{/api,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@45b15381{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@239f017e{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:20:18 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d08b4e6{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:19 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:20:19 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:20:19 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7645f03e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:20:19 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:19 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20ead579{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:20:19 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:20:19 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c52552f{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:20:23 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 283.814 ms
2025-03-29 13:20:23 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:20:23 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53518 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:20:23 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:20:23 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:20:23 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:20:23 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:20:23 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 221 ms on YAU (executor driver) (1/1)
2025-03-29 13:20:23 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.506 s
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:20:23 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:20:23 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.547109 s
2025-03-29 13:20:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.7114 ms
2025-03-29 13:20:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.1744 ms
2025-03-29 13:20:24 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:20:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53518 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:20:24 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:20:24 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:20:24 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:20:24 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1871 bytes result sent to driver
2025-03-29 13:20:24 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 50 ms on YAU (executor driver) (1/1)
2025-03-29 13:20:24 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.064 s
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:20:24 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.070721 s
2025-03-29 13:20:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.0592 ms
2025-03-29 13:20:24 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:56
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:56) with 1 output partitions
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:56)
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:56), which has no missing parents
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:20:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53518 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:56) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:20:24 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:20:24 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:20:24 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.7914 ms
2025-03-29 13:20:24 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:20:24 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1362 bytes result sent to driver
2025-03-29 13:20:24 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 237 ms on YAU (executor driver) (1/1)
2025-03-29 13:20:24 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:56) finished in 0.285 s
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:20:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:20:24 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:56, took 0.290612 s
2025-03-29 13:20:24 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:20:24 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:20:24 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:20:24 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:20:24 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:20:24 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:20:24 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:20:24 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:20:24 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:20:24 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:20:24 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:20:24 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-d2a7e40b-182f-4085-b81e-105fa7a6a879
2025-03-29 13:21:03 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:21:03 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:21:03 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:21:03 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:21:03 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:21:04 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:21:04 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:21:04 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:21:04 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53571.
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:21:04 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:21:04 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:21:04 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-c12518bc-931a-4566-8c83-21d188dac780
2025-03-29 13:21:04 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:21:04 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:21:05 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2561ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:21:05 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:21:05 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:21:05 [main] INFO  o.sparkproject.jetty.server.Server - Started @2719ms
2025-03-29 13:21:05 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:21:05 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:21:05 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:21:05 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53622.
2025-03-29 13:21:05 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53622
2025-03-29 13:21:05 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:21:05 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53622, None)
2025-03-29 13:21:05 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53622 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53622, None)
2025-03-29 13:21:05 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53622, None)
2025-03-29 13:21:05 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53622, None)
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6badba10{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52a33c3f{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19a20bb2{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3eb3232b{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60bb7995{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67774e29{/static,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e8b3b79{/,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@518ddd3b{/api,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@239f017e{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@772caabe{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1acb74ad{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:05 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:21:05 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:21:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:21:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@daf22f0{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:21:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d299393{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:21:06 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0e9707{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:21:10 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 257.2871 ms
2025-03-29 13:21:10 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:21:10 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53622 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:21:10 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:21:10 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:21:10 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:21:11 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:21:11 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1901 bytes result sent to driver
2025-03-29 13:21:11 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 276 ms on YAU (executor driver) (1/1)
2025-03-29 13:21:11 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.583 s
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:21:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.624381 s
2025-03-29 13:21:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 36.1968 ms
2025-03-29 13:21:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.3085 ms
2025-03-29 13:21:11 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:21:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53622 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:21:11 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:21:11 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:21:11 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:21:11 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1877 bytes result sent to driver
2025-03-29 13:21:11 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 13:21:11 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.044 s
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:21:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:21:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.047841 s
2025-03-29 13:21:11 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:21:11 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:21:11 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:21:11 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:21:11 [dispatcher-event-loop-13] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:21:11 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:21:11 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:21:11 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:21:11 [dispatcher-event-loop-1] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:21:11 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:21:11 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:21:11 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-0a09781b-a925-4894-9cf9-909fddd4142c
2025-03-29 13:22:24 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:22:24 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:22:24 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:22:24 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:22:24 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:22:24 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:22:24 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:22:24 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:22:24 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:22:24 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:22:24 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:22:24 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:22:24 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:22:25 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53687.
2025-03-29 13:22:25 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:22:25 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:22:25 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:22:25 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:22:25 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:22:25 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-8471dafb-94c5-4907-80b2-f1e8f276eee9
2025-03-29 13:22:25 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:22:25 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:22:25 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2590ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:22:25 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:22:25 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:22:25 [main] INFO  o.sparkproject.jetty.server.Server - Started @2694ms
2025-03-29 13:22:25 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:22:25 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:22:25 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c9e07c6{/,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:22:26 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:22:26 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53738.
2025-03-29 13:22:26 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53738
2025-03-29 13:22:26 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:22:26 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53738, None)
2025-03-29 13:22:26 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53738 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53738, None)
2025-03-29 13:22:26 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53738, None)
2025-03-29 13:22:26 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53738, None)
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1c9e07c6{/,null,STOPPED,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:22:26 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:22:26 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:22:30 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 251.5986 ms
2025-03-29 13:22:30 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:22:30 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53738 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:22:30 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:22:31 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:22:31 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 181 ms on YAU (executor driver) (1/1)
2025-03-29 13:22:31 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.455 s
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:22:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.497934 s
2025-03-29 13:22:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 37.8136 ms
2025-03-29 13:22:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.9843 ms
2025-03-29 13:22:31 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:22:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53738 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:22:31 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:22:31 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 44 ms on YAU (executor driver) (1/1)
2025-03-29 13:22:31 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.056 s
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:22:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.060013 s
2025-03-29 13:22:31 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.858 ms
2025-03-29 13:22:31 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:55
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:55) with 1 output partitions
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:55)
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:55), which has no missing parents
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:22:31 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53738 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:55) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:22:31 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 23.412 ms
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:22:31 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1319 bytes result sent to driver
2025-03-29 13:22:31 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 84 ms on YAU (executor driver) (1/1)
2025-03-29 13:22:31 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:55) finished in 0.143 s
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:22:31 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:22:31 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:55, took 0.147885 s
2025-03-29 13:22:31 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:22:31 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:22:31 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:22:31 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:22:31 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:22:32 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:22:32 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:22:32 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:22:32 [dispatcher-event-loop-4] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:22:32 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:22:32 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:22:32 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-06f88072-5d1a-4e6c-8223-72e1ec57edea
2025-03-29 13:23:55 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:23:55 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:23:55 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:23:55 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:23:55 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:23:55 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:23:55 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:23:55 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:23:56 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53793.
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:23:56 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:23:56 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:23:56 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-8aa600e3-f784-472f-9b5e-cbe04ff2e621
2025-03-29 13:23:56 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:23:56 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:23:56 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2512ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:23:56 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:23:57 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:23:57 [main] INFO  o.sparkproject.jetty.server.Server - Started @2634ms
2025-03-29 13:23:57 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:23:57 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:23:57 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:23:57 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53844.
2025-03-29 13:23:57 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53844
2025-03-29 13:23:57 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:23:57 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53844, None)
2025-03-29 13:23:57 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53844 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53844, None)
2025-03-29 13:23:57 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53844, None)
2025-03-29 13:23:57 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53844, None)
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:23:57 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:23:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:24:01 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 237.544 ms
2025-03-29 13:24:02 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:24:02 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53844 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:24:02 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:24:02 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:24:02 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:24:02 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:24:02 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 197 ms on YAU (executor driver) (1/1)
2025-03-29 13:24:02 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.480 s
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:24:02 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.540895 s
2025-03-29 13:24:02 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.4807 ms
2025-03-29 13:24:02 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.1932 ms
2025-03-29 13:24:02 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:24:02 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53844 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:24:02 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:24:02 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:24:02 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:24:02 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1785 bytes result sent to driver
2025-03-29 13:24:02 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on YAU (executor driver) (1/1)
2025-03-29 13:24:02 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.042 s
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:24:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:24:02 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.045235 s
2025-03-29 13:24:03 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.9275 ms
2025-03-29 13:24:03 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:56
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:56) with 1 output partitions
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:56)
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:56), which has no missing parents
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.4 KiB, free 4.5 GiB)
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)
2025-03-29 13:24:03 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53844 (size: 11.1 KiB, free: 4.5 GiB)
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:56) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:24:03 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:24:03 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:24:03 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.5413 ms
2025-03-29 13:24:03 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:24:03 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1319 bytes result sent to driver
2025-03-29 13:24:03 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 84 ms on YAU (executor driver) (1/1)
2025-03-29 13:24:03 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:56) finished in 0.132 s
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:24:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:24:03 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:56, took 0.137765 s
2025-03-29 13:24:03 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:24:03 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:24:03 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:24:03 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:24:03 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:24:03 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:24:03 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:24:03 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:24:03 [dispatcher-event-loop-1] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:24:03 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:24:03 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:24:03 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-ab8a093e-8fd4-4b85-949c-5ab5499b79f1
2025-03-29 13:25:01 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:25:01 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:25:01 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:25:01 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:25:01 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:25:01 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:25:01 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:25:01 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:25:01 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:25:01 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:25:01 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:25:01 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:25:01 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:25:02 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53895.
2025-03-29 13:25:02 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:25:02 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:25:02 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:25:02 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:25:02 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:25:02 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-29e52526-cd25-465d-a6b1-28293ffdfdf5
2025-03-29 13:25:02 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:25:02 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:25:02 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2578ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:25:02 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:25:02 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:25:02 [main] INFO  o.sparkproject.jetty.server.Server - Started @2710ms
2025-03-29 13:25:02 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:25:02 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:25:02 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:25:03 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:25:03 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53946.
2025-03-29 13:25:03 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:53946
2025-03-29 13:25:03 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:25:03 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 53946, None)
2025-03-29 13:25:03 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:53946 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 53946, None)
2025-03-29 13:25:03 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 53946, None)
2025-03-29 13:25:03 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 53946, None)
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:25:03 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:25:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:25:07 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 269.3397 ms
2025-03-29 13:25:07 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:25:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:25:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:25:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:25:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:25:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:25:07 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:25:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:53946 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:25:08 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:25:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:25:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:25:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:25:08 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 190 ms on YAU (executor driver) (1/1)
2025-03-29 13:25:08 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.480 s
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:25:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.519926 s
2025-03-29 13:25:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.8341 ms
2025-03-29 13:25:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.8901 ms
2025-03-29 13:25:08 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:25:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:53946 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:25:08 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:25:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:25:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:25:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:25:08 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-29 13:25:08 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.047 s
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:25:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.050903 s
2025-03-29 13:25:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.191 ms
2025-03-29 13:25:08 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:56
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at get_df_from_tablename.scala:56) with 1 output partitions
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at get_df_from_tablename.scala:56)
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:56), which has no missing parents
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 25.4 KiB, free 4.5 GiB)
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 4.5 GiB)
2025-03-29 13:25:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:53946 (size: 11.1 KiB, free: 4.5 GiB)
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at save at get_df_from_tablename.scala:56) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:25:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:25:08 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:25:08 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:25:08 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.3581 ms
2025-03-29 13:25:09 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:25:09 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1405 bytes result sent to driver
2025-03-29 13:25:09 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 215 ms on YAU (executor driver) (1/1)
2025-03-29 13:25:09 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:25:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at get_df_from_tablename.scala:56) finished in 0.264 s
2025-03-29 13:25:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:25:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:25:09 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at get_df_from_tablename.scala:56, took 0.269207 s
2025-03-29 13:25:09 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:25:09 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:25:09 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:25:09 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:25:09 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:25:09 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:25:09 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:25:09 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:25:09 [dispatcher-event-loop-4] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:25:09 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:25:09 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:25:09 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-8fb45f71-99b8-482b-9588-8a20c0cf8e6a
2025-03-29 13:27:36 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:27:36 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:27:36 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:27:36 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:27:36 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:27:36 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:27:36 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:27:36 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:27:36 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:27:36 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:27:36 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:27:36 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:27:36 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:27:37 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54003.
2025-03-29 13:27:37 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:27:37 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:27:37 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:27:37 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:27:37 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:27:37 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-c9815376-267e-4844-a0f1-629e024a0532
2025-03-29 13:27:37 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:27:37 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:27:37 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2512ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:27:37 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:27:37 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:27:37 [main] INFO  o.sparkproject.jetty.server.Server - Started @2636ms
2025-03-29 13:27:37 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@344c3598{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:27:37 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:27:37 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c9e07c6{/,null,AVAILABLE,@Spark}
2025-03-29 13:27:37 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:27:37 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:27:38 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54054.
2025-03-29 13:27:38 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54054
2025-03-29 13:27:38 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:27:38 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54054, None)
2025-03-29 13:27:38 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54054 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54054, None)
2025-03-29 13:27:38 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54054, None)
2025-03-29 13:27:38 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54054, None)
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1c9e07c6{/,null,STOPPED,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ebe067d{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6badba10{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52a33c3f{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19a20bb2{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3eb3232b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60bb7995{/static,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@345d053b{/,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e8b3b79{/api,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@45b15381{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@239f017e{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d08b4e6{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:27:38 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7645f03e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a6ea47d{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20ead579{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65e22def{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:27:38 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c52552f{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:27:42 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 264.1825 ms
2025-03-29 13:27:42 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:27:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:27:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:27:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:27:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:27:42 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:27:43 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54054 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:27:43 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1902 bytes result sent to driver
2025-03-29 13:27:43 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 283 ms on YAU (executor driver) (1/1)
2025-03-29 13:27:43 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.571 s
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:27:43 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.613671 s
2025-03-29 13:27:43 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 30.7504 ms
2025-03-29 13:27:43 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 18.7075 ms
2025-03-29 13:27:43 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:27:43 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54054 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:27:43 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1834 bytes result sent to driver
2025-03-29 13:27:43 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on YAU (executor driver) (1/1)
2025-03-29 13:27:43 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.047 s
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:27:43 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.050671 s
2025-03-29 13:27:43 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.4354 ms
2025-03-29 13:27:43 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:66
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:66) with 1 output partitions
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:66)
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:66), which has no missing parents
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:27:43 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54054 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:66) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:27:43 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:27:43 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1545 bytes result sent to driver
2025-03-29 13:27:43 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 13:27:43 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:66) finished in 0.036 s
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:27:43 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:27:43 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:66, took 0.039637 s
2025-03-29 13:27:44 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.6533 ms
2025-03-29 13:27:44 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:86
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:86) with 1 output partitions
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:86)
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:86), which has no missing parents
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:27:44 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54054 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:86) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:27:44 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:27:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:27:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.9135 ms
2025-03-29 13:27:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:27:44 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1405 bytes result sent to driver
2025-03-29 13:27:44 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 157 ms on YAU (executor driver) (1/1)
2025-03-29 13:27:44 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:86) finished in 0.205 s
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:27:44 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:27:44 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:86, took 0.210574 s
2025-03-29 13:27:44 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:27:44 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:27:44 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@344c3598{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:27:44 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:27:44 [dispatcher-event-loop-2] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:27:44 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:27:44 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:27:44 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:27:44 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:27:44 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:27:44 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:27:44 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-9b16b20e-bc01-44ba-95ff-6a151764d2e8
2025-03-29 13:28:12 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:28:12 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:28:12 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:28:12 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:28:12 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:28:12 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:28:12 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:28:12 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:28:12 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:28:12 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:28:12 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:28:12 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:28:12 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:28:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54105.
2025-03-29 13:28:13 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:28:13 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:28:13 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:28:13 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:28:13 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:28:13 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-9282b8b1-c89b-42a9-8d90-b4e3c6cbe6f8
2025-03-29 13:28:13 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:28:13 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:28:13 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2557ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:28:13 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:28:13 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:28:13 [main] INFO  o.sparkproject.jetty.server.Server - Started @2687ms
2025-03-29 13:28:13 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:28:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:28:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:28:13 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:28:13 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:28:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54156.
2025-03-29 13:28:13 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54156
2025-03-29 13:28:13 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:28:13 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54156, None)
2025-03-29 13:28:13 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54156 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54156, None)
2025-03-29 13:28:13 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54156, None)
2025-03-29 13:28:13 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54156, None)
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:28:14 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:28:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:28:18 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 262.8002 ms
2025-03-29 13:28:18 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:28:18 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54156 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:28:18 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:28:19 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:28:19 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 199 ms on YAU (executor driver) (1/1)
2025-03-29 13:28:19 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.470 s
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:28:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.516591 s
2025-03-29 13:28:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 42.1943 ms
2025-03-29 13:28:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.9292 ms
2025-03-29 13:28:19 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:28:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54156 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:28:19 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:28:19 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on YAU (executor driver) (1/1)
2025-03-29 13:28:19 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.042 s
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:28:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.045734 s
2025-03-29 13:28:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.3553 ms
2025-03-29 13:28:19 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:66
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:66) with 1 output partitions
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:66)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:66), which has no missing parents
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:28:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54156 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:66) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:28:19 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-29 13:28:19 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on YAU (executor driver) (1/1)
2025-03-29 13:28:19 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:66) finished in 0.045 s
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:28:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:66, took 0.048719 s
2025-03-29 13:28:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.8871 ms
2025-03-29 13:28:19 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:86
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:86) with 1 output partitions
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:86)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:86), which has no missing parents
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:28:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54156 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:86) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:28:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:28:19 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:28:19 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:28:20 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.4172 ms
2025-03-29 13:28:20 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:28:20 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1362 bytes result sent to driver
2025-03-29 13:28:20 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 242 ms on YAU (executor driver) (1/1)
2025-03-29 13:28:20 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:28:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:86) finished in 0.293 s
2025-03-29 13:28:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:28:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:28:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:86, took 0.298777 s
2025-03-29 13:28:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:28:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:28:20 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:28:20 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:28:20 [dispatcher-event-loop-6] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:28:20 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:28:20 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:28:20 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:28:20 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:28:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:28:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:28:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-4527f595-8740-47a1-a626-df5f5872f6e5
2025-03-29 13:29:52 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:29:52 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:29:52 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:29:52 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:29:52 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:29:52 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:29:52 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:29:52 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:29:52 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:29:52 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:29:52 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:29:52 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:29:52 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:29:53 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54209.
2025-03-29 13:29:53 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:29:53 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:29:53 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:29:53 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:29:53 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:29:53 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-5424f8fe-b2e7-4cbc-84ac-e5fe7f741754
2025-03-29 13:29:53 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:29:53 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:29:53 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2578ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:29:53 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:29:53 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:29:54 [main] INFO  o.sparkproject.jetty.server.Server - Started @2692ms
2025-03-29 13:29:54 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:29:54 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:29:54 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:29:54 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54260.
2025-03-29 13:29:54 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54260
2025-03-29 13:29:54 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:29:54 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54260, None)
2025-03-29 13:29:54 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54260 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54260, None)
2025-03-29 13:29:54 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54260, None)
2025-03-29 13:29:54 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54260, None)
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:29:54 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:29:54 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:29:58 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 259.2272 ms
2025-03-29 13:29:59 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:29:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54260 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:29:59 [dispatcher-event-loop-7] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:29:59 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:29:59 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:29:59 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1902 bytes result sent to driver
2025-03-29 13:29:59 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 262 ms on YAU (executor driver) (1/1)
2025-03-29 13:29:59 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.567 s
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:29:59 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.619385 s
2025-03-29 13:29:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 34.8164 ms
2025-03-29 13:29:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.5212 ms
2025-03-29 13:29:59 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:29:59 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54260 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:29:59 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:29:59 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:29:59 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:29:59 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1871 bytes result sent to driver
2025-03-29 13:29:59 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on YAU (executor driver) (1/1)
2025-03-29 13:29:59 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.051 s
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:29:59 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:29:59 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.055832 s
2025-03-29 13:29:59 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.1349 ms
2025-03-29 13:30:00 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:38
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:38) with 1 output partitions
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:38)
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:38), which has no missing parents
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:30:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54260 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:38) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:30:00 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:30:00 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:30:00 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:30:00 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-29 13:30:00 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 32 ms on YAU (executor driver) (1/1)
2025-03-29 13:30:00 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:38) finished in 0.043 s
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:30:00 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:38, took 0.046151 s
2025-03-29 13:30:00 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.1522 ms
2025-03-29 13:30:00 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:58)
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:30:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54260 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:30:00 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:30:00 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:30:00 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 18.9512 ms
2025-03-29 13:30:00 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:30:00 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1362 bytes result sent to driver
2025-03-29 13:30:00 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 111 ms on YAU (executor driver) (1/1)
2025-03-29 13:30:00 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:58) finished in 0.158 s
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:30:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:30:00 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:58, took 0.162383 s
2025-03-29 13:30:00 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:30:00 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:30:00 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:30:00 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:30:00 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:30:00 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:30:00 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:30:00 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:30:00 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:30:00 [dispatcher-event-loop-6] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:30:00 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:30:00 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:30:00 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-a940bb02-6d76-4e9e-aa94-66714a5245a9
2025-03-29 13:31:29 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:31:29 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:31:29 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:31:29 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:31:29 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:31:29 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:31:29 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:31:29 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:31:29 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:31:29 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:31:29 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:31:29 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:31:29 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:31:30 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54314.
2025-03-29 13:31:30 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:31:30 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:31:30 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:31:30 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:31:30 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:31:30 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-b29db674-8124-411f-9d99-fcd4e7b912ad
2025-03-29 13:31:30 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:31:30 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:31:30 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2441ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:31:30 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:31:30 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:31:30 [main] INFO  o.sparkproject.jetty.server.Server - Started @2570ms
2025-03-29 13:31:30 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:31:30 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:31:30 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:31:30 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54365.
2025-03-29 13:31:30 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54365
2025-03-29 13:31:30 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:31:30 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54365, None)
2025-03-29 13:31:30 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54365 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54365, None)
2025-03-29 13:31:30 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54365, None)
2025-03-29 13:31:30 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54365, None)
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:31:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:31:31 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:31:31 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:31:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 260.4631 ms
2025-03-29 13:31:35 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:31:35 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54365 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:31:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:31:35 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:31:35 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1902 bytes result sent to driver
2025-03-29 13:31:36 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 272 ms on YAU (executor driver) (1/1)
2025-03-29 13:31:36 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.537 s
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:31:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.576053 s
2025-03-29 13:31:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.9873 ms
2025-03-29 13:31:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 19.0733 ms
2025-03-29 13:31:36 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:31:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54365 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:31:36 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:31:36 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on YAU (executor driver) (1/1)
2025-03-29 13:31:36 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.046 s
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:31:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.051377 s
2025-03-29 13:31:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.7414 ms
2025-03-29 13:31:36 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:38
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:38) with 1 output partitions
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:38)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:38), which has no missing parents
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:31:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54365 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:38) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:31:36 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1459 bytes result sent to driver
2025-03-29 13:31:36 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on YAU (executor driver) (1/1)
2025-03-29 13:31:36 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:38) finished in 0.036 s
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:31:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:38, took 0.038717 s
2025-03-29 13:31:36 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.9196 ms
2025-03-29 13:31:36 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:58)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:31:36 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54365 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:31:36 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 26.1365 ms
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:31:36 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1405 bytes result sent to driver
2025-03-29 13:31:36 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 133 ms on YAU (executor driver) (1/1)
2025-03-29 13:31:36 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:58) finished in 0.178 s
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:31:36 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:31:36 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:58, took 0.184318 s
2025-03-29 13:31:36 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:31:36 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:31:36 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:31:36 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:31:36 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:31:36 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:31:36 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:31:36 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:31:36 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:31:36 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:31:36 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:31:36 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:31:36 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-2fdaaf50-8dc8-4ea8-9a45-845e5c5b33a8
2025-03-29 13:39:25 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:39:26 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:39:26 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:39:26 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:39:26 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:39:26 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:39:26 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:39:26 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:39:26 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:39:26 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:39:26 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:39:26 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:39:26 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:39:27 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54429.
2025-03-29 13:39:27 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:39:27 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:39:27 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:39:27 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:39:27 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:39:27 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-57fa181f-a3d8-4424-b18b-998cd83c8b96
2025-03-29 13:39:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:39:27 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:39:27 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2490ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:39:27 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:39:27 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:39:27 [main] INFO  o.sparkproject.jetty.server.Server - Started @2620ms
2025-03-29 13:39:27 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:39:27 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:39:27 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:39:27 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54480.
2025-03-29 13:39:27 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54480
2025-03-29 13:39:27 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:39:27 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54480, None)
2025-03-29 13:39:27 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54480 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54480, None)
2025-03-29 13:39:27 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54480, None)
2025-03-29 13:39:27 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54480, None)
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:39:27 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:28 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:39:28 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:39:28 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:39:28 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:28 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:39:28 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:39:28 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:39:32 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 253.1895 ms
2025-03-29 13:39:32 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:39:32 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54480 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:39:32 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:39:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:39:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:39:32 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:39:32 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 190 ms on YAU (executor driver) (1/1)
2025-03-29 13:39:32 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.457 s
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:39:32 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:39:32 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.496959 s
2025-03-29 13:39:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.264 ms
2025-03-29 13:39:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.0802 ms
2025-03-29 13:39:33 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:39:33 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54480 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:39:33 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:39:33 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:39:33 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:39:33 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1867 bytes result sent to driver
2025-03-29 13:39:33 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-03-29 13:39:33 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.045 s
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:39:33 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.050428 s
2025-03-29 13:39:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.3629 ms
2025-03-29 13:39:33 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:39:33 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54480 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:39:33 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:39:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:39:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:39:33 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1545 bytes result sent to driver
2025-03-29 13:39:33 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on YAU (executor driver) (1/1)
2025-03-29 13:39:33 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.041 s
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:39:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:39:33 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.043203 s
2025-03-29 13:39:33 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:39:33 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:39:33 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:39:33 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:39:33 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:39:33 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:39:33 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:39:33 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:39:33 [dispatcher-event-loop-2] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:39:33 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:39:33 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:39:33 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-412945e5-34c3-4a8d-a192-02a745d2805e
2025-03-29 13:40:08 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:40:09 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:40:09 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:40:09 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:40:09 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:40:09 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:40:09 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:40:09 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54527.
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:40:09 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:40:09 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:40:09 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:40:10 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-984a762e-6b60-497e-aefc-5cb5b34a4fa8
2025-03-29 13:40:10 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:40:10 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:40:10 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2559ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:40:10 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:40:10 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:40:10 [main] INFO  o.sparkproject.jetty.server.Server - Started @2688ms
2025-03-29 13:40:10 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:40:10 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:40:10 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:40:10 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54578.
2025-03-29 13:40:10 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54578
2025-03-29 13:40:10 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:40:10 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54578, None)
2025-03-29 13:40:10 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54578 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54578, None)
2025-03-29 13:40:10 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54578, None)
2025-03-29 13:40:10 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54578, None)
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:40:10 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:11 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:40:11 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:40:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:40:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:40:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:40:11 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:40:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 253.8275 ms
2025-03-29 13:40:15 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:40:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54578 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:40:15 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:40:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:40:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:40:15 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:40:15 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 195 ms on YAU (executor driver) (1/1)
2025-03-29 13:40:15 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.489 s
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:40:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:40:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.536045 s
2025-03-29 13:40:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 34.599 ms
2025-03-29 13:40:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.6808 ms
2025-03-29 13:40:16 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:40:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54578 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:40:16 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:40:16 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:40:16 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:40:16 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:40:16 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on YAU (executor driver) (1/1)
2025-03-29 13:40:16 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.047 s
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:40:16 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.052249 s
2025-03-29 13:40:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.984 ms
2025-03-29 13:40:16 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:40:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54578 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:40:16 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:40:16 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:40:16 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:40:16 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-29 13:40:16 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on YAU (executor driver) (1/1)
2025-03-29 13:40:16 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.038 s
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:40:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:40:16 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.041735 s
2025-03-29 13:40:16 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:40:16 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:40:16 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:40:16 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:40:16 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:40:16 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:40:16 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:40:16 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:40:16 [dispatcher-event-loop-4] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:40:16 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:40:16 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:40:16 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-eda72321-e55f-4ba6-a58a-452ef9f48214
2025-03-29 13:41:13 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:41:13 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:41:13 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:41:13 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:41:13 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:41:13 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:41:13 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:41:13 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:41:13 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:41:13 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:41:13 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:41:13 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:41:13 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:41:14 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54628.
2025-03-29 13:41:14 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:41:14 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:41:14 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:41:14 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:41:14 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:41:14 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-5fb8f406-dd19-4a33-8b3d-bf7de3e0be07
2025-03-29 13:41:14 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:41:14 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:41:14 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2676ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:41:14 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:41:14 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:41:14 [main] INFO  o.sparkproject.jetty.server.Server - Started @2793ms
2025-03-29 13:41:14 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:41:14 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:41:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:41:14 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:41:14 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:41:14 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54679.
2025-03-29 13:41:14 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54679
2025-03-29 13:41:14 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:41:14 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54679, None)
2025-03-29 13:41:14 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54679 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54679, None)
2025-03-29 13:41:14 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54679, None)
2025-03-29 13:41:14 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54679, None)
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:41:15 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:41:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:41:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 266.3261 ms
2025-03-29 13:41:19 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:41:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54679 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:41:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:41:19 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:41:19 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:41:20 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:41:20 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:41:20 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 203 ms on YAU (executor driver) (1/1)
2025-03-29 13:41:20 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.476 s
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:41:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.518403 s
2025-03-29 13:41:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.2919 ms
2025-03-29 13:41:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.0114 ms
2025-03-29 13:41:20 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:41:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54679 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:41:20 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:41:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:41:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:41:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1871 bytes result sent to driver
2025-03-29 13:41:20 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on YAU (executor driver) (1/1)
2025-03-29 13:41:20 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.047 s
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:41:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.051462 s
2025-03-29 13:41:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.7539 ms
2025-03-29 13:41:20 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:41:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54679 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:41:20 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:41:20 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:41:20 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:41:20 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-29 13:41:20 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on YAU (executor driver) (1/1)
2025-03-29 13:41:20 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.035 s
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:41:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:41:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.038159 s
2025-03-29 13:41:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:41:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:41:20 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:41:20 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:41:20 [dispatcher-event-loop-0] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:41:20 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:41:20 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:41:20 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:41:20 [dispatcher-event-loop-4] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:41:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:41:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:41:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-c554f49c-9633-438e-9acf-3eeb29aedac6
2025-03-29 13:42:12 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:42:13 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:42:13 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:42:13 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:42:13 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:42:13 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:42:13 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:42:13 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:42:13 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:42:13 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:42:13 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:42:13 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:42:13 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:42:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54728.
2025-03-29 13:42:14 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:42:14 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:42:14 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:42:14 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:42:14 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:42:14 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-f8e80125-6509-4c28-8a4c-49341d00d678
2025-03-29 13:42:14 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:42:14 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:42:14 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2417ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:42:14 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:42:14 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:42:14 [main] INFO  o.sparkproject.jetty.server.Server - Started @2541ms
2025-03-29 13:42:14 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:42:14 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:42:14 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:42:14 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54779.
2025-03-29 13:42:14 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54779
2025-03-29 13:42:14 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:42:14 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54779, None)
2025-03-29 13:42:14 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54779 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54779, None)
2025-03-29 13:42:14 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54779, None)
2025-03-29 13:42:14 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54779, None)
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:42:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:15 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:42:15 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:42:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:42:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:42:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:42:15 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:42:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 237.5836 ms
2025-03-29 13:42:19 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:42:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54779 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:42:19 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:42:19 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:42:19 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:42:19 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:42:19 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 196 ms on YAU (executor driver) (1/1)
2025-03-29 13:42:19 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.504 s
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:42:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:42:19 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.558767 s
2025-03-29 13:42:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 37.6893 ms
2025-03-29 13:42:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.696 ms
2025-03-29 13:42:20 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:42:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54779 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:42:20 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:42:20 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 38 ms on YAU (executor driver) (1/1)
2025-03-29 13:42:20 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.050 s
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:42:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.053669 s
2025-03-29 13:42:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.8779 ms
2025-03-29 13:42:20 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:42:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54779 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:42:20 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1545 bytes result sent to driver
2025-03-29 13:42:20 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on YAU (executor driver) (1/1)
2025-03-29 13:42:20 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.035 s
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:42:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.039520 s
2025-03-29 13:42:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.7001 ms
2025-03-29 13:42:20 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:54
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:54) with 1 output partitions
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:54)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:54), which has no missing parents
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.2 KiB, free 4.5 GiB)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:42:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54779 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:54) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:42:20 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.196 ms
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:42:20 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1362 bytes result sent to driver
2025-03-29 13:42:20 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 193 ms on YAU (executor driver) (1/1)
2025-03-29 13:42:20 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:54) finished in 0.238 s
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:42:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:42:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:54, took 0.242433 s
2025-03-29 13:42:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:42:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:42:20 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:42:20 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:42:20 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:42:20 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:42:20 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:42:20 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:42:20 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:42:20 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:42:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:42:20 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-d26bb254-9bb8-4f4e-813a-1feff355572a
2025-03-29 13:43:55 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:43:55 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:43:55 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:43:55 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:43:55 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:43:55 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:43:55 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:43:55 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:43:55 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:43:55 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:43:55 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:43:55 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:43:55 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:43:56 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54831.
2025-03-29 13:43:56 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:43:56 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:43:56 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:43:56 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:43:56 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:43:56 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-b47c6c99-be8c-45ee-973f-6488dd85377a
2025-03-29 13:43:56 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:43:56 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:43:56 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2501ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:43:56 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:43:56 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:43:56 [main] INFO  o.sparkproject.jetty.server.Server - Started @2606ms
2025-03-29 13:43:57 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:43:57 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:43:57 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:43:57 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54882.
2025-03-29 13:43:57 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54882
2025-03-29 13:43:57 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:43:57 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54882, None)
2025-03-29 13:43:57 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54882 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54882, None)
2025-03-29 13:43:57 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54882, None)
2025-03-29 13:43:57 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54882, None)
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:43:57 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:43:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:44:02 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 284.798 ms
2025-03-29 13:44:02 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:44:02 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54882 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:44:02 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:44:02 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:44:02 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:44:02 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:44:02 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 191 ms on YAU (executor driver) (1/1)
2025-03-29 13:44:02 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.486 s
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:44:02 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.531576 s
2025-03-29 13:44:02 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.1174 ms
2025-03-29 13:44:02 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.8882 ms
2025-03-29 13:44:02 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:44:02 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54882 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:44:02 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:44:02 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:44:02 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:44:02 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:44:02 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on YAU (executor driver) (1/1)
2025-03-29 13:44:02 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.050 s
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:44:02 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.054054 s
2025-03-29 13:44:02 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.4086 ms
2025-03-29 13:44:02 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:44:02 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54882 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:44:02 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:44:02 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:44:02 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:44:03 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:44:03 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1459 bytes result sent to driver
2025-03-29 13:44:03 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 13:44:03 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.036 s
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:44:03 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.039053 s
2025-03-29 13:44:03 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.5697 ms
2025-03-29 13:44:03 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:55
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:55) with 1 output partitions
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:55)
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:55), which has no missing parents
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:44:03 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54882 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:55) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:44:03 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:44:03 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:44:03 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.6064 ms
2025-03-29 13:44:03 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:44:03 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1362 bytes result sent to driver
2025-03-29 13:44:03 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 243 ms on YAU (executor driver) (1/1)
2025-03-29 13:44:03 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:55) finished in 0.290 s
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:44:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:44:03 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:55, took 0.295118 s
2025-03-29 13:44:03 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:44:03 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:44:03 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:44:03 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:44:03 [dispatcher-event-loop-4] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:44:03 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:44:03 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:44:03 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:44:03 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:44:03 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:44:03 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:44:03 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-00878dd5-0343-4ae3-8d39-f730bcb6a1b4
2025-03-29 13:45:32 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:45:33 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:45:33 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:45:33 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:45:33 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:45:33 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:45:33 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:45:33 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54934.
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:45:33 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:45:33 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:45:33 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-d1e09975-8ebe-4349-bbbc-a0918ca67f97
2025-03-29 13:45:33 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:45:33 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:45:34 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2430ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:45:34 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:45:34 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:45:34 [main] INFO  o.sparkproject.jetty.server.Server - Started @2567ms
2025-03-29 13:45:34 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:45:34 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:45:34 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:45:34 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54985.
2025-03-29 13:45:34 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:54985
2025-03-29 13:45:34 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:45:34 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 54985, None)
2025-03-29 13:45:34 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:54985 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 54985, None)
2025-03-29 13:45:34 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 54985, None)
2025-03-29 13:45:34 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 54985, None)
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:45:34 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:45:34 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:45:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 288.6634 ms
2025-03-29 13:45:39 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:45:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:54985 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:45:39 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:45:39 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 188 ms on YAU (executor driver) (1/1)
2025-03-29 13:45:39 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.454 s
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:45:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.496429 s
2025-03-29 13:45:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.7047 ms
2025-03-29 13:45:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.3732 ms
2025-03-29 13:45:39 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:45:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:54985 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:45:39 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:45:39 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on YAU (executor driver) (1/1)
2025-03-29 13:45:39 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.042 s
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:45:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.045301 s
2025-03-29 13:45:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.9078 ms
2025-03-29 13:45:39 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:45:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:54985 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:45:39 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:45:39 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-29 13:45:39 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 13:45:39 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.036 s
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:45:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:45:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.039728 s
2025-03-29 13:45:40 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.7889 ms
2025-03-29 13:45:40 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:58)
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:45:40 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:54985 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:45:40 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:45:40 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:45:40 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 23.971 ms
2025-03-29 13:45:40 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:45:40 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1405 bytes result sent to driver
2025-03-29 13:45:40 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 204 ms on YAU (executor driver) (1/1)
2025-03-29 13:45:40 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:58) finished in 0.256 s
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:45:40 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:45:40 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:58, took 0.260778 s
2025-03-29 13:45:40 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:45:40 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:45:40 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:45:40 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:45:40 [dispatcher-event-loop-5] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:45:40 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:45:40 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:45:40 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:45:40 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:45:40 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:45:40 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:45:40 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-3478fe67-59b4-488d-9baa-7bf70195a4c3
2025-03-29 13:48:06 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:48:06 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:48:06 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:48:06 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:48:06 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:48:06 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:48:06 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:48:06 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:48:06 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:48:06 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:48:06 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:48:06 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:48:06 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:48:07 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55038.
2025-03-29 13:48:07 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:48:07 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:48:07 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:48:07 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:48:07 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:48:07 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-202acb35-782b-4560-bb25-1c629b926799
2025-03-29 13:48:07 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:48:07 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:48:07 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2550ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:48:07 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:48:07 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:48:07 [main] INFO  o.sparkproject.jetty.server.Server - Started @2670ms
2025-03-29 13:48:07 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:48:07 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:48:07 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:48:08 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:48:08 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55089.
2025-03-29 13:48:08 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55089
2025-03-29 13:48:08 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:48:08 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55089, None)
2025-03-29 13:48:08 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55089 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55089, None)
2025-03-29 13:48:08 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55089, None)
2025-03-29 13:48:08 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55089, None)
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:48:08 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:48:08 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:48:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 251.4801 ms
2025-03-29 13:48:12 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:48:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:48:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:48:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:48:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:48:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:48:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:48:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55089 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:48:13 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:48:13 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 189 ms on YAU (executor driver) (1/1)
2025-03-29 13:48:13 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.494 s
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:48:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.536385 s
2025-03-29 13:48:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 34.4263 ms
2025-03-29 13:48:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.8469 ms
2025-03-29 13:48:13 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:48:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55089 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:48:13 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1780 bytes result sent to driver
2025-03-29 13:48:13 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on YAU (executor driver) (1/1)
2025-03-29 13:48:13 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.048 s
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:48:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.051595 s
2025-03-29 13:48:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.4445 ms
2025-03-29 13:48:13 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:48:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55089 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:48:13 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:48:13 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-29 13:48:13 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on YAU (executor driver) (1/1)
2025-03-29 13:48:13 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.034 s
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:48:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.037472 s
2025-03-29 13:48:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.3837 ms
2025-03-29 13:48:13 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:58)
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:48:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:48:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:48:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:48:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55089 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:48:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:48:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:48:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:48:14 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:48:14 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:48:14 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.7193 ms
2025-03-29 13:48:14 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:48:14 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1405 bytes result sent to driver
2025-03-29 13:48:14 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 209 ms on YAU (executor driver) (1/1)
2025-03-29 13:48:14 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:48:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:58) finished in 0.256 s
2025-03-29 13:48:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:48:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:48:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:58, took 0.261323 s
2025-03-29 13:48:14 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:48:14 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:48:14 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:48:14 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:48:14 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:48:14 [dispatcher-event-loop-3] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:48:14 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:48:14 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:48:14 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:48:14 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:48:14 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:48:14 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:48:14 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-1073a818-8a92-4462-bb54-e578185133bc
2025-03-29 13:50:27 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:50:28 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:50:28 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:50:28 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:50:28 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:50:28 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:50:28 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:50:28 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:50:28 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:50:28 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:50:28 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:50:28 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:50:28 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:50:28 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55142.
2025-03-29 13:50:28 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:50:28 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:50:29 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:50:29 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:50:29 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:50:29 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-134df181-0277-41eb-adf2-8b31ce015553
2025-03-29 13:50:29 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:50:29 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:50:29 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2476ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:50:29 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:50:29 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:50:29 [main] INFO  o.sparkproject.jetty.server.Server - Started @2609ms
2025-03-29 13:50:29 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:50:29 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:50:29 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:50:29 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55193.
2025-03-29 13:50:29 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55193
2025-03-29 13:50:29 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:50:29 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55193, None)
2025-03-29 13:50:29 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55193 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55193, None)
2025-03-29 13:50:29 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55193, None)
2025-03-29 13:50:29 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55193, None)
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:50:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:30 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:50:30 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:50:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:50:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:50:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:50:30 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:50:34 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 272.5717 ms
2025-03-29 13:50:34 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:50:34 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55193 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:50:34 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:50:34 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:50:34 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:50:34 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:50:34 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 201 ms on YAU (executor driver) (1/1)
2025-03-29 13:50:34 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.512 s
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:50:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:50:34 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.556551 s
2025-03-29 13:50:34 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.2692 ms
2025-03-29 13:50:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.6857 ms
2025-03-29 13:50:35 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:50:35 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55193 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:50:35 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:50:35 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on YAU (executor driver) (1/1)
2025-03-29 13:50:35 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.045 s
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:50:35 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.049310 s
2025-03-29 13:50:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.1174 ms
2025-03-29 13:50:35 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:50:35 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55193 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:50:35 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1459 bytes result sent to driver
2025-03-29 13:50:35 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 13:50:35 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.037 s
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:50:35 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.040669 s
2025-03-29 13:50:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.364 ms
2025-03-29 13:50:35 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:58)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:50:35 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55193 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:50:35 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.5457 ms
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:50:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1405 bytes result sent to driver
2025-03-29 13:50:35 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 180 ms on YAU (executor driver) (1/1)
2025-03-29 13:50:35 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:58) finished in 0.226 s
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:50:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:50:35 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:58, took 0.232355 s
2025-03-29 13:50:35 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:50:35 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:50:35 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:50:35 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:50:35 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:50:35 [dispatcher-event-loop-2] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:50:35 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:50:35 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:50:35 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:50:35 [dispatcher-event-loop-7] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:50:35 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:50:35 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:50:35 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-8e540737-21a0-4007-b428-056d4c9b06c8
2025-03-29 13:51:26 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:51:27 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:51:27 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:51:27 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:51:27 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:51:27 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:51:27 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:51:27 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:51:27 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:51:27 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:51:27 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:51:27 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:51:27 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:51:27 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55249.
2025-03-29 13:51:28 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:51:28 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:51:28 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:51:28 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:51:28 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:51:28 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-56a40474-0ccf-4e0f-92c8-0f0094405d98
2025-03-29 13:51:28 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:51:28 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:51:28 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2665ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:51:28 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:51:28 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:51:28 [main] INFO  o.sparkproject.jetty.server.Server - Started @2820ms
2025-03-29 13:51:28 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:51:28 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:51:28 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:51:28 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:51:28 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:51:28 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55300.
2025-03-29 13:51:28 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55300
2025-03-29 13:51:28 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:51:28 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55300, None)
2025-03-29 13:51:28 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55300 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55300, None)
2025-03-29 13:51:28 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55300, None)
2025-03-29 13:51:28 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55300, None)
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:51:29 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:51:29 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:51:33 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 268.3079 ms
2025-03-29 13:51:33 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:51:33 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55300 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:51:33 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:51:34 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:51:34 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 187 ms on YAU (executor driver) (1/1)
2025-03-29 13:51:34 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.508 s
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:51:34 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.553883 s
2025-03-29 13:51:34 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.6857 ms
2025-03-29 13:51:34 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.2759 ms
2025-03-29 13:51:34 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:51:34 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55300 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:51:34 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:51:34 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on YAU (executor driver) (1/1)
2025-03-29 13:51:34 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.047 s
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:51:34 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.051876 s
2025-03-29 13:51:34 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.6105 ms
2025-03-29 13:51:34 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:51:34 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55300 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:51:34 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-29 13:51:34 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 13:51:34 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.037 s
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:51:34 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.041080 s
2025-03-29 13:51:34 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.2888 ms
2025-03-29 13:51:34 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:58)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:51:34 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55300 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:51:34 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:51:34 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:51:34 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.7154 ms
2025-03-29 13:51:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:51:35 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1405 bytes result sent to driver
2025-03-29 13:51:35 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 235 ms on YAU (executor driver) (1/1)
2025-03-29 13:51:35 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:58) finished in 0.287 s
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:51:35 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:58, took 0.293251 s
2025-03-29 13:51:35 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:51:35 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[16] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:51:35 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:55300 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-29 13:51:35 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:51:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-29 13:51:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:51:35 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1459 bytes result sent to driver
2025-03-29 13:51:35 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 22 ms on YAU (executor driver) (1/1)
2025-03-29 13:51:35 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (isEmpty at get_df_from_tablename.scala:39) finished in 0.031 s
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-29 13:51:35 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: isEmpty at get_df_from_tablename.scala:39, took 0.034771 s
2025-03-29 13:51:35 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.9323 ms
2025-03-29 13:51:35 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (save at get_df_from_tablename.scala:58)
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[21] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 25.9 KiB, free 4.5 GiB)
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 4.5 GiB)
2025-03-29 13:51:35 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:55300 (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-29 13:51:35 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:51:35 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-29 13:51:35 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:51:35 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1319 bytes result sent to driver
2025-03-29 13:51:35 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 53 ms on YAU (executor driver) (1/1)
2025-03-29 13:51:35 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (save at get_df_from_tablename.scala:58) finished in 0.066 s
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:51:35 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-29 13:51:35 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: save at get_df_from_tablename.scala:58, took 0.070973 s
2025-03-29 13:51:35 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:51:35 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:51:35 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:51:35 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:51:35 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:51:35 [dispatcher-event-loop-9] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:51:35 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:51:35 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:51:35 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:51:35 [dispatcher-event-loop-13] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:51:35 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:51:35 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:51:35 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-8b7f22d6-75b5-4722-acbb-e556addd5216
2025-03-29 13:53:31 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:53:31 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:53:31 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:53:31 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:53:31 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:53:31 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:53:31 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:53:31 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:53:31 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:53:31 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:53:31 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:53:31 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:53:31 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:53:32 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55364.
2025-03-29 13:53:32 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:53:32 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:53:32 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:53:32 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:53:32 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:53:32 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-4bf44f66-7d13-4dc8-9660-7190f801f893
2025-03-29 13:53:32 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:53:32 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:53:32 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2494ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:53:32 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:53:32 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:53:32 [main] INFO  o.sparkproject.jetty.server.Server - Started @2617ms
2025-03-29 13:53:32 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:53:32 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:53:32 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73010765{/,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:53:33 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:53:33 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55415.
2025-03-29 13:53:33 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55415
2025-03-29 13:53:33 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:53:33 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55415, None)
2025-03-29 13:53:33 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55415 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55415, None)
2025-03-29 13:53:33 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55415, None)
2025-03-29 13:53:33 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55415, None)
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@73010765{/,null,STOPPED,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a4ab7f7{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74d6736{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@668625f5{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75babb67{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69cd1085{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40fa8766{/static,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/api,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@38cedb7d{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1015a4b9{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:53:33 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:53:33 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:53:37 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 258.9818 ms
2025-03-29 13:53:37 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:22
2025-03-29 13:53:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at test_logging.scala:22) with 1 output partitions
2025-03-29 13:53:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at test_logging.scala:22)
2025-03-29 13:53:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:53:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:53:37 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22), which has no missing parents
2025-03-29 13:53:37 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:53:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55415 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at test_logging.scala:22) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:53:38 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:53:38 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 188 ms on YAU (executor driver) (1/1)
2025-03-29 13:53:38 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at test_logging.scala:22) finished in 0.459 s
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:53:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at test_logging.scala:22, took 0.503701 s
2025-03-29 13:53:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.9667 ms
2025-03-29 13:53:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.7666 ms
2025-03-29 13:53:38 [main] INFO  org.apache.spark.SparkContext - Starting job: show at test_logging.scala:36
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (show at test_logging.scala:36) with 1 output partitions
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (show at test_logging.scala:36)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36), which has no missing parents
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:53:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55415 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at test_logging.scala:36) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:53:38 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1828 bytes result sent to driver
2025-03-29 13:53:38 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on YAU (executor driver) (1/1)
2025-03-29 13:53:38 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (show at test_logging.scala:36) finished in 0.048 s
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:53:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: show at test_logging.scala:36, took 0.051653 s
2025-03-29 13:53:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.6638 ms
2025-03-29 13:53:38 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:53:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55415 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:53:38 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1502 bytes result sent to driver
2025-03-29 13:53:38 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on YAU (executor driver) (1/1)
2025-03-29 13:53:38 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (isEmpty at get_df_from_tablename.scala:39) finished in 0.035 s
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:53:38 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: isEmpty at get_df_from_tablename.scala:39, took 0.038209 s
2025-03-29 13:53:38 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.3689 ms
2025-03-29 13:53:38 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at get_df_from_tablename.scala:58)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:53:38 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55415 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:53:38 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:53:38 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:53:38 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.5644 ms
2025-03-29 13:53:39 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:53:39 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1405 bytes result sent to driver
2025-03-29 13:53:39 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 196 ms on YAU (executor driver) (1/1)
2025-03-29 13:53:39 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at get_df_from_tablename.scala:58) finished in 0.239 s
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:53:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at get_df_from_tablename.scala:58, took 0.243340 s
2025-03-29 13:53:39 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:53:39 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[16] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:53:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:55415 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-29 13:53:39 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:53:39 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-29 13:53:39 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:53:39 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1502 bytes result sent to driver
2025-03-29 13:53:39 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 22 ms on YAU (executor driver) (1/1)
2025-03-29 13:53:39 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (isEmpty at get_df_from_tablename.scala:39) finished in 0.030 s
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-29 13:53:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: isEmpty at get_df_from_tablename.scala:39, took 0.032857 s
2025-03-29 13:53:39 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.4605 ms
2025-03-29 13:53:39 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (save at get_df_from_tablename.scala:58)
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[21] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 25.9 KiB, free 4.5 GiB)
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 4.5 GiB)
2025-03-29 13:53:39 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:55415 (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-29 13:53:39 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:53:39 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-29 13:53:39 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:53:39 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 1362 bytes result sent to driver
2025-03-29 13:53:39 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 56 ms on YAU (executor driver) (1/1)
2025-03-29 13:53:39 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (save at get_df_from_tablename.scala:58) finished in 0.069 s
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:53:39 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-29 13:53:39 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: save at get_df_from_tablename.scala:58, took 0.074170 s
2025-03-29 13:53:39 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:53:39 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Invoking stop() from shutdown hook
2025-03-29 13:53:39 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:53:39 [shutdown-hook-0] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@53830483{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:53:39 [shutdown-hook-0] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:53:39 [dispatcher-event-loop-9] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:53:39 [shutdown-hook-0] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:53:39 [shutdown-hook-0] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:53:39 [shutdown-hook-0] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:53:39 [dispatcher-event-loop-13] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:53:39 [shutdown-hook-0] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:53:39 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:53:39 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-b9603b19-d7f3-4752-b08b-10ea7435fbb1
2025-03-29 13:54:01 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-03-29 13:54:02 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:54:02 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-03-29 13:54:02 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-03-29 13:54:02 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-03-29 13:54:02 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-03-29 13:54:02 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-03-29 13:54:02 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55476.
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-03-29 13:54:02 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-03-29 13:54:02 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-03-29 13:54:02 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-03-29 13:54:02 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-f219015c-9671-4afe-a3fa-e2f27fc2e2ae
2025-03-29 13:54:03 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-03-29 13:54:03 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-03-29 13:54:03 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2513ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-03-29 13:54:03 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-03-29 13:54:03 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-03-29 13:54:03 [main] INFO  o.sparkproject.jetty.server.Server - Started @2637ms
2025-03-29 13:54:03 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:54:03 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-03-29 13:54:03 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-03-29 13:54:03 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55527.
2025-03-29 13:54:03 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:55527
2025-03-29 13:54:03 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-03-29 13:54:03 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 55527, None)
2025-03-29 13:54:03 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:55527 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 55527, None)
2025-03-29 13:54:03 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 55527, None)
2025-03-29 13:54:03 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 55527, None)
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  task1.mysql_config_project$ - Application started!
2025-03-29 13:54:03 [main] ERROR task1.mysql_config_project$ - An error occurred
2025-03-29 13:54:03 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-03-29 13:54:03 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158e9f6e{/SQL,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54b2fc58{/SQL/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5426cb36{/SQL/execution,null,AVAILABLE,@Spark}
2025-03-29 13:54:03 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b1ec694{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-03-29 13:54:04 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/static/sql,null,AVAILABLE,@Spark}
2025-03-29 13:54:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 249.5845 ms
2025-03-29 13:54:08 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:32
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at mysql_config_project.scala:32) with 1 output partitions
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at mysql_config_project.scala:32)
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32), which has no missing parents
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-03-29 13:54:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:55527 (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at mysql_config_project.scala:32) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-03-29 13:54:08 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-03-29 13:54:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:08 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-03-29 13:54:08 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 188 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:08 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at mysql_config_project.scala:32) finished in 0.474 s
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-03-29 13:54:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at mysql_config_project.scala:32, took 0.515413 s
2025-03-29 13:54:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.527 ms
2025-03-29 13:54:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.0907 ms
2025-03-29 13:54:08 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at mysql_config_project.scala:35
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at mysql_config_project.scala:35) with 1 output partitions
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at mysql_config_project.scala:35)
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35), which has no missing parents
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-03-29 13:54:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:55527 (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at mysql_config_project.scala:35) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-03-29 13:54:08 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-03-29 13:54:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:08 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1773 bytes result sent to driver
2025-03-29 13:54:08 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:08 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at mysql_config_project.scala:35) finished in 0.045 s
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-03-29 13:54:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at mysql_config_project.scala:35, took 0.048661 s
2025-03-29 13:54:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 24.0694 ms
2025-03-29 13:54:08 [main] INFO  task1.mysql_config_project$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-03-29 13:54:09 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 22.1865 ms
2025-03-29 13:54:09 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (show at mysql_config_project.scala:58)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:54:09 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:55527 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-03-29 13:54:09 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 1823 bytes result sent to driver
2025-03-29 13:54:09 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:09 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (show at mysql_config_project.scala:58) finished in 0.034 s
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-03-29 13:54:09 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: show at mysql_config_project.scala:58, took 0.038395 s
2025-03-29 13:54:09 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.6236 ms
2025-03-29 13:54:09 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:54:09 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:55527 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-03-29 13:54:09 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 1545 bytes result sent to driver
2025-03-29 13:54:09 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 27 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:09 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (isEmpty at get_df_from_tablename.scala:39) finished in 0.044 s
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-03-29 13:54:09 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: isEmpty at get_df_from_tablename.scala:39, took 0.047833 s
2025-03-29 13:54:09 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.9228 ms
2025-03-29 13:54:09 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at get_df_from_tablename.scala:58)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[16] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:54:09 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:55527 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-03-29 13:54:09 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:09 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1405 bytes result sent to driver
2025-03-29 13:54:09 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 201 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:09 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at get_df_from_tablename.scala:58) finished in 0.252 s
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-03-29 13:54:09 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at get_df_from_tablename.scala:58, took 0.256589 s
2025-03-29 13:54:09 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:54:10 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:10 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:10 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:10 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:10 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:10 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:10 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:10 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.3382 ms
2025-03-29 13:54:10 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (save at mysql_config_project.scala:71)
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[19] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-03-29 13:54:10 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:55527 (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:10 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-03-29 13:54:10 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-03-29 13:54:10 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on YAU:55527 in memory (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:55527 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:55527 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:55527 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on YAU:55527 in memory (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291354107203419527287611636_0005_m_000000_5' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202503291354107203419527287611636_0005_m_000000
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291354107203419527287611636_0005_m_000000_5: Committed. Elapsed time: 8 ms.
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 2828 bytes result sent to driver
2025-03-29 13:54:11 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 1103 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:11 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (save at mysql_config_project.scala:71) finished in 1.148 s
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-03-29 13:54:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: save at mysql_config_project.scala:71, took 1.152267 s
2025-03-29 13:54:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job eea7aa0c-4e7a-440f-8534-ce8fb5f48d2a.
2025-03-29 13:54:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job eea7aa0c-4e7a-440f-8534-ce8fb5f48d2a committed. Elapsed time: 28 ms.
2025-03-29 13:54:11 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job eea7aa0c-4e7a-440f-8534-ce8fb5f48d2a.
2025-03-29 13:54:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 15.3349 ms
2025-03-29 13:54:11 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:122
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (show at mysql_config_project.scala:122) with 1 output partitions
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (show at mysql_config_project.scala:122)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[22] at show at mysql_config_project.scala:122), which has no missing parents
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 4.5 GiB)
2025-03-29 13:54:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:55527 (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[22] at show at mysql_config_project.scala:122) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-03-29 13:54:11 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1822 bytes result sent to driver
2025-03-29 13:54:11 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 30 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:11 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (show at mysql_config_project.scala:122) finished in 0.040 s
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-03-29 13:54:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: show at mysql_config_project.scala:122, took 0.044446 s
2025-03-29 13:54:11 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[25] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:54:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:55527 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[25] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-03-29 13:54:11 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 1502 bytes result sent to driver
2025-03-29 13:54:11 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 24 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:11 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (isEmpty at get_df_from_tablename.scala:39) finished in 0.032 s
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-03-29 13:54:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: isEmpty at get_df_from_tablename.scala:39, took 0.034869 s
2025-03-29 13:54:11 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.4767 ms
2025-03-29 13:54:11 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (save at get_df_from_tablename.scala:58)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[30] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 25.9 KiB, free 4.5 GiB)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 4.5 GiB)
2025-03-29 13:54:11 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:55527 (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[30] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-03-29 13:54:11 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:11 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1362 bytes result sent to driver
2025-03-29 13:54:11 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 53 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:11 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (save at get_df_from_tablename.scala:58) finished in 0.064 s
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:11 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-03-29 13:54:11 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: save at get_df_from_tablename.scala:58, took 0.066837 s
2025-03-29 13:54:12 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:54:12 [main] INFO  task1.mysql_config_project$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-03-29 13:54:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.2836 ms
2025-03-29 13:54:12 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 9 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (show at mysql_config_project.scala:58)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[33] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:54:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:55527 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[33] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 1 tasks resource profile 0
2025-03-29 13:54:12 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 1881 bytes result sent to driver
2025-03-29 13:54:12 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 26 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:12 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 9 (show at mysql_config_project.scala:58) finished in 0.035 s
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 9: Stage finished
2025-03-29 13:54:12 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 9 finished: show at mysql_config_project.scala:58, took 0.039094 s
2025-03-29 13:54:12 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[36] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:54:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:55527 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[36] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 1 tasks resource profile 0
2025-03-29 13:54:12 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 10) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 10)
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 10.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 10). 1459 bytes result sent to driver
2025-03-29 13:54:12 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 10) in 21 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:12 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 10 (isEmpty at get_df_from_tablename.scala:39) finished in 0.029 s
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 10: Stage finished
2025-03-29 13:54:12 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: isEmpty at get_df_from_tablename.scala:39, took 0.032353 s
2025-03-29 13:54:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.201 ms
2025-03-29 13:54:12 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 11 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (save at get_df_from_tablename.scala:58)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[41] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:54:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:55527 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[41] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-03-29 13:54:12 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 1319 bytes result sent to driver
2025-03-29 13:54:12 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 47 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:12 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (save at get_df_from_tablename.scala:58) finished in 0.062 s
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-03-29 13:54:12 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 11 finished: save at get_df_from_tablename.scala:58, took 0.066551 s
2025-03-29 13:54:12 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:54:12 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:12 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:12 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.531 ms
2025-03-29 13:54:12 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 12 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 12 (save at mysql_config_project.scala:71)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 12 (MapPartitionsRDD[44] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-03-29 13:54:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:55527 (size: 77.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[44] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 12.0 with 1 tasks resource profile 0
2025-03-29 13:54:12 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 12.0 (TID 12) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 12)
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 13:54:12 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on YAU:55527 in memory (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on YAU:55527 in memory (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_11_piece0 on YAU:55527 in memory (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_9_piece0 on YAU:55527 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_10_piece0 on YAU:55527 in memory (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on YAU:55527 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on YAU:55527 in memory (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291354121937935869426743326_0012_m_000000_12' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202503291354121937935869426743326_0012_m_000000
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291354121937935869426743326_0012_m_000000_12: Committed. Elapsed time: 5 ms.
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 12.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 12). 2785 bytes result sent to driver
2025-03-29 13:54:13 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 12.0 (TID 12) in 943 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:13 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 12 (save at mysql_config_project.scala:71) finished in 0.973 s
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 12: Stage finished
2025-03-29 13:54:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 12 finished: save at mysql_config_project.scala:71, took 0.974843 s
2025-03-29 13:54:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 8448ce66-9558-4b3d-b480-f89bcd5efdcb.
2025-03-29 13:54:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 8448ce66-9558-4b3d-b480-f89bcd5efdcb committed. Elapsed time: 17 ms.
2025-03-29 13:54:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 8448ce66-9558-4b3d-b480-f89bcd5efdcb.
2025-03-29 13:54:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.9473 ms
2025-03-29 13:54:13 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:122
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 13 (show at mysql_config_project.scala:122) with 1 output partitions
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 13 (show at mysql_config_project.scala:122)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 13 (MapPartitionsRDD[47] at show at mysql_config_project.scala:122), which has no missing parents
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on YAU:55527 (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 13 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[47] at show at mysql_config_project.scala:122) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 13.0 with 1 tasks resource profile 0
2025-03-29 13:54:13 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 13.0 (TID 13) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 13)
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 13.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 13). 1850 bytes result sent to driver
2025-03-29 13:54:13 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 13.0 (TID 13) in 21 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:13 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 13 (show at mysql_config_project.scala:122) finished in 0.027 s
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 13: Stage finished
2025-03-29 13:54:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 13 finished: show at mysql_config_project.scala:122, took 0.029029 s
2025-03-29 13:54:13 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 14 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 14 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 14 (MapPartitionsRDD[50] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on YAU:55527 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[50] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 14.0 with 1 tasks resource profile 0
2025-03-29 13:54:13 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 14.0 (TID 14) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 14)
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 14.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 14). 1459 bytes result sent to driver
2025-03-29 13:54:13 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 14.0 (TID 14) in 21 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:13 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 14 (isEmpty at get_df_from_tablename.scala:39) finished in 0.026 s
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 14: Stage finished
2025-03-29 13:54:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 14 finished: isEmpty at get_df_from_tablename.scala:39, took 0.028153 s
2025-03-29 13:54:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.5589 ms
2025-03-29 13:54:13 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 15 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 15 (save at get_df_from_tablename.scala:58)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 15 (MapPartitionsRDD[55] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 25.9 KiB, free 4.5 GiB)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on YAU:55527 (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[55] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 15.0 with 1 tasks resource profile 0
2025-03-29 13:54:13 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 15.0 (TID 15) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 15)
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 15.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 15). 1362 bytes result sent to driver
2025-03-29 13:54:13 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 15.0 (TID 15) in 47 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:13 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 15 (save at get_df_from_tablename.scala:58) finished in 0.061 s
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 15: Stage finished
2025-03-29 13:54:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 15 finished: save at get_df_from_tablename.scala:58, took 0.063746 s
2025-03-29 13:54:13 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:54:13 [main] INFO  task1.mysql_config_project$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-03-29 13:54:13 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.3323 ms
2025-03-29 13:54:13 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 16 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 16 (show at mysql_config_project.scala:58)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 16 (MapPartitionsRDD[58] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:54:13 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on YAU:55527 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 16 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[58] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 16.0 with 1 tasks resource profile 0
2025-03-29 13:54:13 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 16.0 (TID 16) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:13 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 16)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 16.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 16). 1839 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 16.0 (TID 16) in 22 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 16 (show at mysql_config_project.scala:58) finished in 0.030 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 16: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 16 finished: show at mysql_config_project.scala:58, took 0.032173 s
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 17 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 17 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 17 (MapPartitionsRDD[61] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on YAU:55527 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[61] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 17.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 17.0 (TID 17) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 17)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 17.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 17). 1502 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 17.0 (TID 17) in 19 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 17 (isEmpty at get_df_from_tablename.scala:39) finished in 0.025 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 17: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 17 finished: isEmpty at get_df_from_tablename.scala:39, took 0.026502 s
2025-03-29 13:54:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.5088 ms
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 18 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 18 (save at get_df_from_tablename.scala:58)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 18 (MapPartitionsRDD[66] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_18_piece0 in memory on YAU:55527 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 18 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[66] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 18.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-14] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 18.0 (TID 18) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 18.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 18.0 (TID 18)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 18.0 (TID 18)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 18.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 18.0 (TID 18). 1319 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 18.0 (TID 18) in 40 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 18 (save at get_df_from_tablename.scala:58) finished in 0.053 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 18: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 18 finished: save at get_df_from_tablename.scala:58, took 0.055468 s
2025-03-29 13:54:14 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:54:14 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:14 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:14 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:14 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:14 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:14 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:14 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.1961 ms
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: save at mysql_config_project.scala:71
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 19 (save at mysql_config_project.scala:71) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 19 (save at mysql_config_project.scala:71)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 19 (MapPartitionsRDD[69] at save at mysql_config_project.scala:71), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_19_piece0 in memory on YAU:55527 (size: 77.6 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 19 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[69] at save at mysql_config_project.scala:71) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 19.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 19.0 (TID 19) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 19.0 (TID 19)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_20250329135414155758001481444954_0019_m_000000_19' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_20250329135414155758001481444954_0019_m_000000
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_20250329135414155758001481444954_0019_m_000000_19: Committed. Elapsed time: 4 ms.
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 19.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 19.0 (TID 19). 2742 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 19.0 (TID 19) in 120 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 19 (save at mysql_config_project.scala:71) finished in 0.147 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 19: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 19 finished: save at mysql_config_project.scala:71, took 0.148423 s
2025-03-29 13:54:14 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 62d4d551-868c-4654-8349-a012f1dce507.
2025-03-29 13:54:14 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 62d4d551-868c-4654-8349-a012f1dce507 committed. Elapsed time: 16 ms.
2025-03-29 13:54:14 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 62d4d551-868c-4654-8349-a012f1dce507.
2025-03-29 13:54:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.6716 ms
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:122
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 20 (show at mysql_config_project.scala:122) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 20 (show at mysql_config_project.scala:122)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 20 (MapPartitionsRDD[72] at show at mysql_config_project.scala:122), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_20_piece0 in memory on YAU:55527 (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 20 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[72] at show at mysql_config_project.scala:122) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 20.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-5] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 20.0 (TID 20) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 20.0 (TID 20)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 20.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 20.0 (TID 20). 1858 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 20.0 (TID 20) in 20 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 20 (show at mysql_config_project.scala:122) finished in 0.025 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 20: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 20 finished: show at mysql_config_project.scala:122, took 0.027008 s
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 21 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 21 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 21 (MapPartitionsRDD[75] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_21_piece0 in memory on YAU:55527 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 21 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[75] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 21.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 21.0 (TID 21) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 21.0 (TID 21)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 21.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 21.0 (TID 21). 1502 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 21.0 (TID 21) in 16 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 21 (isEmpty at get_df_from_tablename.scala:39) finished in 0.022 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 21: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 21 finished: isEmpty at get_df_from_tablename.scala:39, took 0.024749 s
2025-03-29 13:54:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.7776 ms
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 22 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 22 (save at get_df_from_tablename.scala:58)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 22 (MapPartitionsRDD[80] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_22 stored as values in memory (estimated size 25.9 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_22_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_22_piece0 in memory on YAU:55527 (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 22 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[80] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 22.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 22.0 (TID 22) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 22.0 (TID 22)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 22.0 (TID 22)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 22.0 (TID 22)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 22.0 (TID 22)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 22.0 (TID 22). 1319 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 22.0 (TID 22) in 43 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 22 (save at get_df_from_tablename.scala:58) finished in 0.052 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 22: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 22 finished: save at get_df_from_tablename.scala:58, took 0.053394 s
2025-03-29 13:54:14 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:54:14 [main] INFO  task1.mysql_config_project$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-03-29 13:54:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.0229 ms
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:58
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 23 (show at mysql_config_project.scala:58) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 23 (show at mysql_config_project.scala:58)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 23 (MapPartitionsRDD[83] at show at mysql_config_project.scala:58), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_23 stored as values in memory (estimated size 15.2 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_23_piece0 in memory on YAU:55527 (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 23 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[83] at show at mysql_config_project.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 23.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-14] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 23.0 (TID 23) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 23.0 (TID 23)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 23.0 (TID 23)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 23.0 (TID 23)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 23.0 (TID 23)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 23.0 (TID 23). 1850 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 23.0 (TID 23) in 21 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 23 (show at mysql_config_project.scala:58) finished in 0.028 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 23: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 23 finished: show at mysql_config_project.scala:58, took 0.029734 s
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 24 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 24 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 24 (MapPartitionsRDD[86] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_24 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_24_piece0 in memory on YAU:55527 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 24 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[86] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 24.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-3] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 24.0 (TID 24) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 24.0 (TID 24)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 24.0 (TID 24)
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 24.0 (TID 24)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 24.0 (TID 24)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 24.0 (TID 24). 1502 bytes result sent to driver
2025-03-29 13:54:14 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 24.0 (TID 24) in 20 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:14 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 24 (isEmpty at get_df_from_tablename.scala:39) finished in 0.026 s
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 24: Stage finished
2025-03-29 13:54:14 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 24 finished: isEmpty at get_df_from_tablename.scala:39, took 0.028223 s
2025-03-29 13:54:14 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.6486 ms
2025-03-29 13:54:14 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 25 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 25 (save at get_df_from_tablename.scala:58)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 25 (MapPartitionsRDD[91] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_25 stored as values in memory (estimated size 25.3 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 4.5 GiB)
2025-03-29 13:54:14 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_25_piece0 in memory on YAU:55527 (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 25 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[91] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:14 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 25.0 with 1 tasks resource profile 0
2025-03-29 13:54:14 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 25.0 (TID 25) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:14 [Executor task launch worker for task 0.0 in stage 25.0 (TID 25)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 25.0 (TID 25)
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 25.0 (TID 25)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 25.0 (TID 25)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 25.0 (TID 25). 1319 bytes result sent to driver
2025-03-29 13:54:15 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 25.0 (TID 25) in 40 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:15 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 25 (save at get_df_from_tablename.scala:58) finished in 0.048 s
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 25: Stage finished
2025-03-29 13:54:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 25 finished: save at get_df_from_tablename.scala:58, took 0.050165 s
2025-03-29 13:54:15 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:54:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.4228 ms
2025-03-29 13:54:15 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:74
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 26 (show at mysql_config_project.scala:74) with 1 output partitions
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 26 (show at mysql_config_project.scala:74)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 26 (MapPartitionsRDD[94] at show at mysql_config_project.scala:74), which has no missing parents
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_26 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_26_piece0 in memory on YAU:55527 (size: 6.3 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 26 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[94] at show at mysql_config_project.scala:74) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 26.0 with 1 tasks resource profile 0
2025-03-29 13:54:15 [dispatcher-event-loop-7] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 26.0 (TID 26) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 26.0 (TID 26)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 26.0 (TID 26)
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 26.0 (TID 26)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 26.0 (TID 26)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 26.0 (TID 26). 4233 bytes result sent to driver
2025-03-29 13:54:15 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 26.0 (TID 26) in 41 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:15 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 26 (show at mysql_config_project.scala:74) finished in 0.047 s
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 26: Stage finished
2025-03-29 13:54:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 26 finished: show at mysql_config_project.scala:74, took 0.048902 s
2025-03-29 13:54:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.9864 ms
2025-03-29 13:54:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.1903 ms
2025-03-29 13:54:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 4.1498 ms
2025-03-29 13:54:15 [main] INFO  org.apache.spark.SparkContext - Starting job: first at mysql_config_project.scala:82
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 27 (first at mysql_config_project.scala:82) with 1 output partitions
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 27 (first at mysql_config_project.scala:82)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 27 (MapPartitionsRDD[98] at first at mysql_config_project.scala:82), which has no missing parents
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_27 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_27_piece0 in memory on YAU:55527 (size: 6.4 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 27 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[98] at first at mysql_config_project.scala:82) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 27.0 with 1 tasks resource profile 0
2025-03-29 13:54:15 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 27.0 (TID 27) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 27.0 (TID 27)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 27.0 (TID 27)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_21_piece0 on YAU:55527 in memory (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 27.0 (TID 27)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_15_piece0 on YAU:55527 in memory (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 27.0 (TID 27)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 27.0 (TID 27). 1691 bytes result sent to driver
2025-03-29 13:54:15 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 27.0 (TID 27) in 69 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:15 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 27 (first at mysql_config_project.scala:82) finished in 0.074 s
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 27: Stage finished
2025-03-29 13:54:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 27 finished: first at mysql_config_project.scala:82, took 0.076037 s
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_16_piece0 on YAU:55527 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_25_piece0 on YAU:55527 in memory (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.5446 ms
2025-03-29 13:54:15 [main] INFO  task1.mysql_config_project$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_23_piece0 on YAU:55527 in memory (size: 7.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_17_piece0 on YAU:55527 in memory (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_22_piece0 on YAU:55527 in memory (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_18_piece0 on YAU:55527 in memory (size: 11.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_14_piece0 on YAU:55527 in memory (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_24_piece0 on YAU:55527 in memory (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_19_piece0 on YAU:55527 in memory (size: 77.6 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_26_piece0 on YAU:55527 in memory (size: 6.3 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_20_piece0 on YAU:55527 in memory (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_13_piece0 on YAU:55527 in memory (size: 7.4 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 24 ms to list leaf files for 1 paths.
2025-03-29 13:54:15 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 28 (load at update_parquet.scala:18) with 1 output partitions
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 28 (load at update_parquet.scala:18)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 28 (MapPartitionsRDD[100] at load at update_parquet.scala:18), which has no missing parents
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_28 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_28_piece0 in memory on YAU:55527 (size: 36.9 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 28 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[100] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 28.0 with 1 tasks resource profile 0
2025-03-29 13:54:15 [dispatcher-event-loop-13] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 28.0 (TID 28) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9092 bytes) 
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 28.0 (TID 28)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 28.0 (TID 28)
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 28.0 (TID 28)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 28.0 (TID 28). 2377 bytes result sent to driver
2025-03-29 13:54:15 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 28.0 (TID 28) in 127 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:15 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 28 (load at update_parquet.scala:18) finished in 0.140 s
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 28: Stage finished
2025-03-29 13:54:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 28 finished: load at update_parquet.scala:18, took 0.141874 s
2025-03-29 13:54:15 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 13:54:15 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 13:54:15 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.3102 ms
2025-03-29 13:54:15 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_29 stored as values in memory (estimated size 200.0 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_29_piece0 in memory on YAU:55527 (size: 34.6 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [main] INFO  org.apache.spark.SparkContext - Created broadcast 29 from isEmpty at update_parquet.scala:19
2025-03-29 13:54:15 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 13:54:15 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at update_parquet.scala:19
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 29 (isEmpty at update_parquet.scala:19) with 1 output partitions
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 29 (isEmpty at update_parquet.scala:19)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 29 (MapPartitionsRDD[104] at isEmpty at update_parquet.scala:19), which has no missing parents
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_30 stored as values in memory (estimated size 11.3 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 4.5 GiB)
2025-03-29 13:54:15 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_30_piece0 in memory on YAU:55527 (size: 5.4 KiB, free: 4.5 GiB)
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 30 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[104] at isEmpty at update_parquet.scala:19) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 29.0 with 1 tasks resource profile 0
2025-03-29 13:54:15 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 29.0 (TID 29) (YAU, executor driver, partition 0, NODE_LOCAL, 9450 bytes) 
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 29.0 (TID 29)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 29.0 (TID 29)
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 29.0 (TID 29)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-92ee86d0-7d82-449c-be8e-37ba7d7f959a-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-29 13:54:15 [Executor task launch worker for task 0.0 in stage 29.0 (TID 29)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 29.0 (TID 29). 1796 bytes result sent to driver
2025-03-29 13:54:15 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 29.0 (TID 29) in 89 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:15 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 29 (isEmpty at update_parquet.scala:19) finished in 0.101 s
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:15 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 29: Stage finished
2025-03-29 13:54:15 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 29 finished: isEmpty at update_parquet.scala:19, took 0.106388 s
2025-03-29 13:54:15 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-03-29 13:54:15 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-03-29 13:54:16 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-29 13:54:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 27.1293 ms
2025-03-29 13:54:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.5791 ms
2025-03-29 13:54:16 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_31 stored as values in memory (estimated size 201.1 KiB, free 4.5 GiB)
2025-03-29 13:54:16 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_31_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 4.5 GiB)
2025-03-29 13:54:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_31_piece0 in memory on YAU:55527 (size: 35.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:16 [main] INFO  org.apache.spark.SparkContext - Created broadcast 31 from save at update_parquet.scala:46
2025-03-29 13:54:16 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-03-29 13:54:16 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.5378 ms
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 112 (save at update_parquet.scala:46) as input to shuffle 0
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got map stage job 30 (save at update_parquet.scala:46) with 2 output partitions
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 30 (save at update_parquet.scala:46)
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 30 (MapPartitionsRDD[112] at save at update_parquet.scala:46), which has no missing parents
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_32 stored as values in memory (estimated size 46.8 KiB, free 4.5 GiB)
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_32_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 4.5 GiB)
2025-03-29 13:54:16 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_32_piece0 in memory on YAU:55527 (size: 18.9 KiB, free: 4.5 GiB)
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 32 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[112] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2025-03-29 13:54:16 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 30.0 with 2 tasks resource profile 0
2025-03-29 13:54:16 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 30.0 (TID 30) (YAU, executor driver, partition 0, NODE_LOCAL, 9548 bytes) 
2025-03-29 13:54:16 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 30.0 (TID 31) (YAU, executor driver, partition 1, PROCESS_LOCAL, 8765 bytes) 
2025-03-29 13:54:16 [Executor task launch worker for task 0.0 in stage 30.0 (TID 30)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 30.0 (TID 30)
2025-03-29 13:54:16 [Executor task launch worker for task 1.0 in stage 30.0 (TID 31)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 30.0 (TID 31)
2025-03-29 13:54:16 [Executor task launch worker for task 0.0 in stage 30.0 (TID 30)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.7797 ms
2025-03-29 13:54:16 [Executor task launch worker for task 1.0 in stage 30.0 (TID 31)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.5403 ms
2025-03-29 13:54:16 [Executor task launch worker for task 1.0 in stage 30.0 (TID 31)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 8.631 ms
2025-03-29 13:54:16 [Executor task launch worker for task 0.0 in stage 30.0 (TID 30)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-92ee86d0-7d82-449c-be8e-37ba7d7f959a-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-03-29 13:54:16 [Executor task launch worker for task 1.0 in stage 30.0 (TID 31)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:16 [Executor task launch worker for task 0.0 in stage 30.0 (TID 30)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new decompressor [.snappy]
2025-03-29 13:54:17 [Executor task launch worker for task 1.0 in stage 30.0 (TID 31)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 30.0 (TID 31). 3234 bytes result sent to driver
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 30.0 (TID 30)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 30.0 (TID 30). 3277 bytes result sent to driver
2025-03-29 13:54:17 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 30.0 (TID 31) in 928 ms on YAU (executor driver) (1/2)
2025-03-29 13:54:17 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 30.0 (TID 30) in 931 ms on YAU (executor driver) (2/2)
2025-03-29 13:54:17 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 30 (save at update_parquet.scala:46) finished in 0.949 s
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: HashSet()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: HashSet()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: HashSet()
2025-03-29 13:54:17 [main] INFO  o.a.s.s.e.a.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-03-29 13:54:17 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:17 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:17 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:17 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:17 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:17 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:17 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:17 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-03-29 13:54:17 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 9.406 ms
2025-03-29 13:54:17 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:46
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 31 (save at update_parquet.scala:46) with 1 output partitions
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 32 (save at update_parquet.scala:46)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 31)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 32 (MapPartitionsRDD[115] at save at update_parquet.scala:46), which has no missing parents
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_33 stored as values in memory (estimated size 243.5 KiB, free 4.5 GiB)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_33_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 4.5 GiB)
2025-03-29 13:54:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_33_piece0 in memory on YAU:55527 (size: 89.0 KiB, free: 4.5 GiB)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 33 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[115] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 32.0 with 1 tasks resource profile 0
2025-03-29 13:54:17 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 32.0 (TID 32) (YAU, executor driver, partition 0, NODE_LOCAL, 8821 bytes) 
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 32.0 (TID 32)
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 2 (1173.7 KiB) non-empty blocks including 2 (1173.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 11 ms
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202503291354175941890037424735658_0032_m_000000_32' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202503291354175941890037424735658_0032_m_000000
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202503291354175941890037424735658_0032_m_000000_32: Committed. Elapsed time: 5 ms.
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 32.0 (TID 32)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 32.0 (TID 32). 6741 bytes result sent to driver
2025-03-29 13:54:17 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 32.0 (TID 32) in 192 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:17 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 32 (save at update_parquet.scala:46) finished in 0.211 s
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 32: Stage finished
2025-03-29 13:54:17 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 31 finished: save at update_parquet.scala:46, took 0.220744 s
2025-03-29 13:54:17 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 19b170df-5431-4fcf-9e5c-031c0cc47e1c.
2025-03-29 13:54:17 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 19b170df-5431-4fcf-9e5c-031c0cc47e1c committed. Elapsed time: 17 ms.
2025-03-29 13:54:17 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 19b170df-5431-4fcf-9e5c-031c0cc47e1c.
2025-03-29 13:54:17 [main] INFO  functions.update_parquet$ - Delta load completed for timestamp
2025-03-29 13:54:17 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.0016 ms
2025-03-29 13:54:17 [main] INFO  org.apache.spark.SparkContext - Starting job: show at mysql_config_project.scala:122
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 32 (show at mysql_config_project.scala:122) with 1 output partitions
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 33 (show at mysql_config_project.scala:122)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 33 (MapPartitionsRDD[118] at show at mysql_config_project.scala:122), which has no missing parents
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_34 stored as values in memory (estimated size 15.5 KiB, free 4.5 GiB)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_34_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 4.5 GiB)
2025-03-29 13:54:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_34_piece0 in memory on YAU:55527 (size: 7.3 KiB, free: 4.5 GiB)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 34 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[118] at show at mysql_config_project.scala:122) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 33.0 with 1 tasks resource profile 0
2025-03-29 13:54:17 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 33.0 (TID 33) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 33.0 (TID 33)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 33.0 (TID 33)
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 33.0 (TID 33)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 33.0 (TID 33)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 33.0 (TID 33). 1861 bytes result sent to driver
2025-03-29 13:54:17 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 33.0 (TID 33) in 17 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:17 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 33 (show at mysql_config_project.scala:122) finished in 0.020 s
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 33: Stage finished
2025-03-29 13:54:17 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 32 finished: show at mysql_config_project.scala:122, took 0.022538 s
2025-03-29 13:54:17 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at get_df_from_tablename.scala:39
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 33 (isEmpty at get_df_from_tablename.scala:39) with 1 output partitions
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 34 (isEmpty at get_df_from_tablename.scala:39)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 34 (MapPartitionsRDD[121] at isEmpty at get_df_from_tablename.scala:39), which has no missing parents
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_35 stored as values in memory (estimated size 9.7 KiB, free 4.5 GiB)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 4.5 GiB)
2025-03-29 13:54:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_35_piece0 in memory on YAU:55527 (size: 5.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 35 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[121] at isEmpty at get_df_from_tablename.scala:39) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 34.0 with 1 tasks resource profile 0
2025-03-29 13:54:17 [dispatcher-event-loop-15] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 34.0 (TID 34) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 34.0 (TID 34)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 34.0 (TID 34)
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 34.0 (TID 34)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 34.0 (TID 34)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 34.0 (TID 34). 1502 bytes result sent to driver
2025-03-29 13:54:17 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 34.0 (TID 34) in 17 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:17 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 34 (isEmpty at get_df_from_tablename.scala:39) finished in 0.020 s
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 34: Stage finished
2025-03-29 13:54:17 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 33 finished: isEmpty at get_df_from_tablename.scala:39, took 0.021798 s
2025-03-29 13:54:17 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.1363 ms
2025-03-29 13:54:17 [main] INFO  org.apache.spark.SparkContext - Starting job: save at get_df_from_tablename.scala:58
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 34 (save at get_df_from_tablename.scala:58) with 1 output partitions
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 35 (save at get_df_from_tablename.scala:58)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 35 (MapPartitionsRDD[126] at save at get_df_from_tablename.scala:58), which has no missing parents
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_36 stored as values in memory (estimated size 25.9 KiB, free 4.5 GiB)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_36_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 4.5 GiB)
2025-03-29 13:54:17 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_36_piece0 in memory on YAU:55527 (size: 11.2 KiB, free: 4.5 GiB)
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 36 from broadcast at DAGScheduler.scala:1540
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[126] at save at get_df_from_tablename.scala:58) (first 15 tasks are for partitions Vector(0))
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 35.0 with 1 tasks resource profile 0
2025-03-29 13:54:17 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 35.0 (TID 35) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 35.0 (TID 35)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 35.0 (TID 35)
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 35.0 (TID 35)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-03-29 13:54:17 [Executor task launch worker for task 0.0 in stage 35.0 (TID 35)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 35.0 (TID 35). 1319 bytes result sent to driver
2025-03-29 13:54:17 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 35.0 (TID 35) in 41 ms on YAU (executor driver) (1/1)
2025-03-29 13:54:17 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 35 (save at get_df_from_tablename.scala:58) finished in 0.054 s
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
2025-03-29 13:54:17 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 35: Stage finished
2025-03-29 13:54:17 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 34 finished: save at get_df_from_tablename.scala:58, took 0.055744 s
2025-03-29 13:54:17 [main] INFO  functions.get_df_from_tablename$ - Successfully updated table config
2025-03-29 13:54:17 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-03-29 13:54:17 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-03-29 13:54:17 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-03-29 13:54:17 [dispatcher-event-loop-6] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-03-29 13:54:17 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-03-29 13:54:17 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-03-29 13:54:17 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-03-29 13:54:17 [dispatcher-event-loop-10] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-03-29 13:54:17 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-03-29 13:54:17 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-03-29 13:54:17 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-4f06ab8a-d101-47f4-8349-b24367928802
2025-04-02 22:14:53 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-04-02 22:14:54 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-04-02 22:14:54 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-04-02 22:14:54 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-04-02 22:14:54 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-04-02 22:14:54 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-04-02 22:14:54 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-04-02 22:14:54 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-04-02 22:14:54 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-04-02 22:14:54 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-04-02 22:14:54 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-04-02 22:14:54 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-04-02 22:14:54 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-04-02 22:14:54 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50624.
2025-04-02 22:14:54 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-04-02 22:14:54 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-04-02 22:14:55 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-04-02 22:14:55 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-04-02 22:14:55 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-04-02 22:14:55 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-1db16bdd-ee2a-4a19-8449-db7411908ed9
2025-04-02 22:14:55 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-04-02 22:14:55 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-04-02 22:14:55 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2707ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-04-02 22:14:55 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-04-02 22:14:55 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-04-02 22:14:55 [main] INFO  o.sparkproject.jetty.server.Server - Started @2831ms
2025-04-02 22:14:55 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-04-02 22:14:55 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@468dda3e{/,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-04-02 22:14:55 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-04-02 22:14:55 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50675.
2025-04-02 22:14:55 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:50675
2025-04-02 22:14:55 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-04-02 22:14:55 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 50675, None)
2025-04-02 22:14:55 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:50675 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 50675, None)
2025-04-02 22:14:55 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 50675, None)
2025-04-02 22:14:55 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 50675, None)
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@468dda3e{/,null,STOPPED,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bee793f{/jobs,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43b5021c{/jobs/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4548d254{/jobs/job,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208f0007{/jobs/job/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39c96e48{/stages,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@40d23c82{/stages/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@550de6b8{/stages/stage,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c6c4689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/stages/pool,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/stages/pool/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd64b11{/storage,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/storage/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/storage/rdd,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/environment,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@365cdacf{/environment/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9efcd90{/executors,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/executors/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/static,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49e4c2d5{/,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/api,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b960b5b{/metrics/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:55 [main] INFO  Main$ - Application started!
2025-04-02 22:14:55 [main] INFO  Main$ - hdfs
2025-04-02 22:14:55 [main] INFO  Main$ - LOGGING TEST - LOAD MYSQL DATA TO HDFS
2025-04-02 22:14:56 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-04-02 22:14:56 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-04-02 22:14:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0e9707{/SQL,null,AVAILABLE,@Spark}
2025-04-02 22:14:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74024f3{/SQL/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3fcee3d9{/SQL/execution,null,AVAILABLE,@Spark}
2025-04-02 22:14:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@760487aa{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-04-02 22:14:56 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4faf104{/static/sql,null,AVAILABLE,@Spark}
2025-04-02 22:15:00 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 261.8623 ms
2025-04-02 22:15:00 [main] INFO  org.apache.spark.SparkContext - Starting job: show at Main.scala:34
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at Main.scala:34) with 1 output partitions
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at Main.scala:34)
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-04-02 22:15:00 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:50675 (size: 7.0 KiB, free: 4.5 GiB)
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:15:00 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-04-02 22:15:01 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:15:01 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-04-02 22:15:01 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:15:01 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-04-02 22:15:01 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 191 ms on YAU (executor driver) (1/1)
2025-04-02 22:15:01 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at Main.scala:34) finished in 0.515 s
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-04-02 22:15:01 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at Main.scala:34, took 0.557752 s
2025-04-02 22:15:01 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 40.5507 ms
2025-04-02 22:15:01 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.5247 ms
2025-04-02 22:15:01 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at Main.scala:37
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at Main.scala:37) with 1 output partitions
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at Main.scala:37)
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at Main.scala:37), which has no missing parents
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-04-02 22:15:01 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:50675 (size: 6.2 KiB, free: 4.5 GiB)
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at Main.scala:37) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-04-02 22:15:01 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:15:01 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-04-02 22:15:01 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:15:01 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1773 bytes result sent to driver
2025-04-02 22:15:01 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on YAU (executor driver) (1/1)
2025-04-02 22:15:01 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at Main.scala:37) finished in 0.048 s
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:15:01 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-04-02 22:15:01 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at Main.scala:37, took 0.052626 s
2025-04-02 22:15:01 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 31.7339 ms
2025-04-02 22:15:01 [main] INFO  Main$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-04-02 22:15:02 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:15:02 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:15:02 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:15:02 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:15:02 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:15:02 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:15:02 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:15:02 [main] INFO  Main$ - ERROR IS >>>>>>>>>>>>>>>>>>>>> Call From YAU/192.168.1.37 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused: no further information; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused <<<<<<<<<<<<<<<<<
2025-04-02 22:15:02 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-04-02 22:15:02 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-04-02 22:15:02 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-04-02 22:15:02 [dispatcher-event-loop-13] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-04-02 22:15:02 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-04-02 22:15:02 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-04-02 22:15:02 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-04-02 22:15:02 [dispatcher-event-loop-1] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-04-02 22:15:02 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-04-02 22:15:02 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-04-02 22:15:02 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-a38ccaf7-8aa9-40fb-ac8c-546a1a30b201
2025-04-02 22:18:56 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-04-02 22:18:56 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-04-02 22:18:56 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-04-02 22:18:56 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-04-02 22:18:56 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-04-02 22:18:56 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-04-02 22:18:56 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-04-02 22:18:56 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-04-02 22:18:56 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-04-02 22:18:56 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-04-02 22:18:56 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-04-02 22:18:56 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-04-02 22:18:56 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-04-02 22:18:57 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50893.
2025-04-02 22:18:57 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-04-02 22:18:57 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-04-02 22:18:57 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-04-02 22:18:57 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-04-02 22:18:57 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-04-02 22:18:57 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-9308e1b0-2fa8-465f-89ad-d035762e21d2
2025-04-02 22:18:57 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-04-02 22:18:57 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-04-02 22:18:57 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @2589ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-04-02 22:18:57 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-04-02 22:18:57 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-04-02 22:18:57 [main] INFO  o.sparkproject.jetty.server.Server - Started @2719ms
2025-04-02 22:18:57 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-04-02 22:18:57 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-04-02 22:18:57 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7cea0110{/,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-04-02 22:18:58 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-04-02 22:18:58 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50944.
2025-04-02 22:18:58 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:50944
2025-04-02 22:18:58 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-04-02 22:18:58 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 50944, None)
2025-04-02 22:18:58 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:50944 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 50944, None)
2025-04-02 22:18:58 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 50944, None)
2025-04-02 22:18:58 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 50944, None)
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7cea0110{/,null,STOPPED,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@61514735{/jobs,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@655f69da{/jobs/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e86807a{/jobs/job,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@590f0c50{/jobs/job/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a90c13c{/stages,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@188598ad{/stages/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b7e8044{/stages/stage,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a1706e1{/stages/stage/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63cf9de0{/stages/pool,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5befbac1{/stages/pool/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a565afb{/storage,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@949c598{/storage/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bfaa0a6{/storage/rdd,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@314b9e4b{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51dae791{/environment,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5de5e95{/environment/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@303c55fa{/executors,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7eb200ce{/executors/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c2924d7{/executors/threadDump,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6587305a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f81621c{/static,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c1447b5{/,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24a2e565{/api,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48a663e9{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3178219a{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@465b38e6{/metrics/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  Main$ - Application started!
2025-04-02 22:18:58 [main] INFO  Main$ - hdfs
2025-04-02 22:18:58 [main] INFO  Main$ - LOGGING TEST - LOAD MYSQL DATA TO HDFS
2025-04-02 22:18:58 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-04-02 22:18:58 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dc769f9{/SQL,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9b5f3c7{/SQL/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e1b374c{/SQL/execution,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9c93d16{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-04-02 22:18:58 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5489b1f7{/static/sql,null,AVAILABLE,@Spark}
2025-04-02 22:19:03 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 271.1623 ms
2025-04-02 22:19:03 [main] INFO  org.apache.spark.SparkContext - Starting job: show at Main.scala:34
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at Main.scala:34) with 1 output partitions
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at Main.scala:34)
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-04-02 22:19:03 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:50944 (size: 7.0 KiB, free: 4.5 GiB)
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-04-02 22:19:03 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:19:03 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-04-02 22:19:03 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:19:03 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-04-02 22:19:03 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 186 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:03 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at Main.scala:34) finished in 0.488 s
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-04-02 22:19:03 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at Main.scala:34, took 0.529605 s
2025-04-02 22:19:03 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.5141 ms
2025-04-02 22:19:03 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.6915 ms
2025-04-02 22:19:03 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at Main.scala:37
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at Main.scala:37) with 1 output partitions
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at Main.scala:37)
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at Main.scala:37), which has no missing parents
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-04-02 22:19:03 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:50944 (size: 6.2 KiB, free: 4.5 GiB)
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at Main.scala:37) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-04-02 22:19:03 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:19:03 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-04-02 22:19:03 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:19:03 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1816 bytes result sent to driver
2025-04-02 22:19:03 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 38 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:03 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at Main.scala:37) finished in 0.049 s
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:03 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-04-02 22:19:03 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at Main.scala:37, took 0.052379 s
2025-04-02 22:19:04 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.5639 ms
2025-04-02 22:19:04 [main] INFO  Main$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-04-02 22:19:04 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:04 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:04 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:04 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:04 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:04 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:04 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:05 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 21.5973 ms
2025-04-02 22:19:05 [main] INFO  org.apache.spark.SparkContext - Starting job: save at Main.scala:55
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at Main.scala:55) with 1 output partitions
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at Main.scala:55)
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at save at Main.scala:55), which has no missing parents
2025-04-02 22:19:05 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:50944 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-04-02 22:19:05 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:50944 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-04-02 22:19:05 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:50944 (size: 76.9 KiB, free: 4.5 GiB)
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at save at Main.scala:55) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:05 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-04-02 22:19:05 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-04-02 22:19:05 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:19:06 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202504022219057682568141392547750_0002_m_000000_2' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202504022219057682568141392547750_0002_m_000000
2025-04-02 22:19:06 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202504022219057682568141392547750_0002_m_000000_2: Committed. Elapsed time: 16 ms.
2025-04-02 22:19:06 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2785 bytes result sent to driver
2025-04-02 22:19:06 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1629 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:06 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-04-02 22:19:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at Main.scala:55) finished in 1.677 s
2025-04-02 22:19:06 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:06 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-04-02 22:19:06 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at Main.scala:55, took 1.682421 s
2025-04-02 22:19:06 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job fefa32d0-bb31-466a-b10c-41a589f4ed5d.
2025-04-02 22:19:06 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job fefa32d0-bb31-466a-b10c-41a589f4ed5d committed. Elapsed time: 43 ms.
2025-04-02 22:19:06 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job fefa32d0-bb31-466a-b10c-41a589f4ed5d.
2025-04-02 22:19:06 [main] INFO  Main$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-04-02 22:19:07 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:07 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:07 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:07 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:07 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:07 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:07 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:07 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.6701 ms
2025-04-02 22:19:07 [main] INFO  org.apache.spark.SparkContext - Starting job: save at Main.scala:55
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at Main.scala:55) with 1 output partitions
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at Main.scala:55)
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at Main.scala:55), which has no missing parents
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-04-02 22:19:07 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:50944 (size: 77.2 KiB, free: 4.5 GiB)
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at Main.scala:55) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:07 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-04-02 22:19:07 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-04-02 22:19:07 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-04-02 22:19:07 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:50944 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202504022219075801464108212099716_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202504022219075801464108212099716_0003_m_000000
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202504022219075801464108212099716_0003_m_000000_3: Committed. Elapsed time: 6 ms.
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2785 bytes result sent to driver
2025-04-02 22:19:08 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 1195 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:08 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at Main.scala:55) finished in 1.238 s
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-04-02 22:19:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at Main.scala:55, took 1.243850 s
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job f1772468-acfd-4487-af36-23580c70b0f8.
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job f1772468-acfd-4487-af36-23580c70b0f8 committed. Elapsed time: 23 ms.
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job f1772468-acfd-4487-af36-23580c70b0f8.
2025-04-02 22:19:08 [main] INFO  Main$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:08 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:08 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:08 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:08 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.5865 ms
2025-04-02 22:19:08 [main] INFO  org.apache.spark.SparkContext - Starting job: save at Main.scala:55
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at Main.scala:55) with 1 output partitions
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at Main.scala:55)
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at save at Main.scala:55), which has no missing parents
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 77.7 KiB, free 4.5 GiB)
2025-04-02 22:19:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:50944 (size: 77.7 KiB, free: 4.5 GiB)
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at save at Main.scala:55) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-04-02 22:19:08 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202504022219088721253116672733180_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202504022219088721253116672733180_0004_m_000000
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202504022219088721253116672733180_0004_m_000000_4: Committed. Elapsed time: 6 ms.
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2742 bytes result sent to driver
2025-04-02 22:19:08 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 158 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:08 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at Main.scala:55) finished in 0.180 s
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-04-02 22:19:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at Main.scala:55, took 0.184787 s
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 3d621769-ce0a-496b-8c50-6a69bbcffee1.
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 3d621769-ce0a-496b-8c50-6a69bbcffee1 committed. Elapsed time: 24 ms.
2025-04-02 22:19:08 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 3d621769-ce0a-496b-8c50-6a69bbcffee1.
2025-04-02 22:19:08 [main] INFO  Main$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-04-02 22:19:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.247 ms
2025-04-02 22:19:08 [main] INFO  org.apache.spark.SparkContext - Starting job: show at Main.scala:58
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at Main.scala:58) with 1 output partitions
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at Main.scala:58)
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:58), which has no missing parents
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-04-02 22:19:08 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:50944 (size: 6.3 KiB, free: 4.5 GiB)
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:58) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-04-02 22:19:08 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:19:08 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 4233 bytes result sent to driver
2025-04-02 22:19:08 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 61 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:08 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at Main.scala:58) finished in 0.070 s
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:08 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-04-02 22:19:08 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at Main.scala:58, took 0.074805 s
2025-04-02 22:19:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.8921 ms
2025-04-02 22:19:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 25.9993 ms
2025-04-02 22:19:08 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.8397 ms
2025-04-02 22:19:09 [main] INFO  org.apache.spark.SparkContext - Starting job: first at Main.scala:66
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (first at Main.scala:66) with 1 output partitions
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (first at Main.scala:66)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at Main.scala:66), which has no missing parents
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-04-02 22:19:09 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:50944 (size: 6.4 KiB, free: 4.5 GiB)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at Main.scala:66) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-04-02 22:19:09 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 22:19:09 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-04-02 22:19:09 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:19:09 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1648 bytes result sent to driver
2025-04-02 22:19:09 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 80 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:09 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (first at Main.scala:66) finished in 0.089 s
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-04-02 22:19:09 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: first at Main.scala:66, took 0.092858 s
2025-04-02 22:19:09 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.2969 ms
2025-04-02 22:19:09 [main] INFO  Main$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-04-02 22:19:09 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 35 ms to list leaf files for 1 paths.
2025-04-02 22:19:09 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (load at update_parquet.scala:18) with 1 output partitions
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (load at update_parquet.scala:18)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[23] at load at update_parquet.scala:18), which has no missing parents
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 4.5 GiB)
2025-04-02 22:19:09 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:50944 (size: 37.0 KiB, free: 4.5 GiB)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-04-02 22:19:09 [dispatcher-event-loop-14] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9092 bytes) 
2025-04-02 22:19:09 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-04-02 22:19:09 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2377 bytes result sent to driver
2025-04-02 22:19:09 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 187 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:09 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (load at update_parquet.scala:18) finished in 0.206 s
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-04-02 22:19:09 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: load at update_parquet.scala:18, took 0.208855 s
2025-04-02 22:19:09 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-04-02 22:19:09 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-04-02 22:19:09 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.3399 ms
2025-04-02 22:19:09 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 200.0 KiB, free 4.5 GiB)
2025-04-02 22:19:09 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 4.5 GiB)
2025-04-02 22:19:09 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:50944 (size: 34.6 KiB, free: 4.5 GiB)
2025-04-02 22:19:09 [main] INFO  org.apache.spark.SparkContext - Created broadcast 8 from isEmpty at update_parquet.scala:19
2025-04-02 22:19:09 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-04-02 22:19:09 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at update_parquet.scala:19
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (isEmpty at update_parquet.scala:19) with 1 output partitions
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (isEmpty at update_parquet.scala:19)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[27] at isEmpty at update_parquet.scala:19), which has no missing parents
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 11.3 KiB, free 4.5 GiB)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 4.5 GiB)
2025-04-02 22:19:09 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:50944 (size: 5.4 KiB, free: 4.5 GiB)
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at isEmpty at update_parquet.scala:19) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-04-02 22:19:09 [dispatcher-event-loop-2] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, NODE_LOCAL, 9450 bytes) 
2025-04-02 22:19:09 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-04-02 22:19:09 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-955706fc-04bf-43c8-9b7c-3732ac41b5f2-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-04-02 22:19:09 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1753 bytes result sent to driver
2025-04-02 22:19:09 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 111 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:09 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (isEmpty at update_parquet.scala:19) finished in 0.132 s
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:09 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-04-02 22:19:09 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: isEmpty at update_parquet.scala:19, took 0.138904 s
2025-04-02 22:19:09 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-04-02 22:19:09 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-04-02 22:19:10 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-04-02 22:19:10 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 35.0495 ms
2025-04-02 22:19:10 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 16.0445 ms
2025-04-02 22:19:10 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 201.1 KiB, free 4.5 GiB)
2025-04-02 22:19:10 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 4.5 GiB)
2025-04-02 22:19:10 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:50944 (size: 35.0 KiB, free: 4.5 GiB)
2025-04-02 22:19:10 [main] INFO  org.apache.spark.SparkContext - Created broadcast 10 from save at update_parquet.scala:46
2025-04-02 22:19:10 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-04-02 22:19:10 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.8172 ms
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 35 (save at update_parquet.scala:46) as input to shuffle 0
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got map stage job 9 (save at update_parquet.scala:46) with 2 output partitions
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 9 (save at update_parquet.scala:46)
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at save at update_parquet.scala:46), which has no missing parents
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 46.8 KiB, free 4.5 GiB)
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 4.5 GiB)
2025-04-02 22:19:10 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:50944 (size: 18.9 KiB, free: 4.5 GiB)
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2025-04-02 22:19:10 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 2 tasks resource profile 0
2025-04-02 22:19:10 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, NODE_LOCAL, 9548 bytes) 
2025-04-02 22:19:10 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 9.0 (TID 10) (YAU, executor driver, partition 1, PROCESS_LOCAL, 8765 bytes) 
2025-04-02 22:19:10 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-04-02 22:19:10 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 9.0 (TID 10)
2025-04-02 22:19:10 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 17.221 ms
2025-04-02 22:19:10 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.1936 ms
2025-04-02 22:19:10 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.6765 ms
2025-04-02 22:19:10 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-955706fc-04bf-43c8-9b7c-3732ac41b5f2-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-04-02 22:19:10 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 22:19:10 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new decompressor [.snappy]
2025-04-02 22:19:12 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 9.0 (TID 10). 3234 bytes result sent to driver
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 3277 bytes result sent to driver
2025-04-02 22:19:12 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 9.0 (TID 10) in 2402 ms on YAU (executor driver) (1/2)
2025-04-02 22:19:12 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 2407 ms on YAU (executor driver) (2/2)
2025-04-02 22:19:12 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 9 (save at update_parquet.scala:46) finished in 2.433 s
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: HashSet()
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: HashSet()
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: HashSet()
2025-04-02 22:19:12 [main] INFO  o.a.s.s.e.a.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-04-02 22:19:12 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:12 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:12 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:12 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:12 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-04-02 22:19:12 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.5115 ms
2025-04-02 22:19:12 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:46
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (save at update_parquet.scala:46) with 1 output partitions
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (save at update_parquet.scala:46)
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[38] at save at update_parquet.scala:46), which has no missing parents
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 243.5 KiB, free 4.5 GiB)
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 4.5 GiB)
2025-04-02 22:19:12 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:50944 (size: 89.0 KiB, free: 4.5 GiB)
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[38] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0))
2025-04-02 22:19:12 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-04-02 22:19:12 [dispatcher-event-loop-10] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, NODE_LOCAL, 8821 bytes) 
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 2 (1173.7 KiB) non-empty blocks including 2 (1173.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 20 ms
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-04-02 22:19:12 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-04-02 22:19:13 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202504022219127515919123562573004_0011_m_000000_11' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202504022219127515919123562573004_0011_m_000000
2025-04-02 22:19:13 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202504022219127515919123562573004_0011_m_000000_11: Committed. Elapsed time: 6 ms.
2025-04-02 22:19:13 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 6784 bytes result sent to driver
2025-04-02 22:19:13 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 219 ms on YAU (executor driver) (1/1)
2025-04-02 22:19:13 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-04-02 22:19:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (save at update_parquet.scala:46) finished in 0.257 s
2025-04-02 22:19:13 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 22:19:13 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-04-02 22:19:13 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: save at update_parquet.scala:46, took 0.269958 s
2025-04-02 22:19:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 6cc4b4ca-afaa-4ea6-a9f4-dc94c29b4c8d.
2025-04-02 22:19:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 6cc4b4ca-afaa-4ea6-a9f4-dc94c29b4c8d committed. Elapsed time: 22 ms.
2025-04-02 22:19:13 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 6cc4b4ca-afaa-4ea6-a9f4-dc94c29b4c8d.
2025-04-02 22:19:13 [main] INFO  functions.update_parquet$ - Delta load completed for timestamp
2025-04-02 22:19:13 [main] INFO  Main$ -  }}}}}}}}}}}}}}}}}} SUCCESSFULLY CONDUCTED ALL STEPS {{{{{{{{{{{{{{{{{
2025-04-02 22:19:13 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-04-02 22:19:13 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@4eb1c69{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-04-02 22:19:13 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4040
2025-04-02 22:19:13 [dispatcher-event-loop-15] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-04-02 22:19:13 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-04-02 22:19:13 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-04-02 22:19:13 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-04-02 22:19:13 [dispatcher-event-loop-3] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-04-02 22:19:13 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-04-02 22:19:13 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-04-02 22:19:13 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-5b7e6040-5b1a-4edc-b36a-860a12dbfec0
2025-04-02 23:07:12 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.4
2025-04-02 23:07:12 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-04-02 23:07:12 [main] INFO  o.a.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-04-02 23:07:12 [main] INFO  o.a.spark.resource.ResourceUtils - ==============================================================
2025-04-02 23:07:12 [main] INFO  org.apache.spark.SparkContext - Submitted application: mysql config
2025-04-02 23:07:12 [main] INFO  o.a.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-04-02 23:07:12 [main] INFO  o.a.spark.resource.ResourceProfile - Limiting resource is cpu
2025-04-02 23:07:12 [main] INFO  o.a.s.r.ResourceProfileManager - Added ResourceProfile id: 0
2025-04-02 23:07:12 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: shres
2025-04-02 23:07:12 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: shres
2025-04-02 23:07:12 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-04-02 23:07:12 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-04-02 23:07:12 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: shres; groups with view permissions: EMPTY; users with modify permissions: shres; groups with modify permissions: EMPTY
2025-04-02 23:07:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51714.
2025-04-02 23:07:13 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-04-02 23:07:13 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-04-02 23:07:13 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-04-02 23:07:13 [main] INFO  o.a.s.s.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-04-02 23:07:13 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-04-02 23:07:13 [main] INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\shres\AppData\Local\Temp\blockmgr-bded6fa6-f1f4-4f11-9fe6-1b8929733ce3
2025-04-02 23:07:13 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore started with capacity 4.5 GiB
2025-04-02 23:07:13 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-04-02 23:07:13 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @3144ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-04-02 23:07:13 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-04-02 23:07:13 [main] INFO  o.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.25+9-LTS-256
2025-04-02 23:07:13 [main] INFO  o.sparkproject.jetty.server.Server - Started @3286ms
2025-04-02 23:07:13 [main] WARN  org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-04-02 23:07:13 [main] INFO  o.s.jetty.server.AbstractConnector - Started ServerConnector@11f406f8{HTTP/1.1, (http/1.1)}{0.0.0.0:4041}
2025-04-02 23:07:13 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4041.
2025-04-02 23:07:13 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@11a8042c{/,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host YAU
2025-04-02 23:07:14 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-04-02 23:07:14 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51765.
2025-04-02 23:07:14 [main] INFO  o.a.s.n.n.NettyBlockTransferService - Server created on YAU:51765
2025-04-02 23:07:14 [main] INFO  o.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-04-02 23:07:14 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, YAU, 51765, None)
2025-04-02 23:07:14 [dispatcher-BlockManagerMaster] INFO  o.a.s.s.BlockManagerMasterEndpoint - Registering block manager YAU:51765 with 4.5 GiB RAM, BlockManagerId(driver, YAU, 51765, None)
2025-04-02 23:07:14 [main] INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, YAU, 51765, None)
2025-04-02 23:07:14 [main] INFO  o.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, YAU, 51765, None)
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@11a8042c{/,null,STOPPED,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@594d9f07{/jobs,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e9f73b{/jobs/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d3aba5{/jobs/job,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76e9f00b{/jobs/job/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f1b8544{/stages,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@688a2c09{/stages/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ee83775{/stages/stage,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b5de58f{/stages/stage/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abbe000{/stages/pool,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b9499fe{/stages/pool/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52a33c3f{/storage,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19a20bb2{/storage/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3eb3232b{/storage/rdd,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60bb7995{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67774e29{/environment,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5d7399f9{/environment/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@14fded9d{/executors,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a3bd45b{/executors/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4f2d995e{/executors/threadDump,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6198e9b5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4ecd00b5{/static,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3ba348ca{/,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@45b15381{/api,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b13467c{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64dae3b7{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1a1cc163{/metrics/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  Main$ - Application started!
2025-04-02 23:07:14 [main] INFO  Main$ - hdfs
2025-04-02 23:07:14 [main] INFO  Main$ - LOGGING TEST - LOAD MYSQL DATA TO HDFS
2025-04-02 23:07:14 [main] INFO  o.a.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-04-02 23:07:14 [main] INFO  o.a.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/shres/IdeaProjects/hadoop/spark-warehouse'.
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@29f38091{/SQL,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77c3c037{/SQL/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1e7f19b4{/SQL/execution,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4346808{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-04-02 23:07:14 [main] INFO  o.s.j.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/static/sql,null,AVAILABLE,@Spark}
2025-04-02 23:07:19 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 299.2631 ms
2025-04-02 23:07:19 [main] INFO  org.apache.spark.SparkContext - Starting job: show at Main.scala:34
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (show at Main.scala:34) with 1 output partitions
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (show at Main.scala:34)
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34), which has no missing parents
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 14.6 KiB, free 4.5 GiB)
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 4.5 GiB)
2025-04-02 23:07:19 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on YAU:51765 (size: 7.0 KiB, free: 4.5 GiB)
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at Main.scala:34) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:19 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-04-02 23:07:19 [dispatcher-event-loop-6] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 23:07:19 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-04-02 23:07:20 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 23:07:20 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1846 bytes result sent to driver
2025-04-02 23:07:20 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 203 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:20 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 0 (show at Main.scala:34) finished in 0.552 s
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-04-02 23:07:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 0 finished: show at Main.scala:34, took 0.611447 s
2025-04-02 23:07:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 35.066 ms
2025-04-02 23:07:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.8287 ms
2025-04-02 23:07:20 [main] INFO  org.apache.spark.SparkContext - Starting job: collect at Main.scala:37
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at Main.scala:37) with 1 output partitions
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (collect at Main.scala:37)
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[5] at collect at Main.scala:37), which has no missing parents
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 4.5 GiB)
2025-04-02 23:07:20 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on YAU:51765 (size: 6.2 KiB, free: 4.5 GiB)
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at collect at Main.scala:37) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-04-02 23:07:20 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 23:07:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-04-02 23:07:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 23:07:20 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1773 bytes result sent to driver
2025-04-02 23:07:20 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 34 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:20 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 1 (collect at Main.scala:37) finished in 0.044 s
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:20 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-04-02 23:07:20 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 1 finished: collect at Main.scala:37, took 0.047527 s
2025-04-02 23:07:20 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 32.768 ms
2025-04-02 23:07:20 [main] INFO  Main$ - ########## dirty_cafe_sales ----> hdfs://localhost:9000/user/sabil/dirty/ -----> 0  ##########
2025-04-02 23:07:21 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:21 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:21 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:21 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:21 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:21 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:21 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:21 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.7452 ms
2025-04-02 23:07:21 [main] INFO  org.apache.spark.SparkContext - Starting job: save at Main.scala:55
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 2 (save at Main.scala:55) with 1 output partitions
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (save at Main.scala:55)
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[8] at save at Main.scala:55), which has no missing parents
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 214.4 KiB, free 4.5 GiB)
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 4.5 GiB)
2025-04-02 23:07:21 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on YAU:51765 (size: 76.9 KiB, free: 4.5 GiB)
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at save at Main.scala:55) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:21 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-04-02 23:07:21 [dispatcher-event-loop-12] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 2) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 2)
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "Transaction ID",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "item",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "quantity",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Price Per Unit",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Total Spent",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "Payment Method",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_date",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary Transaction ID (STRING);
  optional binary item (STRING);
  optional binary quantity (STRING);
  optional binary Price Per Unit (STRING);
  optional binary Total Spent (STRING);
  optional binary Payment Method (STRING);
  optional binary location (STRING);
  optional binary transaction_date (STRING);
}

       
2025-04-02 23:07:21 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new compressor [.snappy]
2025-04-02 23:07:21 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on YAU:51765 in memory (size: 6.2 KiB, free: 4.5 GiB)
2025-04-02 23:07:21 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on YAU:51765 in memory (size: 7.0 KiB, free: 4.5 GiB)
2025-04-02 23:07:22 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 23:07:22 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202504022307214470314912949991131_0002_m_000000_2' to hdfs://localhost:9000/user/sabil/dirty/_temporary/0/task_202504022307214470314912949991131_0002_m_000000
2025-04-02 23:07:22 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202504022307214470314912949991131_0002_m_000000_2: Committed. Elapsed time: 9 ms.
2025-04-02 23:07:22 [Executor task launch worker for task 0.0 in stage 2.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 2). 2828 bytes result sent to driver
2025-04-02 23:07:22 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 2) in 1242 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:22 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 2 (save at Main.scala:55) finished in 1.292 s
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-04-02 23:07:22 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 2 finished: save at Main.scala:55, took 1.296606 s
2025-04-02 23:07:22 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job f3164569-f143-461c-91ba-c37f3c627c94.
2025-04-02 23:07:22 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job f3164569-f143-461c-91ba-c37f3c627c94 committed. Elapsed time: 29 ms.
2025-04-02 23:07:22 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job f3164569-f143-461c-91ba-c37f3c627c94.
2025-04-02 23:07:22 [main] INFO  Main$ - ########## fraud_shrinked ----> hdfs://localhost:9000/user/sabil/fraud/ -----> 0  ##########
2025-04-02 23:07:22 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:22 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:22 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:22 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:22 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:22 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:22 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:22 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.2648 ms
2025-04-02 23:07:22 [main] INFO  org.apache.spark.SparkContext - Starting job: save at Main.scala:55
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 3 (save at Main.scala:55) with 1 output partitions
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (save at Main.scala:55)
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[11] at save at Main.scala:55), which has no missing parents
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 215.7 KiB, free 4.5 GiB)
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 77.2 KiB, free 4.5 GiB)
2025-04-02 23:07:22 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on YAU:51765 (size: 77.2 KiB, free: 4.5 GiB)
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at save at Main.scala:55) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:22 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-04-02 23:07:22 [dispatcher-event-loop-0] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 23:07:22 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "step",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "type",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "nameorig",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalanceorg",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalanceorig",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "namedest",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "oldbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "newbalancedest",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "isflaggedfraud",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 step;
  optional binary type (STRING);
  optional double amount;
  optional binary nameorig (STRING);
  optional double oldbalanceorg;
  optional double newbalanceorig;
  optional binary namedest (STRING);
  optional double oldbalancedest;
  optional double newbalancedest;
  optional int32 isfraud;
  optional int32 isflaggedfraud;
}

       
2025-04-02 23:07:23 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on YAU:51765 in memory (size: 76.9 KiB, free: 4.5 GiB)
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202504022307225226125176355675887_0003_m_000000_3' to hdfs://localhost:9000/user/sabil/fraud/_temporary/0/task_202504022307225226125176355675887_0003_m_000000
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202504022307225226125176355675887_0003_m_000000_3: Committed. Elapsed time: 7 ms.
2025-04-02 23:07:23 [Executor task launch worker for task 0.0 in stage 3.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2785 bytes result sent to driver
2025-04-02 23:07:23 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 1229 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:23 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-04-02 23:07:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 3 (save at Main.scala:55) finished in 1.270 s
2025-04-02 23:07:23 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:23 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-04-02 23:07:23 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 3 finished: save at Main.scala:55, took 1.274621 s
2025-04-02 23:07:23 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 5ae0c5dd-978e-419f-8b12-fc1f128073b5.
2025-04-02 23:07:23 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 5ae0c5dd-978e-419f-8b12-fc1f128073b5 committed. Elapsed time: 23 ms.
2025-04-02 23:07:23 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 5ae0c5dd-978e-419f-8b12-fc1f128073b5.
2025-04-02 23:07:23 [main] INFO  Main$ - ########## bank_transaction ----> hdfs://localhost:9000/user/sabil/bank/ -----> 0  ##########
2025-04-02 23:07:24 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:24 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:24 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:24 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:24 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:24 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:24 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.4731 ms
2025-04-02 23:07:24 [main] INFO  org.apache.spark.SparkContext - Starting job: save at Main.scala:55
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 4 (save at Main.scala:55) with 1 output partitions
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 4 (save at Main.scala:55)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 4 (MapPartitionsRDD[14] at save at Main.scala:55), which has no missing parents
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 218.2 KiB, free 4.5 GiB)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 77.7 KiB, free 4.5 GiB)
2025-04-02 23:07:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on YAU:51765 (size: 77.7 KiB, free: 4.5 GiB)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at save at Main.scala:55) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
2025-04-02 23:07:24 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "transactionid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionamount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactiontype",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "location",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "deviceid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "IP Address",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchantid",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "channel",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customerage",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "customeroccupation",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transactionduration",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "loginattempts",
    "type" : "integer",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "accountbalance",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "previoustransactiondate",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary transactionid (STRING);
  optional binary accountid (STRING);
  optional double transactionamount;
  optional binary transactiondate (STRING);
  optional binary transactiontype (STRING);
  optional binary location (STRING);
  optional binary deviceid (STRING);
  optional binary IP Address (STRING);
  optional binary merchantid (STRING);
  optional binary channel (STRING);
  optional int32 customerage;
  optional binary customeroccupation (STRING);
  optional int32 transactionduration;
  optional int32 loginattempts;
  optional double accountbalance;
  optional binary previoustransactiondate (STRING);
}

       
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202504022307241834208033603253717_0004_m_000000_4' to hdfs://localhost:9000/user/sabil/bank/_temporary/0/task_202504022307241834208033603253717_0004_m_000000
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202504022307241834208033603253717_0004_m_000000_4: Committed. Elapsed time: 7 ms.
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 4.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 2742 bytes result sent to driver
2025-04-02 23:07:24 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 132 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:24 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 4 (save at Main.scala:55) finished in 0.161 s
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 4: Stage finished
2025-04-02 23:07:24 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 4 finished: save at Main.scala:55, took 0.164177 s
2025-04-02 23:07:24 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job c512e83f-acbc-416b-854b-08f39d802dd7.
2025-04-02 23:07:24 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job c512e83f-acbc-416b-854b-08f39d802dd7 committed. Elapsed time: 19 ms.
2025-04-02 23:07:24 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job c512e83f-acbc-416b-854b-08f39d802dd7.
2025-04-02 23:07:24 [main] INFO  Main$ - ########## transaction ----> hdfs://localhost:9000/user/sabil/transaction/ -----> 1  ##########
2025-04-02 23:07:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 12.8335 ms
2025-04-02 23:07:24 [main] INFO  org.apache.spark.SparkContext - Starting job: show at Main.scala:58
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 5 (show at Main.scala:58) with 1 output partitions
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (show at Main.scala:58)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:58), which has no missing parents
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 13.2 KiB, free 4.5 GiB)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 4.5 GiB)
2025-04-02 23:07:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on YAU:51765 (size: 6.3 KiB, free: 4.5 GiB)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[17] at show at Main.scala:58) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
2025-04-02 23:07:24 [dispatcher-event-loop-8] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 5.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 4233 bytes result sent to driver
2025-04-02 23:07:24 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 37 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:24 [task-result-getter-1] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 5 (show at Main.scala:58) finished in 0.048 s
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
2025-04-02 23:07:24 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 5 finished: show at Main.scala:58, took 0.050130 s
2025-04-02 23:07:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.4919 ms
2025-04-02 23:07:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 28.8234 ms
2025-04-02 23:07:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 6.6885 ms
2025-04-02 23:07:24 [main] INFO  org.apache.spark.SparkContext - Starting job: first at Main.scala:66
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 6 (first at Main.scala:66) with 1 output partitions
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (first at Main.scala:66)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at Main.scala:66), which has no missing parents
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 13.1 KiB, free 4.5 GiB)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 4.5 GiB)
2025-04-02 23:07:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on YAU:51765 (size: 6.4 KiB, free: 4.5 GiB)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at Main.scala:66) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks resource profile 0
2025-04-02 23:07:24 [dispatcher-event-loop-11] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (YAU, executor driver, partition 0, PROCESS_LOCAL, 8667 bytes) 
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 6.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1648 bytes result sent to driver
2025-04-02 23:07:24 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 88 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:24 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 6 (first at Main.scala:66) finished in 0.101 s
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 6: Stage finished
2025-04-02 23:07:24 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 6 finished: first at Main.scala:66, took 0.105219 s
2025-04-02 23:07:24 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.5366 ms
2025-04-02 23:07:24 [main] INFO  Main$ - ################# LATEST DATE 2025-03-26T02:53:31 ----> PREVIOUS DATE 2025-03-25T02:53:31 #######################
2025-04-02 23:07:24 [main] INFO  o.a.s.s.e.d.InMemoryFileIndex - It took 28 ms to list leaf files for 1 paths.
2025-04-02 23:07:24 [main] INFO  org.apache.spark.SparkContext - Starting job: load at update_parquet.scala:18
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 7 (load at update_parquet.scala:18) with 1 output partitions
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (load at update_parquet.scala:18)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[23] at load at update_parquet.scala:18), which has no missing parents
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 102.9 KiB, free 4.5 GiB)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 37.0 KiB, free 4.5 GiB)
2025-04-02 23:07:24 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on YAU:51765 (size: 37.0 KiB, free: 4.5 GiB)
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[23] at load at update_parquet.scala:18) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:24 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 1 tasks resource profile 0
2025-04-02 23:07:24 [dispatcher-event-loop-14] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 7) (YAU, executor driver, partition 0, PROCESS_LOCAL, 9092 bytes) 
2025-04-02 23:07:24 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 7)
2025-04-02 23:07:25 [Executor task launch worker for task 0.0 in stage 7.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 7). 2377 bytes result sent to driver
2025-04-02 23:07:25 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 7) in 139 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:25 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 7 (load at update_parquet.scala:18) finished in 0.159 s
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 7: Stage finished
2025-04-02 23:07:25 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 7 finished: load at update_parquet.scala:18, took 0.162904 s
2025-04-02 23:07:25 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-04-02 23:07:25 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-04-02 23:07:25 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 10.9626 ms
2025-04-02 23:07:25 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 200.0 KiB, free 4.5 GiB)
2025-04-02 23:07:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on YAU:51765 in memory (size: 37.0 KiB, free: 4.5 GiB)
2025-04-02 23:07:25 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 4.5 GiB)
2025-04-02 23:07:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on YAU:51765 in memory (size: 6.4 KiB, free: 4.5 GiB)
2025-04-02 23:07:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on YAU:51765 (size: 34.6 KiB, free: 4.5 GiB)
2025-04-02 23:07:25 [main] INFO  org.apache.spark.SparkContext - Created broadcast 8 from isEmpty at update_parquet.scala:19
2025-04-02 23:07:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on YAU:51765 in memory (size: 77.7 KiB, free: 4.5 GiB)
2025-04-02 23:07:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on YAU:51765 in memory (size: 6.3 KiB, free: 4.5 GiB)
2025-04-02 23:07:25 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-04-02 23:07:25 [main] INFO  org.apache.spark.SparkContext - Starting job: isEmpty at update_parquet.scala:19
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 8 (isEmpty at update_parquet.scala:19) with 1 output partitions
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 8 (isEmpty at update_parquet.scala:19)
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 8 (MapPartitionsRDD[27] at isEmpty at update_parquet.scala:19), which has no missing parents
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 11.3 KiB, free 4.5 GiB)
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 4.5 GiB)
2025-04-02 23:07:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on YAU:51765 (size: 5.4 KiB, free: 4.5 GiB)
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[27] at isEmpty at update_parquet.scala:19) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks resource profile 0
2025-04-02 23:07:25 [dispatcher-event-loop-4] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 8) (YAU, executor driver, partition 0, NODE_LOCAL, 9450 bytes) 
2025-04-02 23:07:25 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 8)
2025-04-02 23:07:25 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-8bf2cc90-0de5-432c-b3fc-19bf26e8ef7d-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-04-02 23:07:25 [Executor task launch worker for task 0.0 in stage 8.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 8). 1796 bytes result sent to driver
2025-04-02 23:07:25 [task-result-getter-0] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 8) in 98 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:25 [task-result-getter-0] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 8 (isEmpty at update_parquet.scala:19) finished in 0.117 s
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 8: Stage finished
2025-04-02 23:07:25 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 8 finished: isEmpty at update_parquet.scala:19, took 0.125779 s
2025-04-02 23:07:25 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Pushed Filters: 
2025-04-02 23:07:25 [main] INFO  o.a.s.s.e.d.FileSourceStrategy - Post-Scan Filters: 
2025-04-02 23:07:25 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-04-02 23:07:25 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 29.8201 ms
2025-04-02 23:07:25 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 13.1046 ms
2025-04-02 23:07:25 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 201.1 KiB, free 4.5 GiB)
2025-04-02 23:07:25 [main] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 4.5 GiB)
2025-04-02 23:07:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on YAU:51765 (size: 35.0 KiB, free: 4.5 GiB)
2025-04-02 23:07:25 [main] INFO  org.apache.spark.SparkContext - Created broadcast 10 from save at update_parquet.scala:46
2025-04-02 23:07:25 [main] INFO  o.a.s.s.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2025-04-02 23:07:25 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 14.8058 ms
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 35 (save at update_parquet.scala:46) as input to shuffle 0
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got map stage job 9 (save at update_parquet.scala:46) with 2 output partitions
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 9 (save at update_parquet.scala:46)
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at save at update_parquet.scala:46), which has no missing parents
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 46.8 KiB, free 4.5 GiB)
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 4.5 GiB)
2025-04-02 23:07:25 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on YAU:51765 (size: 18.9 KiB, free: 4.5 GiB)
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0, 1))
2025-04-02 23:07:25 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 2 tasks resource profile 0
2025-04-02 23:07:25 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 9) (YAU, executor driver, partition 0, NODE_LOCAL, 9548 bytes) 
2025-04-02 23:07:25 [dispatcher-event-loop-1] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 9.0 (TID 10) (YAU, executor driver, partition 1, PROCESS_LOCAL, 8765 bytes) 
2025-04-02 23:07:25 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 9)
2025-04-02 23:07:25 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 9.0 (TID 10)
2025-04-02 23:07:25 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 20.6544 ms
2025-04-02 23:07:25 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 5.2577 ms
2025-04-02 23:07:25 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 7.8039 ms
2025-04-02 23:07:25 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.s.s.e.datasources.FileScanRDD - Reading File path: hdfs://localhost:9000/user/sabil/transaction/part-00000-8bf2cc90-0de5-432c-b3fc-19bf26e8ef7d-c000.snappy.parquet, range: 0-125158, partition values: [empty row]
2025-04-02 23:07:26 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  o.a.s.s.e.datasources.jdbc.JDBCRDD - closed connection
2025-04-02 23:07:26 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  o.a.hadoop.io.compress.CodecPool - Got brand-new decompressor [.snappy]
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 9.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 9). 3277 bytes result sent to driver
2025-04-02 23:07:27 [Executor task launch worker for task 1.0 in stage 9.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 9.0 (TID 10). 3191 bytes result sent to driver
2025-04-02 23:07:27 [task-result-getter-1] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 9) in 1380 ms on YAU (executor driver) (1/2)
2025-04-02 23:07:27 [task-result-getter-2] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 9.0 (TID 10) in 1378 ms on YAU (executor driver) (2/2)
2025-04-02 23:07:27 [task-result-getter-2] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ShuffleMapStage 9 (save at update_parquet.scala:46) finished in 1.412 s
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - running: HashSet()
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - waiting: HashSet()
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - failed: HashSet()
2025-04-02 23:07:27 [main] INFO  o.a.s.s.e.a.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-04-02 23:07:27 [main] INFO  o.a.s.s.e.d.parquet.ParquetUtils - Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:27 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:27 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:27 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:27 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:27 [main] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:27 [main] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:27 [main] INFO  o.a.s.s.e.a.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-04-02 23:07:27 [main] INFO  o.a.s.s.c.e.codegen.CodeGenerator - Code generated in 11.2615 ms
2025-04-02 23:07:27 [main] INFO  org.apache.spark.SparkContext - Starting job: save at update_parquet.scala:46
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Got job 10 (save at update_parquet.scala:46) with 1 output partitions
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (save at update_parquet.scala:46)
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 10)
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List()
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[38] at save at update_parquet.scala:46), which has no missing parents
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 243.5 KiB, free 4.5 GiB)
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 89.0 KiB, free 4.5 GiB)
2025-04-02 23:07:27 [dispatcher-BlockManagerMaster] INFO  o.a.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on YAU:51765 (size: 89.0 KiB, free: 4.5 GiB)
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1540
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[38] at save at update_parquet.scala:46) (first 15 tasks are for partitions Vector(0))
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 1 tasks resource profile 0
2025-04-02 23:07:27 [dispatcher-event-loop-9] INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 11) (YAU, executor driver, partition 0, NODE_LOCAL, 8821 bytes) 
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 11)
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Getting 2 (1173.7 KiB) non-empty blocks including 2 (1173.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.ShuffleBlockFetcherIterator - Started 0 remote fetches in 18 ms
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - File Output Committer Algorithm version is 1
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.SQLHadoopMapReduceCommitProtocol - Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.parquet.hadoop.codec.CodecConfig - Compression: SNAPPY
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.p.hadoop.ParquetOutputFormat - ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.s.e.d.p.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "customer_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "zipcode",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "merchant_name",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "mapped_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "transaction_amount",
    "type" : "double",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  }, {
    "name" : "timestamp",
    "type" : "string",
    "nullable" : true,
    "metadata" : {
      "scale" : 0
    }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary customer_id (STRING);
  optional double zipcode;
  optional binary category (STRING);
  optional binary merchant_name (STRING);
  optional binary mapped_category (STRING);
  optional double transaction_amount;
  optional binary timestamp (STRING);
}

       
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.h.m.l.output.FileOutputCommitter - Saved output of task 'attempt_202504022307271374936654722957915_0011_m_000000_11' to hdfs://localhost:9000/user/sabil/transaction/_temporary/0/task_202504022307271374936654722957915_0011_m_000000
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  o.a.s.mapred.SparkHadoopMapRedUtil - attempt_202504022307271374936654722957915_0011_m_000000_11: Committed. Elapsed time: 6 ms.
2025-04-02 23:07:27 [Executor task launch worker for task 0.0 in stage 11.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 11). 6741 bytes result sent to driver
2025-04-02 23:07:27 [task-result-getter-3] INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 11) in 217 ms on YAU (executor driver) (1/1)
2025-04-02 23:07:27 [task-result-getter-3] INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - ResultStage 11 (save at update_parquet.scala:46) finished in 0.235 s
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-04-02 23:07:27 [dag-scheduler-event-loop] INFO  o.a.s.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 11: Stage finished
2025-04-02 23:07:27 [main] INFO  o.a.spark.scheduler.DAGScheduler - Job 10 finished: save at update_parquet.scala:46, took 0.253346 s
2025-04-02 23:07:27 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Start to commit write Job 75cb09c9-e5f5-43a1-989a-4afd0573453b.
2025-04-02 23:07:27 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Write Job 75cb09c9-e5f5-43a1-989a-4afd0573453b committed. Elapsed time: 25 ms.
2025-04-02 23:07:27 [main] INFO  o.a.s.s.e.d.FileFormatWriter - Finished processing stats for write job 75cb09c9-e5f5-43a1-989a-4afd0573453b.
2025-04-02 23:07:27 [main] INFO  functions.update_parquet$ - Delta load completed for timestamp
2025-04-02 23:07:27 [main] INFO  Main$ -  }}}}}}}}}}}}}}}}}} SUCCESSFULLY CONDUCTED ALL STEPS {{{{{{{{{{{{{{{{{
2025-04-02 23:07:27 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-04-02 23:07:27 [main] INFO  o.s.jetty.server.AbstractConnector - Stopped Spark@11f406f8{HTTP/1.1, (http/1.1)}{0.0.0.0:4041}
2025-04-02 23:07:27 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://YAU:4041
2025-04-02 23:07:27 [dispatcher-event-loop-14] INFO  o.a.s.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-04-02 23:07:27 [main] INFO  o.a.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-04-02 23:07:27 [main] INFO  o.apache.spark.storage.BlockManager - BlockManager stopped
2025-04-02 23:07:27 [main] INFO  o.a.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-04-02 23:07:27 [dispatcher-event-loop-3] INFO  o.a.s.s.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-04-02 23:07:27 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-04-02 23:07:27 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Shutdown hook called
2025-04-02 23:07:27 [shutdown-hook-0] INFO  o.a.spark.util.ShutdownHookManager - Deleting directory C:\Users\shres\AppData\Local\Temp\spark-937cd6b1-ed1e-4671-8107-446eb6f1daed
